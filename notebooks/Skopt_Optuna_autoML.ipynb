{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "243b4e45",
   "metadata": {},
   "source": [
    "environment: skopt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9f4908",
   "metadata": {},
   "source": [
    "# Scikit-Optimize\n",
    "\n",
    "Probably you'll have to reload the notebook for the changes being in place. Scikit-Optimize works only with sklearn 0.23.2<br>\n",
    "works with env skopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a8d8d1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.9.0'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'1.0.2'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import skopt\n",
    "import importlib\n",
    "import sklearn\n",
    "display(skopt.__version__)\n",
    "importlib.reload(sklearn)\n",
    "display(sklearn.__version__)\n",
    "\n",
    "# Since BayesSearchCV can not deal with missing values, we have to impute them before:\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "train = pd.read_csv('../data/train.csv', sep=\",\")\n",
    "test = pd.read_csv('../data/test.csv')\n",
    "\n",
    "import sklearn\n",
    "y = train['SalePrice']\n",
    "X = train.drop('SalePrice', axis=1)\n",
    "categorical = [var for var in X.columns if X[var].dtype=='O']\n",
    "numerical = [var for var in X.columns if X[var].dtype!='O']\n",
    "X[categorical] = X[categorical].fillna('None')\n",
    "\n",
    "# auto-sklearn can not deal with categorical variables\n",
    "X= pd.concat([pd.get_dummies(X[categorical], dummy_na=True), X[numerical]], axis=1)\n",
    "\n",
    "y = np.log1p(y)\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(X, y, random_state=42, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91554e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/martin/miniconda3/envs/skopt/lib/python3.8/site-packages/skopt/searchcv.py:300: UserWarning: The `iid` parameter has been deprecated and will be ignored.\n",
      "  warnings.warn(\"The `iid` parameter has been deprecated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BayesSearchCV(cv=5, estimator=GradientBoostingRegressor(), iid=True, n_iter=64,\n",
       "              n_jobs=-1, random_state=0,\n",
       "              search_spaces={'learning_rate': Real(low=0.01, high=0.3, prior='uniform', transform='normalize'),\n",
       "                             'loss': Categorical(categories=('squared_error',), prior=None),\n",
       "                             'max_depth': Integer(low=3, high=6, prior='uniform', transform='normalize'),\n",
       "                             'max_features': Real(low=0.6, high=1.0, prior='uniform', transform='normalize'),\n",
       "                             'n_estimators': Integer(low=400, high=1000, prior='uniform', transform='normalize'),\n",
       "                             'subsample': Real(low=0.6, high=1.0, prior='uniform', transform='normalize')},\n",
       "              verbose=1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_transformer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "\n",
    "X_train.loc[:, numerical] = numeric_transformer.fit_transform(X_train.loc[:, numerical])\n",
    "X_test.loc[:, numerical] = numeric_transformer.fit_transform(X_test.loc[:, numerical])\n",
    "\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "from skopt import BayesSearchCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "regressor = BayesSearchCV(\n",
    "    estimator = GradientBoostingRegressor(),\n",
    "      search_spaces ={\n",
    "         'learning_rate': Real(0.01,0.3),\n",
    "         'loss': Categorical(['squared_error']),\n",
    "         'max_depth': Integer(3,6),\n",
    "         'n_estimators': Integer(400, 1000),\n",
    "         'subsample': Real(0.6, 1.0),\n",
    "         'max_features': Real(0.6, 1.0) \n",
    "      },\n",
    "    n_iter=64,\n",
    "    random_state=0,\n",
    "    verbose=1, iid=True,\n",
    "    cv=5, n_jobs=-1\n",
    "  )\n",
    "regressor.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5c72047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean-squared-error: 0.133699999611186\n"
     ]
    }
   ],
   "source": [
    "predictions = regressor.predict(X_test)\n",
    "print(\"mean-squared-error:\", sklearn.metrics.mean_squared_error(y_test, predictions, squared=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55029c90",
   "metadata": {},
   "source": [
    "# OPTUNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f11e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca954d5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-06 14:21:12,904] A new study created in memory with name: no-name-32b65a43-2bbf-45a5-9637-9fd3fabc9e59\n",
      "[I 2024-04-06 14:21:14,228] Trial 0 finished with value: 0.13180292881418804 and parameters: {'learning_rate': 0.040634652600699865, 'reg_lambda': 1.7644120835714382e-06, 'n_estimators': 980, 'num_leaves': 6, 'bagging_freq': 6, 'min_child_samples': 61, 'subsample_freq': 2, 'colsample_bytree': 0.502318225885592, 'subsample': 0.825573308608514}. Best is trial 0 with value: 0.13180292881418804.\n",
      "[I 2024-04-06 14:21:17,056] Trial 1 finished with value: 0.13298950862484893 and parameters: {'learning_rate': 0.0038482042196899555, 'reg_lambda': 5.917825012149067e-05, 'n_estimators': 998, 'num_leaves': 25, 'bagging_freq': 7, 'min_child_samples': 18, 'subsample_freq': 7, 'colsample_bytree': 0.5891849855217228, 'subsample': 0.7137351350364128}. Best is trial 0 with value: 0.13180292881418804.\n",
      "[I 2024-04-06 14:21:18,760] Trial 2 finished with value: 0.15753499409228872 and parameters: {'learning_rate': 0.002707937715396293, 'reg_lambda': 4.242225206321708e-06, 'n_estimators': 1141, 'num_leaves': 28, 'bagging_freq': 1, 'min_child_samples': 49, 'subsample_freq': 1, 'colsample_bytree': 0.563398216831126, 'subsample': 0.5402714606254477}. Best is trial 0 with value: 0.13180292881418804.\n",
      "[I 2024-04-06 14:21:19,549] Trial 3 finished with value: 0.16015152258679516 and parameters: {'learning_rate': 0.0047405107194104365, 'reg_lambda': 5.5162081209581095e-08, 'n_estimators': 628, 'num_leaves': 26, 'bagging_freq': 6, 'min_child_samples': 86, 'subsample_freq': 0, 'colsample_bytree': 0.7974625765185157, 'subsample': 0.949531435919604}. Best is trial 0 with value: 0.13180292881418804.\n",
      "[I 2024-04-06 14:21:20,732] Trial 4 finished with value: 0.13620213960549712 and parameters: {'learning_rate': 0.009987549138783348, 'reg_lambda': 2.376256995355258e-08, 'n_estimators': 1189, 'num_leaves': 29, 'bagging_freq': 4, 'min_child_samples': 70, 'subsample_freq': 5, 'colsample_bytree': 0.657079810529419, 'subsample': 0.5737616389654896}. Best is trial 0 with value: 0.13180292881418804.\n",
      "[I 2024-04-06 14:21:21,500] Trial 5 finished with value: 0.3277714794802108 and parameters: {'learning_rate': 0.00046999160947834546, 'reg_lambda': 0.01917258760560905, 'n_estimators': 638, 'num_leaves': 20, 'bagging_freq': 5, 'min_child_samples': 90, 'subsample_freq': 1, 'colsample_bytree': 0.7879571774331731, 'subsample': 0.7848701415810735}. Best is trial 0 with value: 0.13180292881418804.\n",
      "[I 2024-04-06 14:21:23,156] Trial 6 finished with value: 0.1635714078039798 and parameters: {'learning_rate': 0.002519330501091393, 'reg_lambda': 0.14637281030188942, 'n_estimators': 825, 'num_leaves': 28, 'bagging_freq': 6, 'min_child_samples': 39, 'subsample_freq': 1, 'colsample_bytree': 0.5639598159396155, 'subsample': 0.7941300796123387}. Best is trial 0 with value: 0.13180292881418804.\n",
      "[I 2024-04-06 14:21:24,368] Trial 7 finished with value: 0.13296000901425545 and parameters: {'learning_rate': 0.060486146105403656, 'reg_lambda': 3.969399046641265e-05, 'n_estimators': 899, 'num_leaves': 20, 'bagging_freq': 2, 'min_child_samples': 49, 'subsample_freq': 4, 'colsample_bytree': 0.6258888706378967, 'subsample': 0.6859320765275658}. Best is trial 0 with value: 0.13180292881418804.\n",
      "[I 2024-04-06 14:21:25,458] Trial 8 finished with value: 0.1271277921527703 and parameters: {'learning_rate': 0.020432857247989145, 'reg_lambda': 0.00019856825890957093, 'n_estimators': 1075, 'num_leaves': 4, 'bagging_freq': 2, 'min_child_samples': 9, 'subsample_freq': 0, 'colsample_bytree': 0.9056286963012872, 'subsample': 0.9292091151691345}. Best is trial 8 with value: 0.1271277921527703.\n",
      "[I 2024-04-06 14:21:26,194] Trial 9 finished with value: 0.35605638511844506 and parameters: {'learning_rate': 0.0001949631048569215, 'reg_lambda': 5.191095349416226e-08, 'n_estimators': 727, 'num_leaves': 29, 'bagging_freq': 5, 'min_child_samples': 81, 'subsample_freq': 6, 'colsample_bytree': 0.7790196163151359, 'subsample': 0.7414108303482396}. Best is trial 8 with value: 0.1271277921527703.\n",
      "[I 2024-04-06 14:21:27,308] Trial 10 finished with value: 0.1270305153288948 and parameters: {'learning_rate': 0.01887918300485119, 'reg_lambda': 0.0030224599951700847, 'n_estimators': 1073, 'num_leaves': 4, 'bagging_freq': 3, 'min_child_samples': 12, 'subsample_freq': 3, 'colsample_bytree': 0.9645117024756075, 'subsample': 0.9807564475327044}. Best is trial 10 with value: 0.1270305153288948.\n",
      "[I 2024-04-06 14:21:28,332] Trial 11 finished with value: 0.12857247732660423 and parameters: {'learning_rate': 0.0270593933877293, 'reg_lambda': 0.003878127976890785, 'n_estimators': 1072, 'num_leaves': 4, 'bagging_freq': 3, 'min_child_samples': 6, 'subsample_freq': 3, 'colsample_bytree': 0.988381937019382, 'subsample': 0.9912694138795071}. Best is trial 10 with value: 0.1270305153288948.\n",
      "[I 2024-04-06 14:21:30,611] Trial 12 finished with value: 0.12830967571977325 and parameters: {'learning_rate': 0.015651033579635577, 'reg_lambda': 0.0013149150269433773, 'n_estimators': 1070, 'num_leaves': 10, 'bagging_freq': 2, 'min_child_samples': 25, 'subsample_freq': 3, 'colsample_bytree': 0.9628321378546478, 'subsample': 0.8915403056775524}. Best is trial 10 with value: 0.1270305153288948.\n",
      "[I 2024-04-06 14:21:32,561] Trial 13 finished with value: 0.13097345699541454 and parameters: {'learning_rate': 0.09083393980418532, 'reg_lambda': 0.5359686091781459, 'n_estimators': 1072, 'num_leaves': 11, 'bagging_freq': 3, 'min_child_samples': 7, 'subsample_freq': 8, 'colsample_bytree': 0.8885404992692112, 'subsample': 0.8990681339535826}. Best is trial 10 with value: 0.1270305153288948.\n",
      "[I 2024-04-06 14:21:34,246] Trial 14 finished with value: 0.12936211082779214 and parameters: {'learning_rate': 0.01222925262369218, 'reg_lambda': 0.0008566911246230507, 'n_estimators': 962, 'num_leaves': 9, 'bagging_freq': 1, 'min_child_samples': 27, 'subsample_freq': 0, 'colsample_bytree': 0.8855973197776448, 'subsample': 0.9938085227525937}. Best is trial 10 with value: 0.1270305153288948.\n",
      "[I 2024-04-06 14:21:36,813] Trial 15 finished with value: 0.22128954591892644 and parameters: {'learning_rate': 0.0011035504674108867, 'reg_lambda': 0.02823631407654004, 'n_estimators': 884, 'num_leaves': 14, 'bagging_freq': 3, 'min_child_samples': 33, 'subsample_freq': 4, 'colsample_bytree': 0.8976393263774768, 'subsample': 0.8863189315856712}. Best is trial 10 with value: 0.1270305153288948.\n",
      "[I 2024-04-06 14:21:38,207] Trial 16 finished with value: 0.12831555364880018 and parameters: {'learning_rate': 0.024092454194728535, 'reg_lambda': 0.0002201407638419047, 'n_estimators': 1147, 'num_leaves': 6, 'bagging_freq': 2, 'min_child_samples': 16, 'subsample_freq': 2, 'colsample_bytree': 0.9440984333493355, 'subsample': 0.6480103311270812}. Best is trial 10 with value: 0.1270305153288948.\n",
      "[I 2024-04-06 14:21:40,286] Trial 17 finished with value: 0.13283989006866864 and parameters: {'learning_rate': 0.006950542655509458, 'reg_lambda': 7.1366950243576905e-06, 'n_estimators': 796, 'num_leaves': 15, 'bagging_freq': 4, 'min_child_samples': 41, 'subsample_freq': 3, 'colsample_bytree': 0.7112886888566041, 'subsample': 0.9375916603449213}. Best is trial 10 with value: 0.1270305153288948.\n",
      "[I 2024-04-06 14:21:41,544] Trial 18 finished with value: 0.22517232944163754 and parameters: {'learning_rate': 0.0012467486491541506, 'reg_lambda': 0.007819820946714531, 'n_estimators': 1032, 'num_leaves': 4, 'bagging_freq': 2, 'min_child_samples': 16, 'subsample_freq': 5, 'colsample_bytree': 0.8407858928225022, 'subsample': 0.8456115505805439}. Best is trial 10 with value: 0.1270305153288948.\n",
      "[I 2024-04-06 14:21:43,635] Trial 19 finished with value: 0.13882554870625494 and parameters: {'learning_rate': 0.09868624732335152, 'reg_lambda': 6.241130264929374e-07, 'n_estimators': 1123, 'num_leaves': 8, 'bagging_freq': 3, 'min_child_samples': 61, 'subsample_freq': 0, 'colsample_bytree': 0.9258622176934123, 'subsample': 0.9406641790052696}. Best is trial 10 with value: 0.1270305153288948.\n",
      "[I 2024-04-06 14:21:45,412] Trial 20 finished with value: 0.1292879912028167 and parameters: {'learning_rate': 0.03105003665393774, 'reg_lambda': 0.00046113554853851945, 'n_estimators': 957, 'num_leaves': 12, 'bagging_freq': 4, 'min_child_samples': 7, 'subsample_freq': 2, 'colsample_bytree': 0.7116340407598434, 'subsample': 0.8509398495291233}. Best is trial 10 with value: 0.1270305153288948.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-06 14:21:47,448] Trial 21 finished with value: 0.12775640870844837 and parameters: {'learning_rate': 0.014764575885820641, 'reg_lambda': 0.0019849242115293976, 'n_estimators': 1072, 'num_leaves': 8, 'bagging_freq': 2, 'min_child_samples': 27, 'subsample_freq': 3, 'colsample_bytree': 0.9931936715253107, 'subsample': 0.8980935494872238}. Best is trial 10 with value: 0.1270305153288948.\n",
      "[I 2024-04-06 14:21:48,782] Trial 22 finished with value: 0.12950010888761415 and parameters: {'learning_rate': 0.017446301509077975, 'reg_lambda': 0.05580486731560558, 'n_estimators': 1038, 'num_leaves': 6, 'bagging_freq': 1, 'min_child_samples': 20, 'subsample_freq': 5, 'colsample_bytree': 0.994330239395611, 'subsample': 0.9989670494935069}. Best is trial 10 with value: 0.1270305153288948.\n",
      "[I 2024-04-06 14:21:50,794] Trial 23 finished with value: 0.1283753342620691 and parameters: {'learning_rate': 0.00907148698630641, 'reg_lambda': 0.002791819164872382, 'n_estimators': 1181, 'num_leaves': 7, 'bagging_freq': 2, 'min_child_samples': 31, 'subsample_freq': 3, 'colsample_bytree': 0.8650963361595613, 'subsample': 0.9412799536268738}. Best is trial 10 with value: 0.1270305153288948.\n",
      "[I 2024-04-06 14:21:51,856] Trial 24 finished with value: 0.12764821870451476 and parameters: {'learning_rate': 0.04861690134667396, 'reg_lambda': 2.2226873127600423e-05, 'n_estimators': 1077, 'num_leaves': 4, 'bagging_freq': 3, 'min_child_samples': 13, 'subsample_freq': 2, 'colsample_bytree': 0.9312503692953369, 'subsample': 0.9015512900097455}. Best is trial 10 with value: 0.1270305153288948.\n",
      "[I 2024-04-06 14:21:53,008] Trial 25 finished with value: 0.12657976796036413 and parameters: {'learning_rate': 0.052226551130774554, 'reg_lambda': 3.8990531711968316e-05, 'n_estimators': 1106, 'num_leaves': 4, 'bagging_freq': 3, 'min_child_samples': 12, 'subsample_freq': 1, 'colsample_bytree': 0.8282327226851848, 'subsample': 0.9566485616199342}. Best is trial 25 with value: 0.12657976796036413.\n",
      "[I 2024-04-06 14:21:56,319] Trial 26 finished with value: 0.13529960728287033 and parameters: {'learning_rate': 0.05873292986788488, 'reg_lambda': 0.00020303802042370242, 'n_estimators': 1119, 'num_leaves': 19, 'bagging_freq': 4, 'min_child_samples': 39, 'subsample_freq': 1, 'colsample_bytree': 0.8327248785284023, 'subsample': 0.9598617019532262}. Best is trial 25 with value: 0.12657976796036413.\n",
      "[I 2024-04-06 14:21:58,781] Trial 27 finished with value: 0.1298890087145146 and parameters: {'learning_rate': 0.006027223825608067, 'reg_lambda': 5.367748156692795e-07, 'n_estimators': 1017, 'num_leaves': 13, 'bagging_freq': 3, 'min_child_samples': 12, 'subsample_freq': 0, 'colsample_bytree': 0.8493407027409087, 'subsample': 0.8586453225386887}. Best is trial 25 with value: 0.12657976796036413.\n",
      "[I 2024-04-06 14:22:01,369] Trial 28 finished with value: 0.13030266473029223 and parameters: {'learning_rate': 0.023523539951028564, 'reg_lambda': 9.677285340385922e-05, 'n_estimators': 1109, 'num_leaves': 16, 'bagging_freq': 5, 'min_child_samples': 5, 'subsample_freq': 1, 'colsample_bytree': 0.7357713725324362, 'subsample': 0.9680192276440568}. Best is trial 25 with value: 0.12657976796036413.\n",
      "[I 2024-04-06 14:22:02,617] Trial 29 finished with value: 0.1300382178192208 and parameters: {'learning_rate': 0.04161497663065091, 'reg_lambda': 1.5627494429615767e-05, 'n_estimators': 958, 'num_leaves': 5, 'bagging_freq': 1, 'min_child_samples': 99, 'subsample_freq': 2, 'colsample_bytree': 0.9059303761801457, 'subsample': 0.820788548169286}. Best is trial 25 with value: 0.12657976796036413.\n",
      "[I 2024-04-06 14:22:04,855] Trial 30 finished with value: 0.36108201543737584 and parameters: {'learning_rate': 0.000110601009338887, 'reg_lambda': 1.5156416086237854e-06, 'n_estimators': 923, 'num_leaves': 10, 'bagging_freq': 4, 'min_child_samples': 23, 'subsample_freq': 0, 'colsample_bytree': 0.8176573694497019, 'subsample': 0.9176090512472123}. Best is trial 25 with value: 0.12657976796036413.\n",
      "[I 2024-04-06 14:22:06,038] Trial 31 finished with value: 0.12700854945321705 and parameters: {'learning_rate': 0.04982593342260308, 'reg_lambda': 1.5723451891772603e-05, 'n_estimators': 1167, 'num_leaves': 4, 'bagging_freq': 3, 'min_child_samples': 13, 'subsample_freq': 2, 'colsample_bytree': 0.9335057056481405, 'subsample': 0.9122172827998704}. Best is trial 25 with value: 0.12657976796036413.\n",
      "[I 2024-04-06 14:22:07,618] Trial 32 finished with value: 0.12854490931208715 and parameters: {'learning_rate': 0.03698015980728854, 'reg_lambda': 0.00013460495442804888, 'n_estimators': 1194, 'num_leaves': 6, 'bagging_freq': 3, 'min_child_samples': 12, 'subsample_freq': 1, 'colsample_bytree': 0.9558800589167658, 'subsample': 0.932122920061359}. Best is trial 25 with value: 0.12657976796036413.\n",
      "[I 2024-04-06 14:22:09,343] Trial 33 finished with value: 0.130353931119768 and parameters: {'learning_rate': 0.07270577333900742, 'reg_lambda': 5.322961618799297e-06, 'n_estimators': 1156, 'num_leaves': 7, 'bagging_freq': 2, 'min_child_samples': 20, 'subsample_freq': 2, 'colsample_bytree': 0.8657827043761159, 'subsample': 0.9709805646896846}. Best is trial 25 with value: 0.12657976796036413.\n",
      "[I 2024-04-06 14:22:10,291] Trial 34 finished with value: 0.12777184549753412 and parameters: {'learning_rate': 0.043611988745085276, 'reg_lambda': 0.00045280582818234456, 'n_estimators': 988, 'num_leaves': 4, 'bagging_freq': 7, 'min_child_samples': 13, 'subsample_freq': 2, 'colsample_bytree': 0.9190515469538936, 'subsample': 0.809459568070057}. Best is trial 25 with value: 0.12657976796036413.\n",
      "[I 2024-04-06 14:22:12,169] Trial 35 finished with value: 0.1275881772805967 and parameters: {'learning_rate': 0.019683204159059442, 'reg_lambda': 3.76710604423332e-05, 'n_estimators': 1105, 'num_leaves': 8, 'bagging_freq': 3, 'min_child_samples': 31, 'subsample_freq': 1, 'colsample_bytree': 0.5101339175594704, 'subsample': 0.8686915332185036}. Best is trial 25 with value: 0.12657976796036413.\n",
      "[I 2024-04-06 14:22:15,832] Trial 36 finished with value: 0.1331444493097694 and parameters: {'learning_rate': 0.003419698528202427, 'reg_lambda': 2.274524580046292e-06, 'n_estimators': 1159, 'num_leaves': 25, 'bagging_freq': 4, 'min_child_samples': 19, 'subsample_freq': 0, 'colsample_bytree': 0.9643590035987842, 'subsample': 0.7623199823228632}. Best is trial 25 with value: 0.12657976796036413.\n",
      "[I 2024-04-06 14:22:17,121] Trial 37 finished with value: 0.13466665990796417 and parameters: {'learning_rate': 0.00936447569561905, 'reg_lambda': 1.0684981460783751e-05, 'n_estimators': 1013, 'num_leaves': 5, 'bagging_freq': 1, 'min_child_samples': 58, 'subsample_freq': 1, 'colsample_bytree': 0.8156241287604288, 'subsample': 0.5982375785572971}. Best is trial 25 with value: 0.12657976796036413.\n",
      "[I 2024-04-06 14:22:19,573] Trial 38 finished with value: 0.1309153595291667 and parameters: {'learning_rate': 0.033900635629251864, 'reg_lambda': 5.296114281761827e-05, 'n_estimators': 1044, 'num_leaves': 18, 'bagging_freq': 2, 'min_child_samples': 9, 'subsample_freq': 4, 'colsample_bytree': 0.8743884578703714, 'subsample': 0.5034993769518704}. Best is trial 25 with value: 0.12657976796036413.\n",
      "[I 2024-04-06 14:22:22,201] Trial 39 finished with value: 0.160198582903443 and parameters: {'learning_rate': 0.0018218773149218913, 'reg_lambda': 0.0005861193335649565, 'n_estimators': 1196, 'num_leaves': 24, 'bagging_freq': 4, 'min_child_samples': 45, 'subsample_freq': 4, 'colsample_bytree': 0.765205937148487, 'subsample': 0.9742632014480189}. Best is trial 25 with value: 0.12657976796036413.\n",
      "[I 2024-04-06 14:22:23,967] Trial 40 finished with value: 0.13049388763865813 and parameters: {'learning_rate': 0.07420904308598503, 'reg_lambda': 0.008092783847011, 'n_estimators': 1098, 'num_leaves': 6, 'bagging_freq': 3, 'min_child_samples': 33, 'subsample_freq': 1, 'colsample_bytree': 0.9141737267301046, 'subsample': 0.9220443512684369}. Best is trial 25 with value: 0.12657976796036413.\n",
      "[I 2024-04-06 14:22:25,958] Trial 41 finished with value: 0.12687007539901266 and parameters: {'learning_rate': 0.02003583031886957, 'reg_lambda': 3.881620164335536e-05, 'n_estimators': 1137, 'num_leaves': 8, 'bagging_freq': 3, 'min_child_samples': 21, 'subsample_freq': 1, 'colsample_bytree': 0.5301742933227784, 'subsample': 0.8708489450994764}. Best is trial 25 with value: 0.12657976796036413.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-06 14:22:27,313] Trial 42 finished with value: 0.1283423803955424 and parameters: {'learning_rate': 0.051760177520479594, 'reg_lambda': 7.276422834650084e-05, 'n_estimators': 1140, 'num_leaves': 5, 'bagging_freq': 3, 'min_child_samples': 22, 'subsample_freq': 0, 'colsample_bytree': 0.6565289041889135, 'subsample': 0.8760972646675143}. Best is trial 25 with value: 0.12657976796036413.\n",
      "[I 2024-04-06 14:22:31,376] Trial 43 finished with value: 0.12736856760205137 and parameters: {'learning_rate': 0.011718808870426289, 'reg_lambda': 2.7096775136870017e-05, 'n_estimators': 1166, 'num_leaves': 22, 'bagging_freq': 2, 'min_child_samples': 15, 'subsample_freq': 2, 'colsample_bytree': 0.508799801224848, 'subsample': 0.9578331539987619}. Best is trial 25 with value: 0.12657976796036413.\n",
      "[I 2024-04-06 14:22:32,837] Trial 44 finished with value: 0.1314591829577632 and parameters: {'learning_rate': 0.023106637556503832, 'reg_lambda': 3.2221944286101394e-07, 'n_estimators': 1130, 'num_leaves': 7, 'bagging_freq': 3, 'min_child_samples': 70, 'subsample_freq': 3, 'colsample_bytree': 0.6156954753297643, 'subsample': 0.9149329495352865}. Best is trial 25 with value: 0.12657976796036413.\n",
      "[I 2024-04-06 14:22:34,898] Trial 45 finished with value: 0.13359553895191884 and parameters: {'learning_rate': 0.004390145900079916, 'reg_lambda': 2.77205834680243e-06, 'n_estimators': 1092, 'num_leaves': 9, 'bagging_freq': 2, 'min_child_samples': 9, 'subsample_freq': 1, 'colsample_bytree': 0.9695527807936086, 'subsample': 0.8416582582957107}. Best is trial 25 with value: 0.12657976796036413.\n",
      "[I 2024-04-06 14:22:35,713] Trial 46 finished with value: 0.128661596028898 and parameters: {'learning_rate': 0.029520442894144322, 'reg_lambda': 0.00015940931127306988, 'n_estimators': 679, 'num_leaves': 4, 'bagging_freq': 5, 'min_child_samples': 5, 'subsample_freq': 2, 'colsample_bytree': 0.5523796347562354, 'subsample': 0.7122250680556101}. Best is trial 25 with value: 0.12657976796036413.\n",
      "[I 2024-04-06 14:22:38,307] Trial 47 finished with value: 0.2978186457156305 and parameters: {'learning_rate': 0.00039595534076405215, 'reg_lambda': 0.00026790163621445587, 'n_estimators': 1060, 'num_leaves': 10, 'bagging_freq': 4, 'min_child_samples': 26, 'subsample_freq': 0, 'colsample_bytree': 0.9404979728231496, 'subsample': 0.9860315051441202}. Best is trial 25 with value: 0.12657976796036413.\n",
      "[I 2024-04-06 14:22:39,422] Trial 48 finished with value: 0.13099567271790424 and parameters: {'learning_rate': 0.007614042564319698, 'reg_lambda': 0.0011037697616392366, 'n_estimators': 873, 'num_leaves': 5, 'bagging_freq': 3, 'min_child_samples': 17, 'subsample_freq': 1, 'colsample_bytree': 0.804241012361847, 'subsample': 0.780733788078585}. Best is trial 25 with value: 0.12657976796036413.\n",
      "[I 2024-04-06 14:22:41,046] Trial 49 finished with value: 0.12828316746632665 and parameters: {'learning_rate': 0.01398754686893389, 'reg_lambda': 0.0060020833038682, 'n_estimators': 1173, 'num_leaves': 7, 'bagging_freq': 3, 'min_child_samples': 10, 'subsample_freq': 3, 'colsample_bytree': 0.9743296651353538, 'subsample': 0.9516430835199429}. Best is trial 25 with value: 0.12657976796036413.\n",
      "[I 2024-04-06 14:22:42,708] Trial 50 finished with value: 0.12849255350805147 and parameters: {'learning_rate': 0.02008030436452349, 'reg_lambda': 1.0262446933112321e-05, 'n_estimators': 804, 'num_leaves': 9, 'bagging_freq': 2, 'min_child_samples': 36, 'subsample_freq': 2, 'colsample_bytree': 0.9002268961607155, 'subsample': 0.9136134173635385}. Best is trial 25 with value: 0.12657976796036413.\n",
      "[I 2024-04-06 14:22:46,899] Trial 51 finished with value: 0.12760190909154567 and parameters: {'learning_rate': 0.011381893659058855, 'reg_lambda': 2.9215426067730648e-05, 'n_estimators': 1159, 'num_leaves': 23, 'bagging_freq': 2, 'min_child_samples': 16, 'subsample_freq': 2, 'colsample_bytree': 0.5076018123432865, 'subsample': 0.9547545250065516}. Best is trial 25 with value: 0.12657976796036413.\n",
      "[I 2024-04-06 14:22:50,806] Trial 52 finished with value: 0.12998011928836561 and parameters: {'learning_rate': 0.06446000299695173, 'reg_lambda': 2.062787466682642e-05, 'n_estimators': 1130, 'num_leaves': 23, 'bagging_freq': 1, 'min_child_samples': 14, 'subsample_freq': 1, 'colsample_bytree': 0.5464518562244195, 'subsample': 0.9792502688643883}. Best is trial 25 with value: 0.12657976796036413.\n",
      "[I 2024-04-06 14:22:53,820] Trial 53 finished with value: 0.12892201175328488 and parameters: {'learning_rate': 0.005429165623604647, 'reg_lambda': 7.781884767532118e-05, 'n_estimators': 1092, 'num_leaves': 27, 'bagging_freq': 2, 'min_child_samples': 24, 'subsample_freq': 3, 'colsample_bytree': 0.567020962788071, 'subsample': 0.8866876254097384}. Best is trial 25 with value: 0.12657976796036413.\n",
      "[I 2024-04-06 14:22:57,779] Trial 54 finished with value: 0.12938818635877486 and parameters: {'learning_rate': 0.017311625696680648, 'reg_lambda': 0.24584994751655936, 'n_estimators': 1199, 'num_leaves': 20, 'bagging_freq': 3, 'min_child_samples': 19, 'subsample_freq': 6, 'colsample_bytree': 0.526959787155312, 'subsample': 0.9996838671360131}. Best is trial 25 with value: 0.12657976796036413.\n",
      "[I 2024-04-06 14:23:01,158] Trial 55 finished with value: 0.12854767677406298 and parameters: {'learning_rate': 0.027683433106327086, 'reg_lambda': 1.019823862497156e-08, 'n_estimators': 1166, 'num_leaves': 21, 'bagging_freq': 2, 'min_child_samples': 10, 'subsample_freq': 2, 'colsample_bytree': 0.6175911970245084, 'subsample': 0.9343585276352662}. Best is trial 25 with value: 0.12657976796036413.\n",
      "[I 2024-04-06 14:23:04,631] Trial 56 finished with value: 0.12707484367068564 and parameters: {'learning_rate': 0.011838756325256926, 'reg_lambda': 5.050007466481769e-06, 'n_estimators': 1048, 'num_leaves': 30, 'bagging_freq': 3, 'min_child_samples': 28, 'subsample_freq': 0, 'colsample_bytree': 0.5818147853772625, 'subsample': 0.9563196778198212}. Best is trial 25 with value: 0.12657976796036413.\n",
      "[I 2024-04-06 14:23:05,666] Trial 57 finished with value: 0.12707747949223672 and parameters: {'learning_rate': 0.0369722205808246, 'reg_lambda': 1.3468831533723495e-06, 'n_estimators': 1055, 'num_leaves': 4, 'bagging_freq': 4, 'min_child_samples': 22, 'subsample_freq': 0, 'colsample_bytree': 0.6566570471119235, 'subsample': 0.9110537879727812}. Best is trial 25 with value: 0.12657976796036413.\n",
      "[I 2024-04-06 14:23:08,594] Trial 58 finished with value: 0.1337733886858922 and parameters: {'learning_rate': 0.08375590266435809, 'reg_lambda': 1.7371762938828435e-07, 'n_estimators': 1050, 'num_leaves': 30, 'bagging_freq': 5, 'min_child_samples': 29, 'subsample_freq': 0, 'colsample_bytree': 0.5720408329721125, 'subsample': 0.9052679172077975}. Best is trial 25 with value: 0.12657976796036413.\n",
      "[I 2024-04-06 14:23:10,865] Trial 59 finished with value: 0.12997597699903238 and parameters: {'learning_rate': 0.05101998542604464, 'reg_lambda': 7.743018065774566e-07, 'n_estimators': 1012, 'num_leaves': 12, 'bagging_freq': 4, 'min_child_samples': 22, 'subsample_freq': 0, 'colsample_bytree': 0.6663225674670349, 'subsample': 0.8731437125596568}. Best is trial 25 with value: 0.12657976796036413.\n",
      "[I 2024-04-06 14:23:12,128] Trial 60 finished with value: 0.1273120813751279 and parameters: {'learning_rate': 0.032014186200118054, 'reg_lambda': 3.793947569109518e-06, 'n_estimators': 991, 'num_leaves': 5, 'bagging_freq': 4, 'min_child_samples': 36, 'subsample_freq': 8, 'colsample_bytree': 0.6797087567661605, 'subsample': 0.8384466659053506}. Best is trial 25 with value: 0.12657976796036413.\n",
      "[I 2024-04-06 14:23:13,609] Trial 61 finished with value: 0.12734666458497387 and parameters: {'learning_rate': 0.04083757664409556, 'reg_lambda': 1.0202548788429772e-05, 'n_estimators': 1082, 'num_leaves': 4, 'bagging_freq': 3, 'min_child_samples': 18, 'subsample_freq': 0, 'colsample_bytree': 0.532030838957342, 'subsample': 0.9282715141037371}. Best is trial 25 with value: 0.12657976796036413.\n",
      "[I 2024-04-06 14:23:15,365] Trial 62 finished with value: 0.1267687828438635 and parameters: {'learning_rate': 0.014167636341828606, 'reg_lambda': 1.3615886692751554e-06, 'n_estimators': 1059, 'num_leaves': 6, 'bagging_freq': 3, 'min_child_samples': 8, 'subsample_freq': 0, 'colsample_bytree': 0.5810220318821702, 'subsample': 0.9460595377285856}. Best is trial 25 with value: 0.12657976796036413.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-06 14:23:17,038] Trial 63 finished with value: 0.12672237553645865 and parameters: {'learning_rate': 0.016679872191643057, 'reg_lambda': 1.0832115276618648e-06, 'n_estimators': 1035, 'num_leaves': 6, 'bagging_freq': 3, 'min_child_samples': 8, 'subsample_freq': 1, 'colsample_bytree': 0.5945358680550409, 'subsample': 0.9442747254709616}. Best is trial 25 with value: 0.12657976796036413.\n",
      "[I 2024-04-06 14:23:18,603] Trial 64 finished with value: 0.12947074949187837 and parameters: {'learning_rate': 0.007632647380323216, 'reg_lambda': 2.8180792422583147e-07, 'n_estimators': 1023, 'num_leaves': 6, 'bagging_freq': 3, 'min_child_samples': 5, 'subsample_freq': 1, 'colsample_bytree': 0.5940486075189773, 'subsample': 0.9424282021309835}. Best is trial 25 with value: 0.12657976796036413.\n",
      "[I 2024-04-06 14:23:20,373] Trial 65 finished with value: 0.12755957666170206 and parameters: {'learning_rate': 0.013517391924224553, 'reg_lambda': 8.098849736205568e-08, 'n_estimators': 1116, 'num_leaves': 8, 'bagging_freq': 3, 'min_child_samples': 8, 'subsample_freq': 1, 'colsample_bytree': 0.581795765052334, 'subsample': 0.9783828333014396}. Best is trial 25 with value: 0.12657976796036413.\n",
      "[I 2024-04-06 14:23:22,211] Trial 66 finished with value: 0.12752089962293178 and parameters: {'learning_rate': 0.01639434696401489, 'reg_lambda': 1.0961037588583835e-06, 'n_estimators': 976, 'num_leaves': 7, 'bagging_freq': 3, 'min_child_samples': 12, 'subsample_freq': 1, 'colsample_bytree': 0.6350350875897127, 'subsample': 0.9641825132505745}. Best is trial 25 with value: 0.12657976796036413.\n",
      "[I 2024-04-06 14:23:24,251] Trial 67 finished with value: 0.1514081248021799 and parameters: {'learning_rate': 0.0026188928051452593, 'reg_lambda': 5.689273916493908e-06, 'n_estimators': 1139, 'num_leaves': 6, 'bagging_freq': 3, 'min_child_samples': 15, 'subsample_freq': 1, 'colsample_bytree': 0.6008606334790444, 'subsample': 0.9460596061654194}. Best is trial 25 with value: 0.12657976796036413.\n",
      "[I 2024-04-06 14:23:25,999] Trial 68 finished with value: 0.13164576626038393 and parameters: {'learning_rate': 0.02338554637962032, 'reg_lambda': 2.934895324817322e-06, 'n_estimators': 1068, 'num_leaves': 11, 'bagging_freq': 3, 'min_child_samples': 76, 'subsample_freq': 3, 'colsample_bytree': 0.5358406237801129, 'subsample': 0.8916019492943638}. Best is trial 25 with value: 0.12657976796036413.\n",
      "[I 2024-04-06 14:23:27,156] Trial 69 finished with value: 0.12904055379173676 and parameters: {'learning_rate': 0.009945487826344095, 'reg_lambda': 1.4124991033898856e-05, 'n_estimators': 922, 'num_leaves': 5, 'bagging_freq': 4, 'min_child_samples': 11, 'subsample_freq': 0, 'colsample_bytree': 0.633270365778583, 'subsample': 0.9891166265247514}. Best is trial 25 with value: 0.12657976796036413.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate: 0.052226551130774554\n",
      "reg_lambda: 3.8990531711968316e-05\n",
      "n_estimators: 1106\n",
      "num_leaves: 4\n",
      "bagging_freq: 3\n",
      "min_child_samples: 12\n",
      "subsample_freq: 1\n",
      "colsample_bytree: 0.8282327226851848\n",
      "subsample: 0.9566485616199342\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=1 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=1 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000258 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3407\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 77\n",
      "[LightGBM] [Info] Start training from score 12.030658\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=1 will be ignored. Current value: bagging_freq=3\n",
      "result on hold-out set after HPO: 0.12973232038555924\n"
     ]
    }
   ],
   "source": [
    "import lightgbm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "import optuna\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "train = pd.read_csv('../data/train.csv', sep=\",\")\n",
    "categorical = [var for var in train.columns if train[var].dtype=='O']\n",
    "\n",
    "for cat_feat in categorical:\n",
    "    train[cat_feat] = train[cat_feat].astype('category')\n",
    "    \n",
    "y = train['SalePrice']\n",
    "X = train.drop('SalePrice', axis=1)\n",
    "y = np.log1p(y)\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "        train_test_split(X, y, random_state=42, test_size=0.2)\n",
    "\n",
    "def objective(trial):\n",
    "\n",
    "    x_tr, x_te, y_tr, y_te = \\\n",
    "        train_test_split(X_train, y_train, random_state=42, test_size=0.2)\n",
    "    \n",
    "    model = lightgbm.LGBMRegressor()\n",
    "\n",
    "    param = {\n",
    "        \"objective\": \"regression\",\n",
    "        \"metric\": \"'neg_mean_squared_error'\",\n",
    "        \"verbosity\": -1,\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-4, 0.1, log=True),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 1e-8, 1.0, log=True),\n",
    "        \"n_estimators\" : trial.suggest_int(\"n_estimators\", 600, 1200),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 4, 30),\n",
    "        \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 1, 7),\n",
    "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 100),\n",
    "        \"subsample_freq\": trial.suggest_int(\"subsample_freq\",0, 8),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\",0.5,1.0),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0)\n",
    "    }\n",
    "    model.set_params(**param)\n",
    "    clf = cross_val_score(\n",
    "    model,\n",
    "         x_tr, y_tr, scoring = 'neg_mean_squared_error'\n",
    "    )\n",
    "\n",
    "    return np.mean(np.sqrt(-clf))\n",
    "\n",
    "study = optuna.create_study()\n",
    "study.optimize(objective , n_trials =70)\n",
    "trial = study.best_trial\n",
    "model = lightgbm.LGBMRegressor()\n",
    "model.set_params(**trial.params)\n",
    "for k,v in trial.params.items():\n",
    "    print(f'{k}: {v}')\n",
    "model.fit(X_train, y_train)\n",
    "print(f'result on hold-out set after HPO: {np.sqrt(mean_squared_error(y_test, model.predict(X_test)))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946a3e1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:skopt]",
   "language": "python",
   "name": "conda-env-skopt-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
