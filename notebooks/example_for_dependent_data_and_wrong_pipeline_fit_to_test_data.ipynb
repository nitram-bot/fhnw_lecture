{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "68d84ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "pd.set_option('display.max_columns', 200)\n",
    "pd.set_option('display.width', 200)\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# Unblanaced dataset\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE, SMOTENC, SMOTEN, SVMSMOTE, BorderlineSMOTE, ADASYN\n",
    "\n",
    "# modeling utilities\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler, OrdinalEncoder\n",
    "from sklearn.experimental import enable_iterative_imputer # enables sklearn.impute.IterativeImputer\n",
    "from sklearn.impute import SimpleImputer, IterativeImputer\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.compose import make_column_transformer, ColumnTransformer\n",
    "\n",
    "# Additional models\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6470fedf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set:\n",
      "       age  workclass  final-weight     education  education-num marital-status      occupation   relationship   race     sex  capital-gain  capital-loss  hours-per-week native-country salary\n",
      "23855  42   State-gov  39239         Masters       14             Never-married  Prof-specialty  Not-in-family  White  Male    0             0             70              United-States  <=50K\n",
      "20950  38   Private    69306         Some-college  10             Divorced       Craft-repair    Unmarried      White  Female  0             0             40              United-States  <=50K\n",
      "160    68   ?          38317         1st-4th       2              Divorced       ?               Not-in-family  White  Female  0             0             20              United-States  <=50K\n",
      "Test set:\n",
      "       age  workclass  final-weight     education  education-num      marital-status       occupation   relationship   race     sex  capital-gain  capital-loss  hours-per-week native-country salary\n",
      "1028   27   Private    216479        Bachelors     13             Never-married       Sales            Not-in-family  White  Female  0             0             40              United-States  <=50K\n",
      "11479  26   Private    322585        HS-grad       9              Never-married       Sales            Own-child      White  Male    0             0             40              United-States  <=50K\n",
      "13284  42   Local-gov  720428        Some-college  10             Married-civ-spouse  Protective-serv  Husband        Black  Male    0             0             40              United-States  >50K \n"
     ]
    }
   ],
   "source": [
    "columns = [\"age\",\"workclass\" ,\"final-weight\",\"education\",\"education-num\",\"marital-status\",\"occupation\", \"relationship\", \"race\", \"sex\", \"capital-gain\",\n",
    "            \"capital-loss\", \"hours-per-week\", \"native-country\", \"salary\" ]\n",
    "\n",
    "# Reading datasets\n",
    "train_df = pd.read_csv('../data/adult.data', names=columns, header=None, skipinitialspace = True)\n",
    "test_df = pd.read_csv('../data/adult.test', names=columns, header=None, skipinitialspace = True)\n",
    "test_df[\"salary\"] = test_df[\"salary\"].apply(lambda x: x.replace('.', ''))\n",
    "\n",
    "print(\"Training set:\") #, train_df.columns)\n",
    "print(train_df.sample(frac=1).tail(3))\n",
    "\n",
    "print(\"Test set:\") #, test_df.columns)\n",
    "print(test_df.sample(frac=1).tail(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e030391b",
   "metadata": {},
   "outputs": [],
   "source": [
    "education_map = {'Preschool': \"elem_school\", '1st-4th':\"elem_school\",'5th-6th':\"elem_school\", \n",
    "                 \"mid_school\":'7th-8th', \n",
    "                 '9th':\"high_school_lower\",'10th':\"high_school_lower\", '11th':\"high_school_lower\", '12th':\"high_school_lower\",\n",
    "                 'HS-grad':\"high_school_upper\", 'Assoc-voc':\"high_school_upper\", 'Assoc-acdm':\"high_school_upper\", 'Some-college':\"high_school_upper\", \n",
    "                  'Bachelors':\"graduate\", 'Masters':'graduate', 'Prof-school':\"post_grad\", 'Doctorate':'post_grad'}\n",
    "train_df['education'] = train_df['education'].map(education_map)\n",
    "test_df['education'] = test_df['education'].map(education_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4d9d285f",
   "metadata": {},
   "outputs": [],
   "source": [
    "employed_map =  {'Self-emp-inc': \"self_employed_expert\", 'Self-emp-not-inc':\"self_employed\", 'Private':\"self_employed\", \n",
    "                 'Local-gov':\"public_servant\", 'State-gov':'public_servant','Federal-gov': 'public_servant',\n",
    "                 \"Withoug-pay\":\"unemployed\", 'Never-worked':'unemployed'}\n",
    "train_df['workclass'] = train_df['workclass'].map(employed_map)\n",
    "test_df['workclass'] = test_df['workclass'].map(employed_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "16580a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "occupation_map = {\"Prof-specialty\":\"executives\", \"Exec-managerial\":\"executives\", \n",
    "                  \"Protective-serv\":\"experts\", \"Tech-support\":\"experts\", \"Sales\":\"experts\", \"Craft-repair\":\"experts\", \"Transport-moving\":\"experts\",\n",
    "                  \"Adm-clerical\":\"technicians\", \"Machine-op-inspct\":\"technicians\", \"Farming-fishing\":\"technicians\", \"Armed-Forces\":\"technicians\",\n",
    "                  \"Priv-house-serv\":\"services\", \"Other-service\":\"services\", \"Handlers-cleaners\":\"services\"}\n",
    "train_df[\"occupation\"] = train_df[\"occupation\"].map(occupation_map)\n",
    "test_df[\"occupation\"] = test_df[\"occupation\"].map(occupation_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a31ef64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "marital_map = {'Married-civ-spouse':\"couple\",'Married-AF-spouse':\"couple\", \n",
    "               'Separated':\"single\",'Divorced':\"single\", 'Married-spouse-absent':\"single\", 'Widowed':\"single\", 'Never-married':\"single\"}\n",
    "train_df[\"marital-status\"] = train_df[\"marital-status\"].map(marital_map)\n",
    "test_df[\"marital-status\"] = test_df[\"marital-status\"].map(marital_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "96a7194e",
   "metadata": {},
   "outputs": [],
   "source": [
    "family_map = {\"Wife\":\"family_strong\", \"Husband\":\"family_strong\", \n",
    "              \"Other-relative\":\"family_weak\", \"Own-child\":\"family_weak\", \n",
    "              \"Unmarried\":\"family_none\", \"Not-in-family\":\"family_none\"}\n",
    "train_df[\"relationship\"] =  train_df[\"relationship\"].map(family_map)\n",
    "test_df[\"relationship\"] =  test_df[\"relationship\"].map(family_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d0968c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp_map = {\"France\":\"GDP_high\",  \"Ireland\":\"GDP_high\",  \"United-States\":\"GDP_high\",  \"Holand-Netherlands\":\"GDP_high\",  \"Canada\":\"GDP_high\",  \"Germany\":\"GDP_high\",  \"Hong\":\"GDP_high\",  \"England\":\"GDP_high\",  \"Japan\":\"GDP_high\",  \"Scotland\":\"GDP_high\", \n",
    "           \"Italy\":\"GDP_mid\",  \"South\":\"GDP_mid\",  \"Puerto-Rico\":\"GDP_mid\",  \"Taiwan\":\"GDP_mid\",  \"Portugal\":\"GDP_mid\", \"Greece\":\"GDP_mid\", \"Hungary\":\"GDP_mid\", \"Poland\":\"GDP_mid\", \"Trinadad&Tobago\":\"GDP_mid\", \"China\":\"GDP_mid\", \n",
    "           \"Mexico\":\"GDP_low\", \"Dominican-Republic\":\"GDP_low\", \"Thailand\":\"GDP_low\", \"Peru\":\"GDP_low\", \"Columbia\":\"GDP_low\", \n",
    "           \"Ecuador\":\"GDP_low\", \"Jamaica\":\"GDP_low\", \"Guatemala\":\"GDP_low\", \"El-Salvador\":\"GDP_low\", \"Vietnam\":\"GDP_low\", \"Philippines\":\"GDP_low\",\n",
    "           \"Laos\":\"GDP_low\", \"Honduras\":\"GDP_low\", \"India\":\"GDP_low\", \n",
    "           \"Nicaragua\":\"GDP_low\", \"Haiti\":\"GDP_low\", \"Cambodia\":\"GDP_low\", \"Iran\":\"GDP_low\", \"Yugoslavia\":\"GDP_low\", \n",
    "           \"Outlying-US(Guam-USVI-etc)\":\"GDP_low\", \"Cuba\":\"GDP_low\"}\n",
    "train_df[\"native-country\"] =  train_df[\"native-country\"].map(gdp_map)\n",
    "test_df[\"native-country\"] =  test_df[\"native-country\"].map(gdp_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e8d0ca29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "num_feats_stdscale = ['hours-per-week', 'capital-gain', 'capital-loss']\n",
    "ordinal_feats = ['education']\n",
    "education_rank = [[\"not_known\",\"elem_school\", \"mid_school\", \"high_school_lower\", \"high_school_upper\", \"graduate\", \"post_grad\"]]\n",
    "cat_feats_ohe = ['workclass', 'marital-status', 'occupation', 'relationship', 'native-country','race', 'sex']\n",
    "num_feats_min_max = ['age']\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', IterativeImputer()),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "ohe = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='not_known')),\n",
    "    ('ohe', OneHotEncoder(handle_unknown='ignore', sparse=False))\n",
    "])\n",
    "\n",
    "\n",
    "ordinal_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='not_known')),\n",
    "    ('ordinal', OrdinalEncoder(categories=education_rank, handle_unknown='use_encoded_value', unknown_value=-1))\n",
    "])\n",
    "\n",
    "min_max_transformer = MinMaxScaler()\n",
    "\n",
    "pipeline = Pipeline(steps =[ \n",
    "    ('columnT', ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, num_feats_stdscale),\n",
    "            ('cat', ohe, cat_feats_ohe),\n",
    "            ('ordinal', ordinal_transformer, ordinal_feats),\n",
    "            ('min_max_standardizer', min_max_transformer, num_feats_min_max)\n",
    "            ]))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e921d61c",
   "metadata": {},
   "source": [
    "### these are the two first mistakes:\n",
    "  - pipeline is fit on whole data and not in cross-validation framework on the training-folds only\n",
    "  - test data shouldl be just transformed with `pipeline.transform()` and not fitted again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c33bda11",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_train = pipeline.fit_transform(train_df.drop(\"salary\", axis=1))\n",
    "processed_test = pipeline.fit_transform(test_df.drop(\"salary\", axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251aab35",
   "metadata": {},
   "source": [
    "### here is the second mistake:\n",
    "  - up-sampline (`SMOTENC`) is applied to all data - not only the trainings-fold within the cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "485d8f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_feature_mask = train_df.drop(\"salary\", axis=1).dtypes == object\n",
    "\n",
    "smote = SMOTENC(categorical_features = categorical_feature_mask, sampling_strategy=\"minority\")\n",
    "X_balanced_train_df, y_balanced_train_df = smote.fit_resample(processed_train, train_df[\"salary\"])\n",
    "train_y = (y_balanced_train_df == '>50K')\n",
    "test_y = (test_df['salary'] == '>50k')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5fc40175",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "\n",
    "\n",
    "models_dict_list = [\n",
    "            {\"name\": \"Lgbm\", \"model\": LGBMClassifier(objective='binary', boosting_type='gbdt',\n",
    "                                                    ),                      # WORKS\n",
    "                    \"params\": {'n_estimators' : Integer(200,1000),\n",
    "                                'learning_rate': Real(1e-3, 0.1, prior='log-uniform'),\n",
    "                                \"subsample_freq\" : Integer(0, 4),\n",
    "                               \"num_leaves\": Integer(15,25),\n",
    "                                \"max_depth\": Integer(2, 10),\n",
    "                               \"subsample\": Real(0.7,1.0),\n",
    "                               \"colsample_bytree\": Real(0.4, 1.0),\n",
    "                              'min_child_samples':  Integer(2,20)\n",
    "                              } },            \n",
    "            {\"name\": \"LogisticReg\", \"model\": LogisticRegression(max_iter=500, solver = 'liblinear'), # WORKS\n",
    "                    \"params\": {'C': Real(1e-6, 1e+6, prior='log-uniform'), \n",
    "                               'penalty' : Categorical(['l1', 'l2']) } }\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bf788c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Running model: LgbmBest validation score:  0.882\n",
      "Best search parameters:  OrderedDict([('colsample_bytree', 0.5165616293938133), ('learning_rate', 0.06838141928599331), ('max_depth', 4), ('min_child_samples', 9), ('n_estimators', 655), ('num_leaves', 23), ('subsample', 0.908930436038046), ('subsample_freq', 4)])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.7/site-packages/sklearn/metrics/_ranking.py:951: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  UndefinedMetricWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Running model: LogisticRegBest validation score:  0.814\n",
      "Best search parameters:  OrderedDict([('C', 4704.313930677073), ('penalty', 'l2')])\n",
      "=== BEST MODEL RESULTS SUMMARY ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.7/site-packages/sklearn/metrics/_ranking.py:951: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  UndefinedMetricWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>AUC score</th>\n",
       "      <th>Best params</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogisticReg</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.620</td>\n",
       "      <td>0.766</td>\n",
       "      <td>0.620</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'C': 4704.313930677073, 'penalty': 'l2'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lgbm</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.569</td>\n",
       "      <td>0.725</td>\n",
       "      <td>0.569</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'colsample_bytree': 0.5165616293938133, 'learning_rate': 0.06838141928599331, 'max_depth': 4, 'min_child_samples': 9, 'n_estimators': 655, 'num_leaves': 23, 'subsample': 0.908930436038046, 'subsample_freq': 4}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             precision  recall  f1-score  accuracy  AUC score  \\\n",
       "Model                                                           \n",
       "LogisticReg  1.0        0.620   0.766     0.620    NaN          \n",
       "Lgbm         1.0        0.569   0.725     0.569    NaN          \n",
       "\n",
       "                                                                                                                                                                                                                    Best params  \n",
       "Model                                                                                                                                                                                                                            \n",
       "LogisticReg  {'C': 4704.313930677073, 'penalty': 'l2'}                                                                                                                                                                           \n",
       "Lgbm         {'colsample_bytree': 0.5165616293938133, 'learning_rate': 0.06838141928599331, 'max_depth': 4, 'min_child_samples': 9, 'n_estimators': 655, 'num_leaves': 23, 'subsample': 0.908930436038046, 'subsample_freq': 4}  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report, precision_recall_curve,  confusion_matrix, roc_curve, auc, precision_recall_fscore_support\n",
    "results_df = pd.DataFrame(columns=['Model', 'precision', 'recall', 'f1-score', 'accuracy', 'AUC score', 'Best params'])\n",
    "\n",
    "N_folds = 5\n",
    "\n",
    "for model_dict in models_dict_list:\n",
    "    \n",
    "    model_name = model_dict[\"name\"]    \n",
    "    if model_dict[\"params\"] == {}:\n",
    "        continue\n",
    "    \n",
    "    # Define search grid\n",
    "    search = BayesSearchCV(estimator = model_dict[\"model\"],\n",
    "                           search_spaces = model_dict[\"params\"],\n",
    "                           n_iter = 10,\n",
    "                           scoring = 'f1', # 'f1', f1_weighted', 'roc_auc', 'accuracy'\n",
    "                           n_jobs = 6, # change based on how many cpus available (8 for me)\n",
    "                           n_points = 6, # change based on how many cpus available (8 for me)\n",
    "                           cv = N_folds, # default: StratifiedKFold for binary labels\n",
    "                           refit = True,\n",
    "                           verbose = 0,\n",
    "                           error_score = 'raise', \n",
    "                           return_train_score  = True,        \n",
    "                            )\n",
    "    \n",
    "    # Training model\n",
    "    print(\"========== Running model: \"+model_name, end='')\n",
    "    _ = search.fit(X_balanced_train_df, train_y)\n",
    "    \n",
    "    # Print results\n",
    "    print(\"Best validation score: \", round(search.best_score_, 3))\n",
    "    print(\"Best search parameters: \", search.best_params_)\n",
    "    \n",
    "    best_model = search.best_estimator_\n",
    "    cv_results = search.cv_results_\n",
    "    \n",
    "    y_true = test_y.to_numpy()\n",
    "    y_pred = best_model.predict(processed_test) \n",
    "    # Evauate metrics for weighted support\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    P, R, F1, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
    "    \n",
    "    # Evaluate probabilities and auc_score\n",
    "\n",
    "    y_predict_proba = best_model.predict_proba(processed_test)[:,1]\n",
    "    \n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_predict_proba)    \n",
    "    auc_score = auc(fpr, tpr)\n",
    "    \n",
    "    # Store parameters\n",
    "    results_df.loc[len(results_df.index)] = [model_name, round(P, 3), round(R, 3),  round(F1, 3), round(accuracy, 3), round(auc_score, 3), search.best_params_]\n",
    "    \n",
    "print(\"=== BEST MODEL RESULTS SUMMARY ===\")\n",
    "results_df = results_df.set_index('Model')\n",
    "results_df.sort_values(\"f1-score\", inplace = True, ascending=False)\n",
    "results_df  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db2ffe0",
   "metadata": {},
   "source": [
    "### see the result: logistic regression is better than Light-GBM\n",
    "\n",
    "\n",
    "\n",
    "### next, the mistakes from above are not repeated:\n",
    "  - up-sampling (`SMOTENC`) is part of the pipeline right now - it gets trained on training folds and applied to hold-out fold\n",
    "  - the whole pipeline is fit within the cross-validation framework and applied to the hold-out set\n",
    "  - the same is true for the test set: just the `.predict()`-method of the pipeline is applied; not `.fit_transform()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e6034463",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dict_list = [\n",
    "            {\"name\": \"Lgbm\", \"model\": LGBMClassifier(objective='binary', boosting_type='gbdt',\n",
    "                                                    ),                      # WORKS\n",
    "                    \"params\": {'clf__n_estimators' : Integer(200,1000),\n",
    "                                'clf__learning_rate': Real(1e-3, 0.1, prior='log-uniform'),\n",
    "                                \"clf__subsample_freq\" : Integer(0, 4),\n",
    "                               \"clf__num_leaves\": Integer(15,25),\n",
    "                                \"clf__max_depth\": Integer(2, 10),\n",
    "                               \"clf__subsample\": Real(0.7,1.0),\n",
    "                               \"clf__colsample_bytree\": Real(0.4, 1.0),\n",
    "                              'clf__min_child_samples':  Integer(2,20)\n",
    "                              } },            \n",
    "            {\"name\": \"LogisticReg\", \"model\": LogisticRegression(max_iter=500, solver = 'liblinear'), # WORKS\n",
    "                    \"params\": {'clf__C': Real(1e-6, 1e+6, prior='log-uniform'), \n",
    "                               'clf__penalty' : Categorical(['l1', 'l2']) } }\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c545dd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines = []\n",
    "params = []\n",
    "names = []\n",
    "for m in models_dict_list:\n",
    "    pipelines.append(Pipeline(steps =[ \n",
    "    ('columnT', ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, num_feats_stdscale),\n",
    "            ('cat', ohe, cat_feats_ohe),\n",
    "            ('ordinal', ordinal_transformer, ordinal_feats),\n",
    "            ('min_max_standardizer', min_max_transformer, num_feats_min_max)\n",
    "            ])),\n",
    "    ('smotenc', SMOTENC(categorical_features=categorical_feature_mask, sampling_strategy=\"minority\")),\n",
    "    (\"clf\", m['model'])\n",
    "    ])\n",
    "                    )\n",
    "    params.append(m[\"params\"])\n",
    "    names.append(m[\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f018418e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Running model: LgbmBest validation score:  0.713\n",
      "Best search parameters:  OrderedDict([('clf__colsample_bytree', 0.43804816661770124), ('clf__learning_rate', 0.01931522132340677), ('clf__max_depth', 8), ('clf__min_child_samples', 14), ('clf__n_estimators', 711), ('clf__num_leaves', 23), ('clf__subsample', 0.8649509640467155), ('clf__subsample_freq', 0)])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.7/site-packages/sklearn/metrics/_ranking.py:951: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  UndefinedMetricWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Running model: LogisticRegBest validation score:  0.662\n",
      "Best search parameters:  OrderedDict([('clf__C', 50728.02008140517), ('clf__penalty', 'l1')])\n",
      "=== BEST MODEL RESULTS SUMMARY ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.7/site-packages/sklearn/metrics/_ranking.py:951: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  UndefinedMetricWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>AUC score</th>\n",
       "      <th>Best params</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Lgbm</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.696</td>\n",
       "      <td>0.821</td>\n",
       "      <td>0.696</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'clf__colsample_bytree': 0.43804816661770124, 'clf__learning_rate': 0.01931522132340677, 'clf__max_depth': 8, 'clf__min_child_samples': 14, 'clf__n_estimators': 711, 'clf__num_leaves': 23, 'clf__subsample': 0.8649509640467155, 'clf__subsample_freq': 0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticReg</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.621</td>\n",
       "      <td>0.766</td>\n",
       "      <td>0.621</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'clf__C': 50728.02008140517, 'clf__penalty': 'l1'}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             precision  recall  f1-score  accuracy  AUC score  \\\n",
       "Model                                                           \n",
       "Lgbm         1.0        0.696   0.821     0.696    NaN          \n",
       "LogisticReg  1.0        0.621   0.766     0.621    NaN          \n",
       "\n",
       "                                                                                                                                                                                                                                                               Best params  \n",
       "Model                                                                                                                                                                                                                                                                       \n",
       "Lgbm         {'clf__colsample_bytree': 0.43804816661770124, 'clf__learning_rate': 0.01931522132340677, 'clf__max_depth': 8, 'clf__min_child_samples': 14, 'clf__n_estimators': 711, 'clf__num_leaves': 23, 'clf__subsample': 0.8649509640467155, 'clf__subsample_freq': 0}  \n",
       "LogisticReg  {'clf__C': 50728.02008140517, 'clf__penalty': 'l1'}                                                                                                                                                                                                            "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "results_df = pd.DataFrame(columns=['Model', 'precision', 'recall', 'f1-score', 'accuracy', 'AUC score', 'Best params'])\n",
    "\n",
    "N_folds = 5\n",
    "\n",
    "for pipe, name, par in zip(pipelines, names, params):\n",
    "    \n",
    "    model_name = name\n",
    "    \n",
    "    # Define search grid\n",
    "    search = BayesSearchCV(estimator = pipe,\n",
    "                           search_spaces = par,\n",
    "                           n_iter = 10,\n",
    "                           scoring = 'f1', # 'f1', f1_weighted', 'roc_auc', 'accuracy'\n",
    "                           n_jobs = 6, # change based on how many cpus available (8 for me)\n",
    "                           n_points = 6, # change based on how many cpus available (8 for me)\n",
    "                           cv = N_folds, # default: StratifiedKFold for binary labels\n",
    "                           refit = True,\n",
    "                           verbose = 0,\n",
    "                           error_score = 'raise', \n",
    "                           return_train_score  = True,        \n",
    "                            )\n",
    "    \n",
    "    # Training model\n",
    "    print(\"========== Running model: \"+model_name, end='')\n",
    "    train_y = (train_df['salary'] == '>50K')\n",
    "    _ = search.fit(train_df.drop(\"salary\", axis=1), train_y)\n",
    "    \n",
    "    # Print results\n",
    "    print(\"Best validation score: \", round(search.best_score_, 3))\n",
    "    print(\"Best search parameters: \", search.best_params_)\n",
    "    \n",
    "    best_model = search.best_estimator_\n",
    "    cv_results = search.cv_results_\n",
    "    \n",
    "    y_true = test_y.to_numpy()\n",
    "    y_pred = best_model.predict(test_df.drop('salary', axis=1)) \n",
    "    # Evauate metrics for weighted support\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    P, R, F1, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
    "    \n",
    "    # Evaluate probabilities and auc_score\n",
    "\n",
    "    y_predict_proba = best_model.predict_proba(test_df.drop('salary', axis=1))[:,1]\n",
    "    \n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_predict_proba)    \n",
    "    auc_score = auc(fpr, tpr)\n",
    "    \n",
    "    # Store parameters\n",
    "    results_df.loc[len(results_df.index)] = [model_name, round(P, 3), round(R, 3),  round(F1, 3), round(accuracy, 3), round(auc_score, 3), search.best_params_]\n",
    "    \n",
    "print(\"=== BEST MODEL RESULTS SUMMARY ===\")\n",
    "results_df = results_df.set_index('Model')\n",
    "results_df.sort_values(\"f1-score\", inplace = True, ascending=False)\n",
    "results_df  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ecc61b0",
   "metadata": {},
   "source": [
    "### the order of the models is reversed right now"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:imbalanced]",
   "language": "python",
   "name": "conda-env-imbalanced-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
