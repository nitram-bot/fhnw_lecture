{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img alt=\"\" caption=\"taken from wikipedia\" onmouseover=\"[taken from here](https://en.wikipedia.org/wiki/DBSCAN)\"\n",
    "id=\"bayesian_optimization\" src=\"../images/sphx_glr_plot_cluster_comparison_0011.png\" width=\"720\" height=\"720\">\n",
    "\n",
    "[The image is taken from the sklearn site](https://scikit-learn.org/stable/modules/clustering.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spectral clustering\n",
    "Spectral clustering originates from Graph Theory (Spectral Analysis)\n",
    "The algorithms works as follows:\n",
    "1. a connectivity matrix / affinity matrix W is formed. This matrix is symmetric and is n x n, where n is the number of observations. If there is a link between observation i and observation j there is a 1 in the matrix at positions $W_{ij}$ and $W_{ji}$. Alternatively, for the affinity matrix, there is a similarity measure indicating the closeness of two observations.\n",
    "2. the degree matrix $D$ is formed. It is a diagonal matrix that contains for each observation the number of links (or sum of similarities) to other observations.\n",
    "3. the laplacian matrix $L$ is formed by $L = D -W$. This matrix has several interesting properties:\n",
    "  * the smallest eigenvalue is always 0. If all observations are connected (fully connected), there is exactly one eigenvalue that is 0.\n",
    "  * the corresponding eigenvector is constant.\n",
    "  * are there $r$ connected components (cluster) in the data and if observations are ordered accordingly, the laplacian has block diagonal form:\n",
    "      \n",
    "   $ L =\n",
    "     \\begin{bmatrix}\n",
    "       L_{1} & & \\\\\n",
    "       & \\ddots & \\\\\n",
    "       & & L_{r}\n",
    "     \\end{bmatrix}\n",
    "   $\n",
    "  * the blocks $L_i$ are proper laplacian matrices on their own. Since each component (cluster) is connected within, $L_i$ has exactly one eigenvalue that is 0. The corresponding eigenvector is constant and is zero for all other components. These eigenvectors hence are indicator vectors for their component. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Height')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# this simple example is taken from https://towardsdatascience.com/unsupervised-machine-learning-spectral-clustering-algorithm-implemented-from-scratch-in-python-205c87271045\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "X = np.array([\n",
    "    [1, 3], [2, 1], [1, 1],\n",
    "    [3, 2], [7, 8], [9, 8],\n",
    "    [9, 9], [8, 7], [13, 14],\n",
    "    [14, 14], [15, 16], [14, 15]\n",
    "])\n",
    "plt.scatter(X[:,0], X[:,1], alpha=0.7, edgecolors='b')\n",
    "plt.xlabel('Weight')\n",
    "plt.ylabel('Height')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we buid the connectivity matrix $W$ (also called adjacency matrix). We see, it has three connected components (clusters):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1 1 0 0 0 0 0 0 0 0]\n",
      " [1 1 1 1 0 0 0 0 0 0 0 0]\n",
      " [1 1 1 1 0 0 0 0 0 0 0 0]\n",
      " [1 1 1 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 1 1 1 0 0 0 0]\n",
      " [0 0 0 0 1 1 1 1 0 0 0 0]\n",
      " [0 0 0 0 1 1 1 1 0 0 0 0]\n",
      " [0 0 0 0 1 1 1 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 1 1 1]\n",
      " [0 0 0 0 0 0 0 0 1 1 1 1]\n",
      " [0 0 0 0 0 0 0 0 1 1 1 1]\n",
      " [0 0 0 0 0 0 0 0 1 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import pairwise_distances\n",
    "W = pairwise_distances(X, metric=\"euclidean\")\n",
    "vectorizer = np.vectorize(lambda x: 1 if x < 5 else 0)\n",
    "W = np.vectorize(vectorizer)(W)\n",
    "print(W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we buid the degree matrix $D$ and finally the laplacian as $L = D - W$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 4 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 4 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 4 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 4 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 4 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 4 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 4 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 4 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 4 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 4 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 4]]\n"
     ]
    }
   ],
   "source": [
    "#D = np.diag(np.reshape(W.dot(np.ones((W.shape[1], 1))), (W.shape[1],)))\n",
    "D = np.diag(W.sum(axis=1))\n",
    "print(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3 -1 -1 -1  0  0  0  0  0  0  0  0]\n",
      " [-1  3 -1 -1  0  0  0  0  0  0  0  0]\n",
      " [-1 -1  3 -1  0  0  0  0  0  0  0  0]\n",
      " [-1 -1 -1  3  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  3 -1 -1 -1  0  0  0  0]\n",
      " [ 0  0  0  0 -1  3 -1 -1  0  0  0  0]\n",
      " [ 0  0  0  0 -1 -1  3 -1  0  0  0  0]\n",
      " [ 0  0  0  0 -1 -1 -1  3  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  3 -1 -1 -1]\n",
      " [ 0  0  0  0  0  0  0  0 -1  3 -1 -1]\n",
      " [ 0  0  0  0  0  0  0  0 -1 -1  3 -1]\n",
      " [ 0  0  0  0  0  0  0  0 -1 -1 -1  3]]\n"
     ]
    }
   ],
   "source": [
    "L = D - W\n",
    "print(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'eigenvalues')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# eigenvalues and eigenvectors\n",
    "eigenvalues, eigenvectors = np.linalg.eig(L)\n",
    "\n",
    "# sort these based on the eigenvalues\n",
    "eigenvectors = eigenvectors[:,np.argsort(eigenvalues)]\n",
    "eigenvalues = eigenvalues[np.argsort(eigenvalues)]\n",
    "plt.scatter(np.arange(1, W.shape[1]+1), eigenvalues, alpha=0.7, edgecolors='b')\n",
    "plt.xlabel('sorted eigenvalues')\n",
    "plt.ylabel('eigenvalues')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corresponding eigenvectors\n",
      "[[-0.5  0.   0. ]\n",
      " [-0.5  0.   0. ]\n",
      " [-0.5  0.   0. ]\n",
      " [-0.5  0.   0. ]\n",
      " [ 0.  -0.5  0. ]\n",
      " [ 0.  -0.5  0. ]\n",
      " [ 0.  -0.5  0. ]\n",
      " [ 0.  -0.5  0. ]\n",
      " [ 0.   0.  -0.5]\n",
      " [ 0.   0.  -0.5]\n",
      " [ 0.   0.  -0.5]\n",
      " [ 0.   0.  -0.5]]\n"
     ]
    }
   ],
   "source": [
    "print('corresponding eigenvectors')\n",
    "print(eigenvectors[:, 0:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a somewhat contrieved example but it illustrates the principal idea. For data that is not as clear cut as our example the spectral embedding matrix (eigenvectors belonging to the $s$ smallest eigenvalues) can be clustered by k-means. Another possibility is to start with the embedding matrix as a indicator matrix and optimize it as to maximize the in-component connectivity (association) and minimize the between component connectivity (cuts)(see https://www1.icsi.berkeley.edu/~stellayu/publication/doc/2003kwayICCV.pdf). In the python sklearn library the last method is called 'discretize'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: 20 newsgroups\n",
    "\n",
    "We are going to demonstrate the virtues of spectral clustering on a text-clustering example. The data is a common dataset with nearly balanced classes. Hence, k-means should also be appropriate.\n",
    "\n",
    "<img alt=\"taken from homepage of 20 newsgroups\" caption=\"The different categories of the newsgroup posts\" id=\"20_newsgroups\" src=\"../images/20_newsgroups.png\">\n",
    "\n",
    "Here is one example:\n",
    "\n",
    "```text\n",
    "From: sigma@rahul.net (Kevin Martin)\n",
    "Subject: Re: Stay Away from MAG Innovision!!!\n",
    "Nntp-Posting-Host: bolero\n",
    "Organization: a2i network\n",
    "Lines: 10\n",
    "\n",
    "In <16BB58B33.D1SAR@VM1.CC.UAKRON.EDU> D1SAR@VM1.CC.UAKRON.EDU (Steve Rimar) writes:\n",
    ">My Mag MX15F works fine....................\n",
    "\n",
    "Mine was beautiful for a year and a half.  Then it went <foomp>.  I bought\n",
    "a ViewSonic 6FS instead.  Another great monitor, IMHO.\n",
    "\n",
    "-- \n",
    "Kevin Martin\n",
    "sigma@rahul.net\n",
    "\"I gotta get me another hat.\"\n",
    "```\n",
    "\n",
    "## Organization\n",
    "1. We build tf-idf vectors since we are following the bag-of-words approach\n",
    "2. For building the adjacency/connectivity/affinity matrix we have several possibilities. We will discuss the most relevant ones\n",
    "3. we compare different cluster solution and evaluate their results on the 20 different target labels of the newsgroup posts. For doing this, we introduce the the *adusted rand index*.\n",
    "4. Since we are always curious we verify if we could have guessed the right number of clusters from the eigenvalue criterion as discussed above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%reload_ext autoreload\n",
    "#%autoreload 2\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "from sklearn.cluster import SpectralClustering\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "import nmslib\n",
    "dataset = fetch_20newsgroups(subset='all', shuffle=True, download_if_missing=True)\n",
    "# http://qwone.com/~jason/20Newsgroups/\n",
    "\n",
    "np.random.seed(123)\n",
    "texts = dataset.data # Extract text\n",
    "target = dataset.target # Extract target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tf-idf\n",
    "refresher:\n",
    "\n",
    "$w_{i,j} = \\text{tf}_{i,j} \\cdot \\log\\frac{N}{\\text{df}_i}$  \n",
    "with  \n",
    "$\\text{tf}_{i,j}$ is the frequency of term i in document j  \n",
    "$\\text{df}_i$ is the number of documents containing term i  \n",
    "\n",
    "Since we want to cluster newsgroup posts we are more interested in words that are nearly unique to certain groups. By setting max_df = 0.3 we ensure that only words are considered that are not too common, i.e. only in 30% of all posts. By contrast, words that are very seldom but are concerned with special topics discussed in the groups are most important for our endeavor. Hence, there is no limit for min_df.  \n",
    "We tell the vectorizer to remove common english stop words.  \n",
    "By default the vectors returned are normed, i.e. they all have length 1. This is important when we compute the cosine similarity between the vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# norm='l2' is default\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_df = 0.3)\n",
    "X = vectorizer.fit_transform(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18846, 173438\n"
     ]
    }
   ],
   "source": [
    "print(f'{X.shape[0]}, {X.shape[1]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connectivity / adjacency / affinity matrix\n",
    "We have several possibilities to express the similarity / connectedness between observations. Some of common ones:  \n",
    "1. The $\\epsilon$ neighborhood graph: all observations whose pairwise distance is less than $\\epsilon$ are connected. (This was used in our contrieved example)\n",
    "2. k-nearest neighborhood graph: for every observation, the k-nearest neighbors get connected. Since the nearest neighbors relationsship is not symmetric, we have to adjust the resulting adjacency matrix: $W_{symm} = 0.5 \\cdot W + W^{T}$ \n",
    "3. fully connected graph: all observations are connected with weights equal to the respective similarity. Possible choices here are\n",
    "  * the gaussian kernel: $\\exp^{-(x_i - x_j)^2/(2\\sigma^2)}$; In sklearn the term $1/(2\\sigma^2) = \\gamma$; the gaussian kernel is also called radial basis function kernel (rbf) or euclidean kernel. For identical vectors $\\exp^{0} = 1$; For dissimilar vectors the term assymptotically approaches 0.\n",
    "  * the cosine kernel: $\\frac{x_i \\cdot x_j^T}{||x_i|| ||x_j||}$; here $||x_i||$ is the norm (length) of vector $x_i$, normalizing the vector to length 1. When the vectors are already normalized, the cosine similarity simplifies to $x_i \\cdot x_j^T$. This is the linear kernel. The cosine measures the angle between two vectors. For identical vectors, the cosine is 1, for orthogonal vectors it is 0.\n",
    "  \n",
    "# our choice\n",
    "Since we deal with very long and sparse vectors, euclidean distance is not a good choice. This has to do with the *curse of dimensionality* (search for it). Typically, for these long tf-idf vectors cosine similarity is used. For bigger data sets, I can not see any reason why we should compute the similarities for all points in the set. Probably, it is sufficient to consider only th $k$ nearest neighbors of each point. This allows us to use sparse matrices, that are far more memory efficient. The sklearn spectral clustering implementation can deal with those matrices. As we will see, this simplification further reduces noise in the data and encourages better overall solutions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approximate nearest neighbors\n",
    "Computing all mutual distances between the 18846 posts can be very time and memory consuming. Theoretically, we only have to compute the triangular matrix minus the diagonal (distance matrices are symmetrical):\n",
    "$0.5 \\cdot 18846^2 - 18846/2 = 177576435$ mutual distances. A clever idea here, is to compute only the k nearest neighbors of each post and treat all other posts as maximal distant. There are a lot of algorithms around for computing nearest neighbors, the most efficient relying on kd-trees.\n",
    "However, there are also approximate nearest neighbor algorithms that are nearly 100% accurate and are even faster than kd-trees. One of those is the hnsw-algorithm as implemented in the python nmslib (an api for the underlying c++ code)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see discussions about 'curse of dimensionality'; to be safe, we opt for cosine-similarity\n",
    "# since we want to be most efficient in everything we do, we use sparse matrices and vectors\n",
    "index = nmslib.init(method='hnsw', space='cosinesimil_sparse', data_type=nmslib.DataType.SPARSE_VECTOR)\n",
    "index.addDataPointBatch(X)\n",
    "index_time_params = {'post':2}\n",
    "index.createIndex(index_time_params, print_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we can query the index\n",
    "# By computing distances for the k=1000 neares neighbors, we have to store 1000 * 18846 = 18846000\n",
    "# distances; but compared to the triangular matrix approach discussed above, we still save 158730435\n",
    "# entries in our matrix.\n",
    "\n",
    "nn = 1000\n",
    "neighbors = index.knnQueryBatch(X, k=nn, num_threads=4)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we build our affinity matrix. Sparse matrices only store the indices and the data for entries in the matrix that acutally contain data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csc_matrix\n",
    "# next we construct a sparse matrix with the distances as measured by cosine similarity\n",
    "col = np.array([i for n in neighbors for i in n[0].tolist()]) # column indices of nearest neighbors\n",
    "row = np.repeat(np.arange(0, len(neighbors)), np.array([len(n[0]) for n in neighbors])) # the row index for each nearest neighbor\n",
    "data = np.array([i for n in neighbors for i in n[1].tolist()]) # the similarities\n",
    "\n",
    "# btw, if you do not understand what's going on in the list part of the construction of the col and\n",
    "# the data variable above, I stronly recommend to have a look at *list comprehension*; \n",
    "# list comprehension is a super fast way to get things done in python\n",
    "\n",
    "affinity = csc_matrix((data, (row, col)), shape = (X.shape[0], X.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4733438586041509"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n_clusters = 20 because we know, that there are 20 different newsgroups\n",
    "# n_components = 21; this is cheated because it should normally be set to the same number as\n",
    "#                the n_clusters, but 21 yielded a better solution\n",
    "# assign_labels = 'discretize' defines how the clusters are found within the \n",
    "#                 embedding matrix (matrix composed of eigenvectors belonging to the n_components \n",
    "#                 smallest eigenvalues). As discussed above, 'discretize' maximizes the \n",
    "#                 in-component connectivity and minimizes the between-component connectivity\n",
    "# affinity = 'precomputed' indicates that the affinity matrix is provided by the user\n",
    "# eigen_solver = 'amg' assumes the python-package pyamg is installed. It is by far the fastest\n",
    "#                way the eigenvalue decomposition                \n",
    "#\n",
    "solution = SpectralClustering(n_clusters = 20, n_components = 21, assign_labels='discretize',\\\n",
    "                              affinity = 'precomputed',\\\n",
    "                              eigen_solver='amg').fit(0.5 * (affinity + affinity.T))\n",
    "metrics.adjusted_rand_score(solution.labels_, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, let's see what our nearest-neighbor trick was good for. In the next cell we compute the spectral clustering for the whole tf-idf matrix and leave it to sklearn to compute all cosine similarities. As discussed above, since the tf-idf vectors are by default normalized, we can use the 'linear' kernel instead of the 'cosine' kernel. This is faster because the additional steps of getting the norms and dividing is not needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27790619703942143"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# linear kernel instead of cosine_similarity if tf-idf vectors are already normalized\n",
    "solution = SpectralClustering(n_clusters=20, n_components = 21, assign_labels='discretize',\\\n",
    "                              affinity='linear',eigen_solver='amg').fit(X)\n",
    "metrics.adjusted_rand_score(solution.labels_, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What would the solution be like if we would have used ordinary euclidean distance (=rbf kernel=gaussian kerne)?\n",
    "gamma ($\\gamma = \\frac{1}{2\\sigma^2}$) defines the size of the neighborhood and is similar to the choice of the parameter $k$ in the approx. k-nearest neighbor algorithm we used in the construction of our affinity matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1732514953135886"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solution = SpectralClustering(n_clusters=20, n_components = 21, assign_labels='discretize',\\\n",
    "                              affinity='rbf',eigen_solver='amg',\\\n",
    "                              gamma = 0.7).fit(X)\n",
    "metrics.adjusted_rand_score(solution.labels_, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How is ordinary k-means performing? Clustering is done on the tf-idf vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08430170579222211"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solutionKMeans = KMeans(n_clusters=20, init='k-means++', max_iter=100, n_init=1).fit(X)\n",
    "metrics.adjusted_rand_score(solutionKMeans.labels_, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Could we have guessed the right number of clusters from the eigenvalues of the laplacian as suggested in all tutorials about spectral clustering?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAY+ElEQVR4nO3dfZAc9X3n8feHRSILCwhHzhashKUkiu5UyImsPcBFHnb9JInzIcUmOakwMY6xKleR71LGqkiFC7uIU35QkeTuTMIpCYXxOayxrSgqo2TtsrVx4hgCsjDLg9csD5doRZANFmZhYyTxvT+mF0bLPE/PTE/v51U1tTPdv+n+TK/02d7umW1FBGZm1v1O63QAMzNLhwvdzCwnXOhmZjnhQjczywkXuplZTpzeqRUvXrw4li1b1tBzX3jhBc4666x0A6Us6xmzng+yn9H5mpf1jFnMd/DgwR9GxOtLzoyIjtzWrl0bjTpw4EDDz22XrGfMer6I7Gd0vuZlPWMW8wH3RZle9SEXM7OccKGbmeWEC93MLCdc6GZmOeFCNzPLCRe6mVlOuNDNzHKiYx8sMjObb/YemmLX6ARHjs1wwaJetq9byaY1A6kt34VuZtYGew9NsXPPODPHTwIwdWyGnXvGAVIrdR9yMTNrg12jE6+U+ayZ4yfZNTqR2jpc6GZmbXDk2Exd0xvhQjcza4MLFvXWNb0RLnQzszbYvm4lvQt6TpnWu6CH7etWpraOqoUu6VZJRyU9WGXcf5J0UtKVqaUzM8uJTWsG+MS7VjOwqBcBA4t6+cS7Vrf9XS63AZ8Bbi83QFIP8ClgNJ1YZmb5s2nNQKoFPlfVPfSI+CbwbJVhHwS+DBxNI5SZmdWv6WPokgaAXwduaT6OmZk1SoULYFQZJC0DvhIRF5WY90Xgpoi4W9JtybgvlVnOVmArQH9//9qRkZGGQk9PT9PX19fQc9sl6xmzng+yn9H5mpf1jFnMNzw8fDAiBkvOLHcpo+IbsAx4sMy8J4Ank9s0hcMum6ot05eg66ys54vIfkbna17WM2YxHxUuQdf0R/8jYvns/aI99L3NLtfMzOpTtdAl3QEMAYslHQY+CiwAiAgfNzczy4iqhR4RW2pdWERc01QaMzNrmD8pamaWEy50M7OccKGbmeWEC93MLCdc6GZmOeFCNzPLCRe6mVlO+CLRZmZtsvfQFLtGJzhybIYLFvWyfd3Ktv89dDMza9LeQ1Ps3DP+yoWip47NsHPPOEBqpe5DLmZmbbBrdOKVMp81c/wku0YnUluHC93MrA2OHJupa3ojXOhmZm1wwaLeuqY3woVuZtYG29etpHdBzynTehf0sH3dytTW4UI3M2uDTWsGePfaAXokAHok3r023YtGu9DNzNpg76EpvnxwipPJZT9PRvDlg1PsPTSV2jpc6GZmbeB3uZiZ5cRUmXezlJveiKqFLulWSUclPVhm/lWSHkhu/yTpF1NLZ2ZmNatlD/02YH2F+U8AvxYRbwT+ANidQi4zM6tTLdcU/aakZRXm/1PRw7uBJc3HMjOzeimSM64VBxUK/SsRcVGVcR8G/kNEXFtm/lZgK0B/f//akZGRevMCMD09TV9fX0PPbZesZ8x6Psh+RudrXtYzpplvfOq5svNWD5xb83KGh4cPRsRgqXmp/XEuScPA+4FfLjcmInaTHJIZHByMoaGhhtY1NjZGo89tl6xnzHo+yH5G52te1jOmme+aHXeVnffkVemsI5VCl/RG4C+ADRHxTBrLNDOz+jT9tkVJFwJ7gKsj4vvNRzIzs0ZU3UOXdAcwBCyWdBj4KLAAICJuAW4Afhr4UxU+0nqi3PEdM7P56I0f/bu2rKeWd7lsqTL/WqDkSVAzM4Mf/+Rk9UEp8CdFzcxywoVuZtZCyyq8uyVtLnQzsxappczfc+mFqa3PF4k2M0tZPXvlH9+0OrX1utDNzFLSzsMrpbjQzcya0OkSL+ZCNzOrUdrl/eQn/3Oqy3Ohm5nN8fY/GuPRoy9w3eoTFf8GSzPSLnNwoZvZPNXJQyWtKHNwoZtZznxk7zj/9+5/6XSMslpV5uBCN7MukKUTj41qZZHPcqGbWVuUKuVWHqPOinYU+SwXuplVlYc95Ha57Odex+c/8OaOrNuFbpZDy3bcNS/2frOgnXvg1bjQzTrIe77dI0vFXY4L3ayCSoXrPeD8mVvaY2NjqV3vsx1quWLRrcA7gaMRcVGJ+QL+J3A58CJwTUR8J+2gZqV4D9dq0Q1712moZQ/9NuAzwO1l5m8AViS3S4A/S76aAY2XrveArZyf6hHf+8PLOx0jc2q5BN03JS2rMGQjcHtEBHC3pEWSzo+Ip1LKaG3kPV5rp9UD53bVIY2sU6GHqwwqFPpXyhxy+QrwyYj4x+Tx14Hfj4j7SozdCmwF6O/vXzsyMtJQ6Onpafr6+hp6bru0O+OxmeP867Mv1jy+vxeenmlhoBRkPeN8z7d64Nyml5H1/8tZzDc8PHwwIgZLzUvjpKhKTCv5UyIidgO7AQYHB2NoaKihFY6NjdHoc9ul0YzN7SHX/u28bvUJbhrP9jnxrGfstnxZPI6c9f/LWc83Vxr/Gg8DS4seLwGOpLDcXPAhDKtXWsXbbe/QsOalUej7gG2SRiicDH1uvhw/91va5qfZwnVhWtbU8rbFO4AhYLGkw8BHgQUAEXELsJ/CWxYnKbxt8X2tCttu3rvuPn73g81ntbzLZUuV+QH8bmqJOsTl3T61/q0L7wGb1Se7Z3RazAVeuyyeTDOz15pXhT7fSrxSEXvv1yx/cl/oeShx7yGbWS1yW+hZLnIXtJm1Qi4LvVNl3n/2Qu65/u2AD2mYWfvlqtCv+vNv863Hnm3pOrx3bWZZlZtC//mdd3Gi+p+lqYvL28y6SS4K/ZI//FrTZX66YPITLnAz6165KPSnn3+poed5D9zM8qTrC72RE6AucjPLo64u9HrL3EVuZnl2WqcDtIvL3Mzyrmv30GvdO3eRm9l8kes99D/5r7/U6QhmZm3TlYU+PvVcTeM2rRlocRIzs+zoykKvhQ+1mNl8U1OhS1ovaULSpKQdJeZfKOmApEOSHpDU0UvGvOfSCzu5ejOzjqha6JJ6gJuBDcAqYIukVXOGfQS4MyLWAJuBP0076KxaToZ+fNPqVq3ezCyzatlDvxiYjIjHI+IlYATYOGdMAOck988FjqQXsT7nnNHTqVWbmXWUCpcErTBAuhJYHxHXJo+vBi6JiG1FY84HvgqcB5wFvC0iDpZY1lZgK0B/f//akZGRugOPTz1Hfy88PVN6/uqBc+teZitMT0/T19fX6RhlZT0fZD+j8zUv6xmzmG94ePhgRAyWmlfL+9BVYtrcnwJbgNsi4iZJbwY+J+miiHj5lCdF7AZ2AwwODsbQ0FANqz/VNTvu4rrVJ7hpvHT0rPwN8rGxMRp5fe2S9XyQ/YzO17ysZ8x6vrlqOeRyGFha9HgJrz2k8n7gToCI+DbwU8DiNALWo//she1epZlZZtRS6PcCKyQtl7SQwknPfXPG/AvwVgBJ/5FCof8gzaBQuIBFJbNXCzIzm4+qFnpEnAC2AaPAIxTezfKQpBslXZEMuw74gKTvAncA10S1g/MNaPXViMzMullNf8slIvYD++dMu6Ho/sPAZelGMzOzeuT2k6JmZvNNbgrdJ0TNbL7LTaH7hKiZzXe5KXQzs/nOhW5mlhMudDOznHChm5nlhAvdzCwnXOhmZjnhQjczywkXuplZTrjQzcxywoVuZpYTLnQzs5xwoZuZ5YQL3cwsJ2oqdEnrJU1ImpS0o8yY35T0sKSHJP1VujHNzKyaqlcsktQD3Ay8ncIFo++VtC+5StHsmBXATuCyiPiRpJ9pVWAzMyutlj30i4HJiHg8Il4CRoCNc8Z8ALg5In4EEBFH041ZcOaC0nHLTTczm09U7VrOkq4E1kfEtcnjq4FLImJb0Zi9wPcpXFe0B/hYRPxdiWVtBbYC9Pf3rx0ZGakr7MNP/ZiTLwf9vfD0zKvTe04Tq84/p65ltdr09DR9fX2djlFW1vNB9jM6X/OynjGL+YaHhw9GxGCpebVcJFolps39KXA6sAIYApYA/yDpoog4dsqTInYDuwEGBwdjaGiohtW/6n077iKA61af4KbxV6MLeGJLfctqtbGxMep9fe2U9XyQ/YzO17ysZ8x6vrlqOVZxGFha9HgJcKTEmL+JiOMR8QQwQaHgU3Xmwp66ppuZzSe1FPq9wApJyyUtBDYD++aM2QsMA0haDPwC8HiaQQFeeOlkXdPNzOaTqoUeESeAbcAo8AhwZ0Q8JOlGSVckw0aBZyQ9DBwAtkfEM60KbWZmr1XLMXQiYj+wf860G4ruB/Ch5GZmZh3g9/uZmeWEC93MLCe6qtBPK/UGSqBHZWaYmc0jXVPoew9N8XKZz0CdrPLhKDOz+aBrCn3X6ETZeQOLetuYxMwsm7qm0I8cmyk7b/u6lW1MYmaWTV1T6IvOXFBy+pkLTmPTmoE2pzEzy56uKfSfHPenQc3MKumaQn/x+Mt1TTczm2+6ptDNzKyyrin0Rb2lj6GXm25mNt90TaG/8xfPr2u6mdl80zWFfuB7P6hrupnZfNM1hV7ufeiV3p9uZjafdE2hX1Dm06DlppuZzTddU+jb162kd8Gpl5rrXdDjT4mamSVqusBFFsx+GrTwN12eZ2BRL9vXrfSnRM3MEjXtoUtaL2lC0qSkHRXGXSkpJA2mF/FVm9YM8K0db2H1wLl8a8dbXOZmZkWqFrqkHuBmYAOwCtgiaVWJcWcD/x24J+2QZmZWXS176BcDkxHxeES8BIwAG0uM+wPg08C/p5jPzMxqpKhycQhJVwLrI+La5PHVwCURsa1ozBrgIxHxbkljwIcj4r4Sy9oKbAXo7+9fOzIy0lDo6elp+vr6Gnpuu2Q9Y9bzQfYzOl/zsp4xi/mGh4cPRkTJw9q1nBQtdX23V34KSDoN+GPgmmoLiojdwG6AwcHBGBoaqmH1r9p7aIpdoxNsXnqSkQdfzvRJ0bGxMep9fe2U9XyQ/YzO17ysZ8x6vrlqOeRyGFha9HgJcKTo8dnARcCYpCeBS4F9aZ8Y3Xtoip17xplKPkg0dWyGnXvG2XtoKs3VmJl1rVoK/V5ghaTlkhYCm4F9szMj4rmIWBwRyyJiGXA3cEWpQy7N2DU6wcycv4k+c/xkxUvTmZnNJ1ULPSJOANuAUeAR4M6IeEjSjZKuaHXAWf7ov5lZZTV9sCgi9gP750y7oczYoeZjvdYFi3pfOdwyd7qZmfmj/2ZmueGP/puZ5UTXFDoUSn3TmgHGxsb44FVDnY5jZpYpXXPIxczMKnOhm5nlhAvdzCwnXOhmZjnhQjczywkXuplZTrjQzcxywoVuZpYTLnQzs5xwoZuZ5YQL3cwsJ1zoZmY54UI3M8uJmgpd0npJE5ImJe0oMf9Dkh6W9ICkr0t6Q/pRzcyskqqFLqkHuBnYAKwCtkhaNWfYIWAwIt4IfAn4dNpBzcysslr20C8GJiPi8Yh4CRgBNhYPiIgDEfFi8vBuYEm6Mc3MrBpFROUB0pXA+oi4Nnl8NXBJRGwrM/4zwL9FxMdLzNsKbAXo7+9fOzIy0lDo6elp+vr6Gnpuu2Q9Y9bzQfYzOl/zsp4xi/mGh4cPRsRgyZkRUfEG/AbwF0WPrwb+d5mx76Gwh35GteWuXbs2GnXgwIGGn9suWc+Y9XwR2c/ofM3LesYs5gPuizK9Wssl6A4DS4seLwGOzB0k6W3A9cCvRcRPav1pY2Zm6ajlGPq9wApJyyUtBDYD+4oHSFoD/B/giog4mn5MMzOrpmqhR8QJYBswCjwC3BkRD0m6UdIVybBdQB/wRUn3S9pXZnFmZtYitRxyISL2A/vnTLuh6P7bUs5lZmZ18idFzcxywoVuZpYTLnQzs5xwoZuZ5YQL3cwsJ1zoZmY54UI3M8sJF7qZWU640M3McsKFbmaWEy50M7OccKGbmeWEC93MLCdc6GZmOeFCNzPLCRe6mVlO1FToktZLmpA0KWlHiflnSPpCMv8eScvSDmpmZpVVLXRJPcDNwAZgFbBF0qo5w94P/Cgifh74Y+BTaQc1M7PKatlDvxiYjIjHI+IlYATYOGfMRuCzyf0vAW+VpPRimplZNYqIygOkK4H1EXFt8vhq4JKI2FY05sFkzOHk8WPJmB/OWdZWYCtAf3//2pGRkYZCT09P09fX19Bz2yXrGbOeD7Kf0fmal/WMWcw3PDx8MCIGS82r5SLRpfa05/4UqGUMEbEb2A0wODgYQ0NDNaz+tcbGxmj0ue2S9YxZzwfZz+h8zct6xqznm6uWQy6HgaVFj5cAR8qNkXQ6cC7wbBoBzcysNrUU+r3ACknLJS0ENgP75ozZB7w3uX8l8I2odizHzMxSVfWQS0SckLQNGAV6gFsj4iFJNwL3RcQ+4C+Bz0mapLBnvrmVoc3M7LVqOYZOROwH9s+ZdkPR/X8HfiPdaGZmVg9/UtTMLCdc6GZmOdFVhb730BSXffIbjE89x2Wf/AZ7D011OpKZWWbUdAw9C/YemmLnnnFmjp+EpTB1bIade8YB2LRmoMPpzMw6r2v20HeNThTKvMjM8ZPsGp3oUCIzs2zpmkI/cmymrulmZvNN1xT6BYt665puZjbfdE2hb1+3kt4FPadM613Qw/Z1KzuUyMwsW7rmpOjsic/CMfPnGVjUy/Z1K31C1Mws0TWFDoVS37RmgLGxMT541VCn45iZZUrXHHIxM7PKXOhmZjnhQjczywkXuplZTrjQzcxywoVuZpYTLnQzs5xQpy79KekHwP9r8OmLgR+mGKcVsp4x6/kg+xmdr3lZz5jFfG+IiNeXmtGxQm+GpPsiYrDTOSrJesas54PsZ3S+5mU9Y9bzzeVDLmZmOeFCNzPLiW4t9N2dDlCDrGfMej7Ifkbna17WM2Y93ym68hi6mZm9VrfuoZuZ2RwudDOznOi6Qpe0XtKEpElJO9q43qWSDkh6RNJDkv5HMv1jkqYk3Z/cLi96zs4k54Skda1+DZKelDSe5LgvmfY6SV+T9Gjy9bxkuiT9ryTDA5LeVLSc9ybjH5X03hTzrSzaTvdL+rGk3+vkNpR0q6Sjkh4smpbaNpO0NvmeTCbPVUoZd0n6XpLjryUtSqYvkzRTtC1vqZal3OttMl9q31NJyyXdk+T7gqSFKeT7QlG2JyXd36ntl6qI6Job0AM8BvwssBD4LrCqTes+H3hTcv9s4PvAKuBjwIdLjF+V5DsDWJ7k7mnlawCeBBbPmfZpYEdyfwfwqeT+5cDfAgIuBe5Jpr8OeDz5el5y/7wWfS//DXhDJ7ch8KvAm4AHW7HNgH8G3pw852+BDSllfAdwenL/U0UZlxWPm7OcklnKvd4m86X2PQXuBDYn928B/luz+ebMvwm4oVPbL81bt+2hXwxMRsTjEfESMAJsbMeKI+KpiPhOcv954BGg0vXvNgIjEfGTiHgCmKSQv92vYSPw2eT+Z4FNRdNvj4K7gUWSzgfWAV+LiGcj4kfA14D1Lcj1VuCxiKj0aeGWb8OI+CbwbIn1Nr3NknnnRMS3o/C//faiZTWVMSK+GhEnkod3A0sqLaNKlnKvt+F8FdT1PU32gt8CfKkV+ZLl/yZwR6VltHL7panbCn0A+Neix4epXKotIWkZsAa4J5m0LfnV99aiX7fKZW3lawjgq5IOStqaTOuPiKeg8EMJ+JkO5iu2mVP/E2VlG0J622wgud+qnLN+m8Ie46zlkg5J+ntJv5JMq5Sl3OttVhrf058GjhX98Ep7G/4K8HREPFo0LSvbr27dVuiljj+29X2XkvqALwO/FxE/Bv4M+Dngl4CnKPz6BuWztvI1XBYRbwI2AL8r6VcrjO1EvsKKC8dArwC+mEzK0jaspN487diW1wMngM8nk54CLoyINcCHgL+SdE47ssyR1ve01bm3cOqORVa2X0O6rdAPA0uLHi8BjrRr5ZIWUCjzz0fEHoCIeDoiTkbEy8CfU/jVsVLWlr2GiDiSfD0K/HWS5enk18XZXxuPdipfkQ3AdyLi6SRvZrZhIq1tdphTD4WkmjM5+fpO4KrkMADJoYxnkvsHKRyX/oUqWcq93oal+D39IYVDW6fPmd60ZJnvAr5QlDsT269R3Vbo9wIrkrPeCyn82r6vHStOjrX9JfBIRPxR0fTzi4b9OjB7Jn0fsFnSGZKWAysonFRpyWuQdJaks2fvUzhp9mCy7Nl3XbwX+JuifL+lgkuB55JfF0eBd0g6L/k1+R3JtDSdsleUlW1YJJVtlsx7XtKlyb+f3ypaVlMkrQd+H7giIl4smv56ST3J/Z+lsM0er5Kl3OttJl8q39PkB9UB4Mo08yXeBnwvIl45lJKV7dewTp2NbfRG4Z0G36fwk/P6Nq73lyn8ivUAcH9yuxz4HDCeTN8HnF/0nOuTnBMUvbuhFa+BwrsDvpvcHppdLoVjkF8HHk2+vi6ZLuDmJMM4MFi0rN+mcLJqEnhfytvxTOAZ4NyiaR3bhhR+sDwFHKewF/b+NLcZMEihzB4DPkPy6ewUMk5SOOY8+2/xlmTsu5Pv/3eB7wD/pVqWcq+3yXypfU+Tf9v/nLzmLwJnNJsvmX4b8DtzxrZ9+6V580f/zcxyotsOuZiZWRkudDOznHChm5nlhAvdzCwnXOhmZjnhQjczywkXuplZTvx/UrJ+PDnDxkYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy.sparse.csgraph import laplacian as csgraph_laplacian\n",
    "from sklearn.utils import check_array\n",
    "from sklearn.utils import check_random_state\n",
    "from sklearn.utils.fixes import lobpcg\n",
    "from sklearn.manifold._spectral_embedding import _set_diag\n",
    "from scipy import sparse\n",
    "from pyamg import smoothed_aggregation_solver\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "norm_laplacian = True\n",
    "random_state = check_random_state(1234)\n",
    "\n",
    "laplacian, dd = csgraph_laplacian(connectivity, normed=norm_laplacian, return_diag=True)\n",
    "laplacian = check_array(laplacian, dtype=np.float64, accept_sparse=True)\n",
    "                                \n",
    "laplacian = _set_diag(laplacian, 1, norm_laplacian)\n",
    "diag_shift = 1e-5 * sparse.eye(laplacian.shape[0])\n",
    "laplacian += diag_shift\n",
    "ml = smoothed_aggregation_solver(check_array(laplacian, 'csr'))\n",
    "laplacian -= diag_shift\n",
    "n_components = laplacian.shape[0]\n",
    "M = ml.aspreconditioner()\n",
    "X = random_state.rand(laplacian.shape[0], n_components + 1)\n",
    "X[:, 0] = dd.ravel()\n",
    "eigs, diffusion_map = lobpcg(laplacian, X, M=M, tol=1.e-5, largest=False)\n",
    "plt.scatter(np.arange(len(eigs)), eigs)\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.08769784,  0.36953977,  0.45080489,  0.48362059,  0.49597784,\n",
       "        0.51719611,  0.53114538,  0.54800999,  0.56116382,  0.57002931])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eigs[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DBSCAN\n",
    "Density-based clustering of applications with noise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DBSCAN has the concept of __core point__, __border point__ and __outlier__. A data point is considered a core point if there are sufficient (__*minPts*__) data points in its vicinity of radius __*eps*__. Border points are those points that are connected to core points but themselves have not enough data point in their neighborhood. Outliers are the points that are not connected to a core points. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img alt=\"\" caption=\"taken from wikipedia\" onmouseover=\"[taken from here](https://en.wikipedia.org/wiki/DBSCAN)\"\n",
    "id=\"bayesian_optimization\" src=\"../images/1024px-DBSCAN-Illustration.svg.png\" width=\"320\" height=\"320\">\n",
    "\n",
    "[The image is taken from wikipedia](https://en.wikipedia.org/wiki/DBSCAN)\n",
    "* red points (e.g. point A) are __core points__\n",
    "* yellow points (e.g. points B, c) are __border points__\n",
    "* the blue point (N) is an __outlier__\n",
    "\n",
    "<br>\n",
    "A starting point is selected by random and its neighborhood is scanned. Then this is done for all points in the neighborhood and so on. In the next step the starting point is choosen among the points not visited previously until all points were visited.<br>\n",
    "Core points are connected to other core-points and form clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "db = DBSCAN(eps=0.5, min_samples=14, metric='cosine', n_jobs=-1)\n",
    "clusters = db.fit(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1,  0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15,\n",
       "       16, 17, 18, 19, 20])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(clusters.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.75031255964891e-05"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.adjusted_rand_score(clusters.labels_, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
