{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "relevant-ecology",
   "metadata": {},
   "source": [
    "Principal receipe found here:\n",
    "https://github.com/parrt/msds621"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hybrid-container",
   "metadata": {},
   "source": [
    "## Creditcard-Fraud: imbalanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "starting-making",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error, f1_score, accuracy_score,\\\n",
    "                            roc_auc_score, average_precision_score, precision_recall_curve, auc,\\\n",
    "                            roc_curve, precision_score, recall_score\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from copy import copy\n",
    "from numpy import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%config InlineBackend.figure_format = 'png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "upper-report",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/mlg-ulb/creditcardfraud\n",
    "df = pd.read_csv(\"../data/creditcard.csv\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southern-partnership",
   "metadata": {},
   "source": [
    "### the data-set is too large - we subsample the majority class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ruled-camping",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_fraud = df.index[df['Class']==0]\n",
    "fraud = df.index[df['Class']==1].tolist()\n",
    "sampled = random.choice(no_fraud, size=100000, replace=False).tolist()\n",
    "df = df.loc[fraud + sampled, ].reset_index()\n",
    "df.to_csv(\"../data/creditcard_subsampled.csv\", header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "first-funds",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"num anomalies {np.sum(df['Class']==1)}/{len(df)} = {100*np.sum(df['Class']==1)/len(df):.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "simple-anchor",
   "metadata": {},
   "source": [
    "## what will our accuracy be ad hoc?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "israeli-personality",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(df.Class.astype(str) + \"_true\", pd.Series(np.zeros_like(df.Class)).astype(str) + \"_Actual\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secure-compression",
   "metadata": {},
   "source": [
    " - $\\text{accuracy} = \\frac{\\text{true positives + true negatives}}{\\text{true negatives + false negatives + true positives + false positives}} = \\frac{0 + 284315}{492 + 284315} = 0.998$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mental-lingerie",
   "metadata": {},
   "source": [
    "## get a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cardiovascular-canadian",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm\n",
    "model = lightgbm.LGBMClassifier(boosting_type='gbdt', num_leaves=31, max_depth=- 1, learning_rate=0.1, \n",
    "                                n_estimators=500, subsample_for_bin=20000, objective='binary', \n",
    "                                subsample=1.0, subsample_freq=0, colsample_bytree=1.0, \n",
    "                                n_jobs=- 1, silent=True, importance_type='split',\n",
    "                                is_unbalance = False, scale_pos_weight = 1.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "orange-component",
   "metadata": {},
   "source": [
    "## train / test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "criminal-reservoir",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df.drop('Class', axis=1), df['Class']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)\n",
    "clf = copy(model)\n",
    "clf.fit(X_train,y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a197147",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(sum(y_train), sum(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "revised-battlefield",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "y_pred_proba = clf.predict_proba(X_test)[:,1] # 2nd column is p(fraud)\n",
    "AUC = roc_auc_score(y_test, y_pred_proba)\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_pred_proba, pos_label=1)\n",
    "PR = auc(recall, precision)\n",
    "FPR, TPR, _ = roc_curve(y_test, y_pred_proba)\n",
    "df_conf = pd.DataFrame(confusion, columns=['non-Fraud','Fraud'], index=['non-Fraud','Fraud'])\n",
    "df_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "composite-brand",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitivity, recall, hit rate, or true positive rate (TPR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hydraulic-mainland",
   "metadata": {},
   "source": [
    " \n",
    " \\begin{equation}\n",
    " \\text{Precision}=\\frac{\\text{TP}}{\\text{TP + FP}}\n",
    "   \\end{equation}\n",
    "  \n",
    "  \\begin{equation} \n",
    " \\text{Recall}=\\text{Sensitivity}=\\text{TPR}=\\frac{\\text{TP}}{\\text{P}} =\\frac{\\text{TP}}{\\text{TP + FN}}\n",
    "    \\end{equation}\n",
    "    \n",
    "   \\begin{equation} \n",
    " \\text{F}_1\\text{-Score} = 2\\frac{\\text{Precision} \\cdot \\text{Recall}}{\\text{Precision} + \\text{Recall}}\n",
    "     \\end{equation}\n",
    "     \n",
    "   \\begin{equation}   \n",
    "  \\text{FPR}=\\frac{\\text{FP}}{\\text{N}} =\\frac{\\text{FP}}{\\text{FP + TN}}\n",
    "    \\end{equation} \n",
    "    \n",
    "The normal ROC auc is computed for the True Positive Rate (TPR) and the False Positive Rate (FPR)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "voluntary-reminder",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Precision {precision_score(y_test, y_pred):.3f}, Recall {recall_score(y_test, y_pred):.3f}\")\n",
    "print(f\"F1 {f1_score(y_test, y_pred):.2f}, Accuracy {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(f\"ROC {AUC:.2f}, AUC PR {PR:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprising-fitting",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(FPR, TPR, 'b.-', markersize=1, alpha=0.5)\n",
    "plt.xlabel(\"FPR\")\n",
    "plt.ylabel(\"TPR / Recall / Sensitivity\")\n",
    "plt.title(f\"credit card $\\\\bf ROC$ curve\")\n",
    "plt.savefig(\"/tmp/ROC-curve.png\", dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d158ab1e",
   "metadata": {},
   "source": [
    "Because of the imbalance, the FPR has from the beginning on very low values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imperial-lewis",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(y_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elect-flavor",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(recall, precision, 'b.-', markersize=1, alpha=0.5)\n",
    "plt.xlabel(\"recall\")\n",
    "plt.ylabel(\"precision\")\n",
    "plt.title(f\"credit card $\\\\bf PR$ curve\")\n",
    "plt.savefig(\"/tmp/PR-curve.png\", dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interior-latest",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep the workspace tidy\n",
    "y_pred, confusion, y_pred_proba, precision, recall = None, None, None, None, None\n",
    "del y_pred, confusion, y_pred_proba, precision, recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subtle-accident",
   "metadata": {},
   "source": [
    "## proper test set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impressive-cornell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# must split out test set first but get 20% from each class at original ratio of fraud/good\n",
    "df_good = df[df['Class']==0]\n",
    "df_fraud = df[df['Class']==1]\n",
    "\n",
    "df_train_good, df_test_good   = train_test_split(df_good, test_size=0.20)\n",
    "df_train_fraud, df_test_fraud = train_test_split(df_fraud, test_size=0.20)\n",
    "\n",
    "df_train = pd.concat([df_train_good, df_train_fraud], axis=0)\n",
    "df_test  = pd.concat([df_test_good, df_test_fraud], axis=0)\n",
    "\n",
    "print(f\"TRAIN num fraud {np.sum(df_train['Class']==1)}/{len(df_train)} = {100*np.sum(df_train['Class']==1)/len(df_train):.2f}%\")\n",
    "print(f\"TEST num fraud {np.sum(df_test['Class']==1)}/{len(df_test)} = {100*np.sum(df_test['Class']==1)/len(df_test):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thrown-snowboard",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep the workspace tidy\n",
    "df_good, df_fraud, df_train_good, df_test_good, df_train_fraud, df_test_fraud, df_train, df_test =None,None,None,None, None, None, None,None\n",
    "del df_good, df_fraud, df_train_good, df_test_good, df_train_fraud, df_test_fraud, df_train, df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amazing-independence",
   "metadata": {},
   "source": [
    "we can also do this with a sklearn data-set splitter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alien-effort",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "splitter = StratifiedShuffleSplit(n_splits=2, test_size=0.2, train_size=0.8)\n",
    "idx = next(splitter.split(df, df.Class))\n",
    "train_idx = idx[0]\n",
    "test_idx = idx[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "canadian-twist",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "missing-amplifier",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df.loc[train_idx]\n",
    "df_test = df.loc[test_idx]\n",
    "print(f\"TRAIN num fraud {np.sum(df_train['Class']==1)}/{len(df_train)} = {100*np.sum(df_train['Class']==1)/len(df_train):.2f}%\")\n",
    "print(f\"TEST num fraud {np.sum(df_test['Class']==1)}/{len(df_test)} = {100*np.sum(df_test['Class']==1)/len(df_test):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "registered-calculation",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = df_train.drop('Class', axis=1), df_train['Class']\n",
    "X_test, y_test = df_test.drop('Class', axis=1), df_test['Class']\n",
    "clf = copy(model)\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "df_conf = pd.DataFrame(confusion, columns=['F','T'], index=['F','T'])\n",
    "df_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occupied-petroleum",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = clf.predict_proba(X_test)[:,1] # 2nd column is p(fraud)\n",
    "AUC = roc_auc_score(y_test, y_pred_proba)\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_pred_proba, pos_label=1)\n",
    "PR = auc(recall, precision)\n",
    "print(f\"Precision {precision_score(y_test, y_pred):.3f}, Recall {recall_score(y_test, y_pred):.3f}\")\n",
    "print(f\"F1 {f1_score(y_test, y_pred):.2f}, Accuracy {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(f\"ROC {AUC:.2f}, AUC PR {PR:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "simple-brunswick",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep workspace tidy\n",
    "df, idx, df_train, df_test, clf, precision, recall, y_pred, y_pred_proba = None, None, None, None, None, None, None, None,None\n",
    "del df, idx, df_train, df_test, clf, precision, recall, y_pred, y_pred_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stunning-jordan",
   "metadata": {},
   "source": [
    "# Strategies for the imbalanced case:\n",
    " - oversample the minority class\n",
    " - undersample the majority class\n",
    " - do both of the former two suggestions\n",
    " - oversample only the cases that get missclassified\n",
    " - set `is_unbalance` and/or `scale_pos_weight` parameters in lightgbm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "binding-version",
   "metadata": {},
   "source": [
    "## oversample fraud"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thirty-leisure",
   "metadata": {},
   "source": [
    "### Synthetic Minority Oversampling Technique = SMOTE\n",
    "The [original paper is here](https://arxiv.org/abs/1106.1813)<br>\n",
    "The idea is to connect very close points in the feature space and generate new samples lying on the connecting line. This is done for the minority class only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "armed-workshop",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imblearn\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "X_train_ov, y_train_ov = SMOTE(sampling_strategy=0.1).fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlimited-boost",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = copy(model)\n",
    "clf.fit(X_train_ov,y_train_ov)\n",
    "y_pred = clf.predict(X_test)\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "df_conf = pd.DataFrame(confusion, columns=['F','T'], index=['F','T'])\n",
    "df_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grand-bracket",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = clf.predict_proba(X_test)[:,1] # 2nd column is p(fraud)\n",
    "AUC = roc_auc_score(y_test, y_pred_proba)\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_pred_proba, pos_label=1)\n",
    "PR = auc(recall, precision)\n",
    "print(f\"Precision {precision_score(y_test, y_pred):.3f}, Recall {recall_score(y_test, y_pred):.3f}\")\n",
    "print(f\"F1 {f1_score(y_test, y_pred):.2f}, Accuracy {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(f\"ROC {AUC:.2f}, AUC PR {PR:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rough-native",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ov, y_train_ov, y_pred, y_pred_proba, precision, recall, clf = None, None, None, None, None, None, None\n",
    "del X_train_ov, y_train_ov, y_pred, y_pred_proba, precision, recall, clf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hispanic-coast",
   "metadata": {},
   "source": [
    "### Adaptive Synthetic Sampling = ADASYN\n",
    "The [paper can be found here](https://www.ele.uri.edu/faculty/he/PDFfiles/adasyn.pdf).<br>\n",
    "More synthetic observations are generated in areas where the density of the minority class is very low. Those cases are hard to learn and upsampling them with SMOTE should make it easier to learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deadly-stomach",
   "metadata": {},
   "outputs": [],
   "source": [
    "# needs too much RAM: \n",
    "X_train_ov, y_train_ov = ADASYN(sampling_strategy=0.05).fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brutal-basketball",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = copy(model)\n",
    "clf.fit(X_train_ov,y_train_ov)\n",
    "y_pred = clf.predict(X_test)\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "df_conf = pd.DataFrame(confusion, columns=['F','T'], index=['F','T'])\n",
    "df_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preliminary-examination",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = clf.predict_proba(X_test)[:,1] # 2nd column is p(fraud)\n",
    "AUC = roc_auc_score(y_test, y_pred_proba)\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_pred_proba, pos_label=1)\n",
    "PR = auc(recall, precision)\n",
    "print(f\"Precision {precision_score(y_test, y_pred):.3f}, Recall {recall_score(y_test, y_pred):.3f}\")\n",
    "print(f\"F1 {f1_score(y_test, y_pred):.2f}, Accuracy {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(f\"ROC {AUC:.2f}, AUC PR {PR:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loose-polymer",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ov, y_train_ov, y_pred, y_pred_proba, precision, recall, clf = None, None, None, None, None, None, None\n",
    "del X_train_ov, y_train_ov, y_pred, y_pred_proba, precision, recall, clf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "limited-somerset",
   "metadata": {},
   "source": [
    "### Borderline-SMOTE\n",
    "The [paper can be found here](https://sci2s.ugr.es/keel/keel-dataset/pdfs/2005-Han-LNCS.pdf)<br>\n",
    "The principal idea is to upsample only those observations that are not classified correctly. The missclassified instances are found by k-nearest-neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outer-peeing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# needs to much RAM for me:\n",
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "X_train_ov, y_train_ov = BorderlineSMOTE(sampling_strategy=0.1).fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subsequent-peripheral",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = copy(model)\n",
    "clf.fit(X_train_ov,y_train_ov)\n",
    "y_pred = clf.predict(X_test)\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "df_conf = pd.DataFrame(confusion, columns=['F','T'], index=['F','T'])\n",
    "df_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "altered-foster",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = clf.predict_proba(X_test)[:,1] # 2nd column is p(fraud)\n",
    "AUC = roc_auc_score(y_test, y_pred_proba)\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_pred_proba, pos_label=1)\n",
    "PR = auc(recall, precision)\n",
    "print(f\"Precision {precision_score(y_test, y_pred):.3f}, Recall {recall_score(y_test, y_pred):.3f}\")\n",
    "print(f\"F1 {f1_score(y_test, y_pred):.2f}, Accuracy {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(f\"ROC {AUC:.2f}, AUC PR {PR:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stock-berlin",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ov, y_train_ov, y_pred, y_pred_proba, precision, recall, clf = None, None, None, None, None, None, None\n",
    "del X_train_ov, y_train_ov, y_pred, y_pred_proba, precision, recall, clf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "verbal-advisory",
   "metadata": {},
   "source": [
    "### Support-Vector-Machine-SMOTE = SVMSMOTE\n",
    "The class-boundaries for the Borderline are learned as the support-vectors of a Support-Vector-Machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accessible-windows",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SVMSMOTE\n",
    "X_train_ov, y_train_ov = SVMSMOTE(sampling_strategy=0.1).fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neural-accounting",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = copy(model)\n",
    "clf.fit(X_train_ov,y_train_ov)\n",
    "y_pred = clf.predict(X_test)\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "df_conf = pd.DataFrame(confusion, columns=['F','T'], index=['F','T'])\n",
    "df_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dressed-neighborhood",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = clf.predict_proba(X_test)[:,1] # 2nd column is p(fraud)\n",
    "AUC = roc_auc_score(y_test, y_pred_proba)\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_pred_proba, pos_label=1)\n",
    "PR = auc(recall, precision)\n",
    "print(f\"Precision {precision_score(y_test, y_pred):.3f}, Recall {recall_score(y_test, y_pred):.3f}\")\n",
    "print(f\"F1 {f1_score(y_test, y_pred):.2f}, Accuracy {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(f\"ROC {AUC:.2f}, AUC PR {PR:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entire-stereo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep the workspace tidy\n",
    "X_train_ov, y_train_ovm, y_pred, clf = None, None, None, None\n",
    "del X_train_ov, y_train_ovm, y_pred, clf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wireless-pointer",
   "metadata": {},
   "source": [
    "## weigh minority class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "referenced-atlantic",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = copy(model)\n",
    "clf.set_params(is_unbalance = True)\n",
    "#, scale_pos_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "potential-implementation",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train,y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "df_conf = pd.DataFrame(confusion, columns=['F','T'], index=['F','T'])\n",
    "df_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "color-template",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = clf.predict_proba(X_test)[:,1] # 2nd column is p(fraud)\n",
    "AUC = roc_auc_score(y_test, y_pred_proba)\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_pred_proba, pos_label=1)\n",
    "PR = auc(recall, precision)\n",
    "print(f\"Precision {precision_score(y_test, y_pred):.3f}, Recall {recall_score(y_test, y_pred):.3f}\")\n",
    "print(f\"F1 {f1_score(y_test, y_pred):.2f}, Accuracy {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(f\"ROC {AUC:.2f}, AUC PR {PR:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "peaceful-herald",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.set_params(is_unbalance=False, scale_pos_weight=200.0)\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "df_conf = pd.DataFrame(confusion, columns=['F','T'], index=['F','T'])\n",
    "df_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "included-equipment",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = clf.predict_proba(X_test)[:,1] # 2nd column is p(fraud)\n",
    "AUC = roc_auc_score(y_test, y_pred_proba)\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_pred_proba, pos_label=1)\n",
    "PR = auc(recall, precision)\n",
    "print(f\"Precision {precision_score(y_test, y_pred):.3f}, Recall {recall_score(y_test, y_pred):.3f}\")\n",
    "print(f\"F1 {f1_score(y_test, y_pred):.2f}, Accuracy {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(f\"ROC {AUC:.2f}, AUC PR {PR:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organizational-alignment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# house-keeping\n",
    "y_pred_proba, precision, recall, clf, y_pred = None, None, None, None, None\n",
    "del y_pred_proba, precision, recall, clf, y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "duplicate-sterling",
   "metadata": {},
   "source": [
    "## Undersample Fraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conventional-plain",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "X_train_u, y_train_u = RandomUnderSampler(sampling_strategy=0.5).fit_resample(X_train, y_train)\n",
    "print(X_train.shape, X_train_u.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enormous-argentina",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = copy(model)\n",
    "clf.fit(X_train_u,y_train_u)\n",
    "y_pred = clf.predict(X_test)\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "df_conf = pd.DataFrame(confusion, columns=['F','T'], index=['F','T'])\n",
    "df_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "connected-subscriber",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = clf.predict_proba(X_test)[:,1] # 2nd column is p(fraud)\n",
    "AUC = roc_auc_score(y_test, y_pred_proba)\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_pred_proba, pos_label=1)\n",
    "PR = auc(recall, precision)\n",
    "print(f\"Precision {precision_score(y_test, y_pred):.3f}, Recall {recall_score(y_test, y_pred):.3f}\")\n",
    "print(f\"F1 {f1_score(y_test, y_pred):.2f}, Accuracy {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(f\"ROC {AUC:.2f}, AUC PR {PR:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confident-sympathy",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba, y_pred, precision, recall, clf, X_train_u, y_train_u = None, None, None, None, None, None, None\n",
    "y_pred_proba, y_pred, precision, recall, clf, X_train_u, y_train_u"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unusual-replacement",
   "metadata": {},
   "source": [
    "## do both: oversample minority class and undersample majority class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "double-candy",
   "metadata": {},
   "source": [
    "### SMOTE and Edited Nearest Neighbors = SMOTE-ENN\n",
    "  - SMOTE is used for upsampling\n",
    "  - ENN removes an observation and its (k=3) nearest neighbors when the majority class of the nearest neighbors is different from the observation's class\n",
    "  \n",
    "### SMOTETOMEK\n",
    "  - this method finds reciprocal nearest-neighbors that are in different classes; These pairs are called Tomek-Links\n",
    "  - the observation in such a pair, belonging to the majority class is deleted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "personalized-august",
   "metadata": {},
   "outputs": [],
   "source": [
    "# not enough RAM\n",
    "from imblearn.combine import SMOTEENN\n",
    "X_train_uo, y_train_uo = SMOTEENN().fit_resample(X_train, y_train)\n",
    "# X_train_uo, y_train_uo = SMOTETomek(random_state=0).fit_resample(X_train, y_train)\n",
    "# print(X_train.shape, X_train_uo.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worthy-wrong",
   "metadata": {},
   "source": [
    "## get best combination: sampling and hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incoming-sentence",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "clf = copy(model)\n",
    "clf.set_params(num_leaves=64)\n",
    "borderline = BorderlineSMOTE(random_state=88)\n",
    "grid = {'class__n_estimators': [200, 500],\n",
    "        'class__neg_bagging_fraction': [0.1, 0.3],\n",
    "        'class__max_depth' : [4, 6, 8,],\n",
    "        'class__learning_rate' :[0.05, 0.1],\n",
    "        'sampling__sampling_strategy' :[0.1, 0.3]}\n",
    "pipeline = Pipeline([('sampling', borderline), ('class', clf)])\n",
    "grid_cv = GridSearchCV(pipeline, grid, scoring = 'f1', cv = 5, refit=True)\n",
    "   \n",
    "grid_cv.fit(X_train, y_train)\n",
    "display(grid_cv.best_score_, grid_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "geographic-deficit",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.set_params(**grid_cv.best_params_)\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_test)#[:, 1]\n",
    "\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "df_conf = pd.DataFrame(confusion, columns=['F','T'], index=['F','T'])\n",
    "df_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "other-terror",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = pipeline.predict_proba(X_test)[:,1] # 2nd column is p(fraud)\n",
    "AUC = roc_auc_score(y_test, y_pred_proba)\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_pred_proba, pos_label=1)\n",
    "PR = auc(recall, precision)\n",
    "print(f\"Precision {precision_score(y_test, y_pred):.3f}, Recall {recall_score(y_test, y_pred):.3f}\")\n",
    "print(f\"F1 {f1_score(y_test, y_pred):.2f}, Accuracy {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(f\"ROC {AUC:.2f}, AUC PR {PR:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "challenging-passenger",
   "metadata": {},
   "source": [
    "## One-Class SVM\n",
    "Train on majority class only and classifiy test-set in in-class examples and out-class examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "selective-affair",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import OneClassSVM \n",
    "\n",
    "train_normal = X_train[y_train == 0] \n",
    "train_outliers = X_train[y_train == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "partial-scoop",
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_prop = len(train_outliers) / len(train_normal) \n",
    "svm = OneClassSVM(kernel='rbf', nu=outlier_prop, gamma=0.000001) \n",
    "svm.fit(train_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "roman-morocco",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svm.predict(X_test)\n",
    "y_pred_corrected = np.zeros_like(y_pred)\n",
    "y_pred_corrected[y_pred == -1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pending-tobago",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atlantic-abraham",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion = confusion_matrix(y_test, y_pred_corrected)\n",
    "\n",
    "df_conf = pd.DataFrame(confusion, columns=['F','T'], index=['F','T'])\n",
    "df_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "egyptian-lending",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUC = roc_auc_score(y_test, y_pred_corrected)\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_pred_corrected, pos_label=1)\n",
    "PR = auc(recall, precision)\n",
    "print(f\"Precision {precision_score(y_test, y_pred_corrected):.3f}, Recall {recall_score(y_test, y_pred_corrected):.3f}\")\n",
    "print(f\"F1 {f1_score(y_test, y_pred_corrected):.2f}, Accuracy {accuracy_score(y_test, y_pred_corrected):.4f}\")\n",
    "print(f\"ROC {AUC:.2f}, AUC PR {PR:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wrong-mouth",
   "metadata": {},
   "source": [
    "Pros:\n",
    "  - It works really well with a clear margin of separation\n",
    "  - It is effective in high dimensional spaces.\n",
    "  - It is effective in cases where the number of dimensions is greater than the number of samples.\n",
    "  - It uses a subset of training points in the decision function (called support vectors), so it is also memory efficient.\n",
    "\n",
    "Cons:\n",
    "  - It doesn’t perform well when we have large data set because the required training time is higher\n",
    "  - It also doesn’t perform very well, when the data set has more noise i.e. target classes are overlapping\n",
    "  - SVM doesn’t directly provide probability estimates, these are calculated using an expensive five-fold cross-validation. It is included in the related SVC method of Python scikit-learn library."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:imbalanced]",
   "language": "python",
   "name": "conda-env-imbalanced-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
