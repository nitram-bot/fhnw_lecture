{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "relevant-ecology",
   "metadata": {},
   "source": [
    "found here:\n",
    "https://github.com/parrt/msds621"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hybrid-container",
   "metadata": {},
   "source": [
    "## Credicard-Fraud: imbalanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "starting-making",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dtreeviz.trees import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error, f1_score, accuracy_score,\\\n",
    "                            roc_auc_score, average_precision_score, precision_recall_curve, auc,\\\n",
    "                            roc_curve\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.datasets import load_boston, load_iris, load_wine, load_digits, \\\n",
    "                             load_breast_cancer, load_diabetes\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from copy import copy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%config InlineBackend.figure_format = 'png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "upper-report",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/mlg-ulb/creditcardfraud\n",
    "df = pd.read_csv(\"../data/creditcard.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "first-funds",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num anomalies 492/284807 = 0.17%\n"
     ]
    }
   ],
   "source": [
    "print(f\"num anomalies {np.sum(df['Class']==1)}/{len(df)} = {100*np.sum(df['Class']==1)/len(df):.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fifteen-vatican",
   "metadata": {},
   "source": [
    "## what will our accuracy be ad hoc?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "indian-gates",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0_Actual</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0_true</th>\n",
       "      <td>284315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_true</th>\n",
       "      <td>492</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0   0_Actual\n",
       "Class           \n",
       "0_true    284315\n",
       "1_true       492"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from sklearn.metrics.classification import precision_recall_fscore_support\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score\n",
    "pd.crosstab(df.Class.astype(str) + \"_true\", pd.Series(np.zeros_like(df.Class)).astype(str) + \"_Actual\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fluid-warrant",
   "metadata": {},
   "source": [
    " - $\\text{accuracy} = \\frac{\\text{true positives + true negatives}}{\\text{true negatives + false negatives + true positives + false positives}} = \\frac{0 + 284315}{492 + 284315} = 0.998$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mental-lingerie",
   "metadata": {},
   "source": [
    "## get a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cardiovascular-canadian",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm\n",
    "model = lightgbm.LGBMClassifier(boosting_type='gbdt', num_leaves=31, max_depth=- 1, learning_rate=0.1, \n",
    "                                n_estimators=500, subsample_for_bin=20000, objective='binary', \n",
    "                                subsample=1.0, subsample_freq=0, colsample_bytree=1.0, \n",
    "                                n_jobs=- 1, silent=True, importance_type='split',\n",
    "                                is_unbalance = False, scale_pos_weight = 1.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "orange-component",
   "metadata": {},
   "source": [
    "## train / test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "criminal-reservoir",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(is_unbalance=False, n_estimators=500, objective='binary',\n",
       "               scale_pos_weight=1.0, subsample_for_bin=20000)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = df.drop('Class', axis=1), df['Class']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)\n",
    "clf = copy(model)\n",
    "clf.fit(X_train,y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "revised-battlefield",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>non-Fraud</th>\n",
       "      <th>Fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>non-Fraud</th>\n",
       "      <td>56805</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fraud</th>\n",
       "      <td>91</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           non-Fraud  Fraud\n",
       "non-Fraud      56805     66\n",
       "Fraud             91      0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "y_pred_proba = clf.predict_proba(X_test)[:,1] # 2nd column is p(fraud)\n",
    "AUC = roc_auc_score(y_test, y_pred_proba)\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_pred_proba, pos_label=1)\n",
    "PR = auc(recall, precision)\n",
    "FPR, TPR, _ = roc_curve(y_test, y_pred_proba)\n",
    "df_conf = pd.DataFrame(confusion, columns=['non-Fraud','Fraud'], index=['non-Fraud','Fraud'])\n",
    "df_conf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parallel-delight",
   "metadata": {},
   "source": [
    " - $\\text{Precision}=\\frac{\\text{TP}}{\\text{TP + FP}}$\n",
    " - $\\text{Recall}=\\frac{\\text{TP}}{\\text{TP + FN}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "voluntary-reminder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision 0.000, Recall 0.000\n",
      "F1 0.00, Accuracy 0.9972\n",
      "ROC 0.50, AUC PR 0.00\n"
     ]
    }
   ],
   "source": [
    "print(f\"Precision {precision_score(y_test, y_pred):.3f}, Recall {recall_score(y_test, y_pred):.3f}\")\n",
    "print(f\"F1 {f1_score(y_test, y_pred):.2f}, Accuracy {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(f\"ROC {AUC:.2f}, AUC PR {PR:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "surprising-fitting",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(FPR, TPR, 'b.-', markersize=1, alpha=0.5)\n",
    "plt.xlabel(\"FPR\")\n",
    "plt.ylabel(\"TPR\")\n",
    "plt.title(f\"credit card $\\\\bf ROC$ curve\")\n",
    "plt.savefig(\"/tmp/ROC-curve.png\", dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "elect-flavor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(recall, precision, 'b.-', markersize=1, alpha=0.5)\n",
    "plt.xlabel(\"recall\")\n",
    "plt.ylabel(\"precision\")\n",
    "plt.title(f\"credit card $\\\\bf PR$ curve\")\n",
    "plt.savefig(\"/tmp/PR-curve.png\", dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "rising-conversion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep the workspace tidy\n",
    "y_pred, confusion, y_pred_proba, recision, recall = None, None, None, None, None\n",
    "del y_pred, confusion, y_pred_proba, recision, recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subtle-accident",
   "metadata": {},
   "source": [
    "## proper test set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "impressive-cornell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN num fraud 393/227845 = 0.17%\n",
      "TEST num fraud 99/56962 = 0.17%\n"
     ]
    }
   ],
   "source": [
    "# must split out test set first but get 20% from each class at original ratio of fraud/good\n",
    "df_good = df[df['Class']==0]\n",
    "df_fraud = df[df['Class']==1]\n",
    "\n",
    "df_train_good, df_test_good   = train_test_split(df_good, test_size=0.20)\n",
    "df_train_fraud, df_test_fraud = train_test_split(df_fraud, test_size=0.20)\n",
    "\n",
    "df_train = pd.concat([df_train_good, df_train_fraud], axis=0)\n",
    "df_test  = pd.concat([df_test_good, df_test_fraud], axis=0)\n",
    "\n",
    "print(f\"TRAIN num fraud {np.sum(df_train['Class']==1)}/{len(df_train)} = {100*np.sum(df_train['Class']==1)/len(df_train):.2f}%\")\n",
    "print(f\"TEST num fraud {np.sum(df_test['Class']==1)}/{len(df_test)} = {100*np.sum(df_test['Class']==1)/len(df_test):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "empty-depth",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep the workspace tidy\n",
    "df_good, df_fraud, df_train_good, df_test_good, df_train_fraud, df_test_fraud, df_train, df_test =None,None,None,None, None, None, None,None\n",
    "del df_good, df_fraud, df_train_good, df_test_good, df_train_fraud, df_test_fraud, df_train, df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "present-allah",
   "metadata": {},
   "source": [
    "we can also do this with a sklearn data-set splitter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "broke-white",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "splitter = StratifiedShuffleSplit(n_splits=2, test_size=0.2, train_size=0.8)\n",
    "idx = next(splitter.split(df, df.Class))\n",
    "train_idx = idx[0]\n",
    "test_idx = idx[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "peripheral-miami",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN num fraud 394/227845 = 0.17%\n",
      "TEST num fraud 98/56962 = 0.17%\n"
     ]
    }
   ],
   "source": [
    "df_train = df.loc[train_idx]\n",
    "df_test = df.loc[test_idx]\n",
    "print(f\"TRAIN num fraud {np.sum(df_train['Class']==1)}/{len(df_train)} = {100*np.sum(df_train['Class']==1)/len(df_train):.2f}%\")\n",
    "print(f\"TEST num fraud {np.sum(df_test['Class']==1)}/{len(df_test)} = {100*np.sum(df_test['Class']==1)/len(df_test):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "registered-calculation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F</th>\n",
       "      <th>T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F</th>\n",
       "      <td>56836</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T</th>\n",
       "      <td>54</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       F   T\n",
       "F  56836  28\n",
       "T     54  44"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train = df_train.drop('Class', axis=1), df_train['Class']\n",
    "X_test, y_test = df_test.drop('Class', axis=1), df_test['Class']\n",
    "clf = copy(model)\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "df_conf = pd.DataFrame(confusion, columns=['F','T'], index=['F','T'])\n",
    "df_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "occupied-petroleum",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision 0.611, Recall 0.449\n",
      "F1 0.52, Accuracy 0.9986\n",
      "ROC 0.72, AUC PR 0.50\n"
     ]
    }
   ],
   "source": [
    "y_pred_proba = clf.predict_proba(X_test)[:,1] # 2nd column is p(fraud)\n",
    "AUC = roc_auc_score(y_test, y_pred_proba)\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_pred_proba, pos_label=1)\n",
    "PR = auc(recall, precision)\n",
    "print(f\"Precision {precision_score(y_test, y_pred):.3f}, Recall {recall_score(y_test, y_pred):.3f}\")\n",
    "print(f\"F1 {f1_score(y_test, y_pred):.2f}, Accuracy {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(f\"ROC {AUC:.2f}, AUC PR {PR:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "passive-structure",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, None, None, None, None, None, None, None, None)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keep workspace tidy\n",
    "df, idx, df_train, df_test, clf, precision, recall, y_pred, y_pred_proba = None, None, None, None, None, None, None, None,None\n",
    "df, idx, df_train, df_test, clf, precision, recall, y_pred, y_pred_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "virgin-browser",
   "metadata": {},
   "source": [
    "# Strategies for the imbalanced case:\n",
    " - oversample the minority class\n",
    " - undersample the majority class\n",
    " - do both of the former two suggestions\n",
    " - oversample only the cases that get missclassified\n",
    " - set `is_unbalance` and/or `scale_pos_weight` parameters in lightgbm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opposite-arizona",
   "metadata": {},
   "source": [
    "## oversample fraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "mediterranean-london",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imblearn\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "X_train_ov, y_train_ov = SMOTE(sampling_strategy=0.1).fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "sexual-penalty",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F</th>\n",
       "      <th>T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F</th>\n",
       "      <td>56860</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T</th>\n",
       "      <td>23</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       F   T\n",
       "F  56860   4\n",
       "T     23  75"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = copy(model)\n",
    "clf.fit(X_train_ov,y_train_ov)\n",
    "y_pred = clf.predict(X_test)\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "df_conf = pd.DataFrame(confusion, columns=['F','T'], index=['F','T'])\n",
    "df_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "competent-preserve",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision 0.949, Recall 0.765\n",
      "F1 0.85, Accuracy 0.9995\n",
      "ROC 0.97, AUC PR 0.83\n"
     ]
    }
   ],
   "source": [
    "y_pred_proba = clf.predict_proba(X_test)[:,1] # 2nd column is p(fraud)\n",
    "AUC = roc_auc_score(y_test, y_pred_proba)\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_pred_proba, pos_label=1)\n",
    "PR = auc(recall, precision)\n",
    "print(f\"Precision {precision_score(y_test, y_pred):.3f}, Recall {recall_score(y_test, y_pred):.3f}\")\n",
    "print(f\"F1 {f1_score(y_test, y_pred):.2f}, Accuracy {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(f\"ROC {AUC:.2f}, AUC PR {PR:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "purple-stations",
   "metadata": {},
   "outputs": [],
   "source": [
    "# needs too much RAM: X_train_ov, y_train_ov = ADASYN().fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "given-vertex",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ov, y_train_ov, y_pred, y_pred_proba, precision, recall, clf = None, None, None, None, None, None, None\n",
    "del X_train_ov, y_train_ov, y_pred, y_pred_proba, precision, recall, clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "rocky-digest",
   "metadata": {},
   "outputs": [],
   "source": [
    "# needs to much RAM for me:\n",
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "X_train_ov, y_train_ov = BorderlineSMOTE(sampling_strategy=0.05).fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "amino-affair",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F</th>\n",
       "      <th>T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F</th>\n",
       "      <td>56860</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T</th>\n",
       "      <td>23</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       F   T\n",
       "F  56860   4\n",
       "T     23  75"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = copy(model)\n",
    "clf.fit(X_train_ov,y_train_ov)\n",
    "y_pred = clf.predict(X_test)\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "df_conf = pd.DataFrame(confusion, columns=['F','T'], index=['F','T'])\n",
    "df_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "removable-background",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision 0.949, Recall 0.765\n",
      "F1 0.85, Accuracy 0.9995\n",
      "ROC 0.97, AUC PR 0.83\n"
     ]
    }
   ],
   "source": [
    "y_pred_proba = clf.predict_proba(X_test)[:,1] # 2nd column is p(fraud)\n",
    "AUC = roc_auc_score(y_test, y_pred_proba)\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_pred_proba, pos_label=1)\n",
    "PR = auc(recall, precision)\n",
    "print(f\"Precision {precision_score(y_test, y_pred):.3f}, Recall {recall_score(y_test, y_pred):.3f}\")\n",
    "print(f\"F1 {f1_score(y_test, y_pred):.2f}, Accuracy {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(f\"ROC {AUC:.2f}, AUC PR {PR:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "minute-reporter",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ov, y_train_ov, y_pred, y_pred_proba, precision, recall, clf = None, None, None, None, None, None, None\n",
    "del X_train_ov, y_train_ov, y_pred, y_pred_proba, precision, recall, clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "divided-clearing",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SVMSMOTE\n",
    "X_train_ov, y_train_ov = SVMSMOTE(sampling_strategy=0.1).fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "imperial-progress",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F</th>\n",
       "      <th>T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F</th>\n",
       "      <td>56860</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T</th>\n",
       "      <td>22</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       F   T\n",
       "F  56860   4\n",
       "T     22  76"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = copy(model)\n",
    "clf.fit(X_train_ov,y_train_ov)\n",
    "y_pred = clf.predict(X_test)\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "df_conf = pd.DataFrame(confusion, columns=['F','T'], index=['F','T'])\n",
    "df_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "better-frame",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep the workspace tidy\n",
    "X_train_ov, y_train_ovm, y_pred, clf = None, None, None, None\n",
    "del X_train_ov, y_train_ovm, y_pred, clf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quality-missouri",
   "metadata": {},
   "source": [
    "## weigh minority class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "located-starter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(is_unbalance=True, n_estimators=500, objective='binary',\n",
       "               scale_pos_weight=1.0, subsample_for_bin=20000)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = copy(model)\n",
    "clf.set_params(is_unbalance = True)\n",
    "#, scale_pos_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "interracial-colorado",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F</th>\n",
       "      <th>T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F</th>\n",
       "      <td>54964</td>\n",
       "      <td>1900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T</th>\n",
       "      <td>14</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       F     T\n",
       "F  54964  1900\n",
       "T     14    84"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train,y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "df_conf = pd.DataFrame(confusion, columns=['F','T'], index=['F','T'])\n",
    "df_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "close-platinum",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision 0.042, Recall 0.857\n",
      "F1 0.08, Accuracy 0.9664\n",
      "ROC 0.91, AUC PR 0.45\n"
     ]
    }
   ],
   "source": [
    "y_pred_proba = clf.predict_proba(X_test)[:,1] # 2nd column is p(fraud)\n",
    "AUC = roc_auc_score(y_test, y_pred_proba)\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_pred_proba, pos_label=1)\n",
    "PR = auc(recall, precision)\n",
    "print(f\"Precision {precision_score(y_test, y_pred):.3f}, Recall {recall_score(y_test, y_pred):.3f}\")\n",
    "print(f\"F1 {f1_score(y_test, y_pred):.2f}, Accuracy {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(f\"ROC {AUC:.2f}, AUC PR {PR:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "optional-encyclopedia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F</th>\n",
       "      <th>T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F</th>\n",
       "      <td>56740</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T</th>\n",
       "      <td>37</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       F    T\n",
       "F  56740  124\n",
       "T     37   61"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.set_params(is_unbalance=False, scale_pos_weight=9.0)\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "df_conf = pd.DataFrame(confusion, columns=['F','T'], index=['F','T'])\n",
    "df_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "mobile-graham",
   "metadata": {},
   "outputs": [],
   "source": [
    "# house-keeping\n",
    "y_pred_proba, precision, recall, clf, y_pred = None, None, None, None, None\n",
    "del y_pred_proba, precision, recall, clf, y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "activated-parameter",
   "metadata": {},
   "source": [
    "## Undersample Fraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "waiting-admission",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(227845, 30) (1182, 30)\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "X_train_u, y_train_u = RandomUnderSampler(sampling_strategy=0.5).fit_resample(X_train, y_train)\n",
    "print(X_train.shape, X_train_u.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "vanilla-failing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F</th>\n",
       "      <th>T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F</th>\n",
       "      <td>56036</td>\n",
       "      <td>828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T</th>\n",
       "      <td>14</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       F    T\n",
       "F  56036  828\n",
       "T     14   84"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = copy(model)\n",
    "clf.fit(X_train_u,y_train_u)\n",
    "y_pred = clf.predict(X_test)\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "df_conf = pd.DataFrame(confusion, columns=['F','T'], index=['F','T'])\n",
    "df_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "connected-subscriber",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision 0.092, Recall 0.857\n",
      "F1 0.17, Accuracy 0.9852\n",
      "ROC 0.97, AUC PR 0.76\n"
     ]
    }
   ],
   "source": [
    "y_pred_proba = clf.predict_proba(X_test)[:,1] # 2nd column is p(fraud)\n",
    "AUC = roc_auc_score(y_test, y_pred_proba)\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_pred_proba, pos_label=1)\n",
    "PR = auc(recall, precision)\n",
    "print(f\"Precision {precision_score(y_test, y_pred):.3f}, Recall {recall_score(y_test, y_pred):.3f}\")\n",
    "print(f\"F1 {f1_score(y_test, y_pred):.2f}, Accuracy {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(f\"ROC {AUC:.2f}, AUC PR {PR:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "utility-ireland",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, None, None, None, None, None, None)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_proba, y_pred, precision, recall, clf, X_train_u, y_train_u = None, None, None, None, None, None, None\n",
    "y_pred_proba, y_pred, precision, recall, clf, X_train_u, y_train_u"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alone-action",
   "metadata": {},
   "source": [
    "## do both: oversample minority class and undersample majority class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "emerging-situation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# not enough RAM\n",
    "# from imblearn.combine import SMOTEENN\n",
    "# X_train_uo, y_train_uo = SMOTEENN().fit_resample(X_train, y_train)\n",
    "# X_train_uo, y_train_uo = SMOTETomek(random_state=0).fit_resample(X_train, y_train)\n",
    "# print(X_train.shape, X_train_uo.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "narrative-alias",
   "metadata": {},
   "source": [
    "## get best combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "chicken-driver",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/creditcard.csv\")\n",
    "X, y = df.drop('Class', axis=1), df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incoming-sentence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    }
   ],
   "source": [
    "from imblearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "clf = copy(model)\n",
    "borderline = BorderlineSMOTE(random_state=88)\n",
    "grid = {'class__n_estimators': [200, 500],\n",
    "        'class__neg_bagging_fraction': [0.1, 0.3],\n",
    "        'class__max_depth' : [4, 6, 8, -1],\n",
    "        'class__learning_rate' :[0.05, 0.1],\n",
    "        'sampling__sampling_strategy' :[0.1, 0.3, 0.5]}\n",
    "pipeline = Pipeline([('sampling', borderline), ('class', clf)])\n",
    "grid_cv = GridSearchCV(pipeline, grid, scoring = 'f1', cv = 4)\n",
    "   \n",
    "grid_cv.fit(X, y)\n",
    "grid_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "approximate-indonesian",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(recall, precision, 'b.-', markersize=1, alpha=0.5)\n",
    "plt.xlabel(\"recall\")\n",
    "plt.ylabel(\"precision\")\n",
    "plt.title(f\"Upsampled credit card $\\\\bf PR$ curve\")\n",
    "plt.savefig(\"/tmp/PR-curve-balanced.png\", dpi=200)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
