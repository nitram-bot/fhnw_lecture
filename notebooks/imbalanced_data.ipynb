{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "relevant-ecology",
   "metadata": {},
   "source": [
    "found here:\n",
    "https://github.com/parrt/msds621"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hybrid-container",
   "metadata": {},
   "source": [
    "## Creditcard-Fraud: imbalanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "starting-making",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dtreeviz.trees import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error, f1_score, accuracy_score,\\\n",
    "                            roc_auc_score, average_precision_score, precision_recall_curve, auc,\\\n",
    "                            roc_curve\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.datasets import load_boston, load_iris, load_wine, load_digits, \\\n",
    "                             load_breast_cancer, load_diabetes\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from copy import copy\n",
    "from numpy import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%config InlineBackend.figure_format = 'png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "upper-report",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807, 31)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://www.kaggle.com/mlg-ulb/creditcardfraud\n",
    "df = pd.read_csv(\"../data/creditcard.csv\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fifth-supplier",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_fraud = df.index[df['Class']==0]\n",
    "fraud = df.index[df['Class']==1].tolist()\n",
    "sampled = random.choice(no_fraud, size=100000, replace=False).tolist()\n",
    "df = df.loc[fraud + sampled, ].reset_index()\n",
    "df.to_csv(\"../data/creditcard_subsampled.csv\", header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "first-funds",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num anomalies 492/100492 = 0.49%\n"
     ]
    }
   ],
   "source": [
    "print(f\"num anomalies {np.sum(df['Class']==1)}/{len(df)} = {100*np.sum(df['Class']==1)/len(df):.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "infectious-winter",
   "metadata": {},
   "source": [
    "## what will our accuracy be ad hoc?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "opponent-filter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0_Actual</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0_true</th>\n",
       "      <td>100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_true</th>\n",
       "      <td>492</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0   0_Actual\n",
       "Class           \n",
       "0_true    100000\n",
       "1_true       492"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from sklearn.metrics.classification import precision_recall_fscore_support\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score\n",
    "pd.crosstab(df.Class.astype(str) + \"_true\", pd.Series(np.zeros_like(df.Class)).astype(str) + \"_Actual\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moral-receipt",
   "metadata": {},
   "source": [
    " - $\\text{accuracy} = \\frac{\\text{true positives + true negatives}}{\\text{true negatives + false negatives + true positives + false positives}} = \\frac{0 + 284315}{492 + 284315} = 0.998$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mental-lingerie",
   "metadata": {},
   "source": [
    "## get a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cardiovascular-canadian",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm\n",
    "model = lightgbm.LGBMClassifier(boosting_type='gbdt', num_leaves=31, max_depth=- 1, learning_rate=0.1, \n",
    "                                n_estimators=500, subsample_for_bin=20000, objective='binary', \n",
    "                                subsample=1.0, subsample_freq=0, colsample_bytree=1.0, \n",
    "                                n_jobs=- 1, silent=True, importance_type='split',\n",
    "                                is_unbalance = False, scale_pos_weight = 1.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "orange-component",
   "metadata": {},
   "source": [
    "## train / test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "criminal-reservoir",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(is_unbalance=False, n_estimators=500, objective='binary',\n",
       "               scale_pos_weight=1.0, subsample_for_bin=20000)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = df.drop('Class', axis=1), df['Class']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)\n",
    "clf = copy(model)\n",
    "clf.fit(X_train,y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "revised-battlefield",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>non-Fraud</th>\n",
       "      <th>Fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>non-Fraud</th>\n",
       "      <td>20011</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fraud</th>\n",
       "      <td>19</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           non-Fraud  Fraud\n",
       "non-Fraud      20011      1\n",
       "Fraud             19     68"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "y_pred_proba = clf.predict_proba(X_test)[:,1] # 2nd column is p(fraud)\n",
    "AUC = roc_auc_score(y_test, y_pred_proba)\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_pred_proba, pos_label=1)\n",
    "PR = auc(recall, precision)\n",
    "FPR, TPR, _ = roc_curve(y_test, y_pred_proba)\n",
    "df_conf = pd.DataFrame(confusion, columns=['non-Fraud','Fraud'], index=['non-Fraud','Fraud'])\n",
    "df_conf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bibliographic-detective",
   "metadata": {},
   "source": [
    " - $\\text{Precision}=\\frac{\\text{TP}}{\\text{TP + FP}}$\n",
    " - $\\text{Recall}=\\frac{\\text{TP}}{\\text{TP + FN}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "voluntary-reminder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision 0.986, Recall 0.782\n",
      "F1 0.87, Accuracy 0.9990\n",
      "ROC 0.97, AUC PR 0.86\n"
     ]
    }
   ],
   "source": [
    "print(f\"Precision {precision_score(y_test, y_pred):.3f}, Recall {recall_score(y_test, y_pred):.3f}\")\n",
    "print(f\"F1 {f1_score(y_test, y_pred):.2f}, Accuracy {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(f\"ROC {AUC:.2f}, AUC PR {PR:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "surprising-fitting",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(FPR, TPR, 'b.-', markersize=1, alpha=0.5)\n",
    "plt.xlabel(\"FPR\")\n",
    "plt.ylabel(\"TPR\")\n",
    "plt.title(f\"credit card $\\\\bf ROC$ curve\")\n",
    "plt.savefig(\"/tmp/ROC-curve.png\", dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "elect-flavor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(recall, precision, 'b.-', markersize=1, alpha=0.5)\n",
    "plt.xlabel(\"recall\")\n",
    "plt.ylabel(\"precision\")\n",
    "plt.title(f\"credit card $\\\\bf PR$ curve\")\n",
    "plt.savefig(\"/tmp/PR-curve.png\", dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "specialized-fetish",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep the workspace tidy\n",
    "y_pred, confusion, y_pred_proba, recision, recall = None, None, None, None, None\n",
    "del y_pred, confusion, y_pred_proba, recision, recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subtle-accident",
   "metadata": {},
   "source": [
    "## proper test set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "impressive-cornell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN num fraud 393/80393 = 0.49%\n",
      "TEST num fraud 99/20099 = 0.49%\n"
     ]
    }
   ],
   "source": [
    "# must split out test set first but get 20% from each class at original ratio of fraud/good\n",
    "df_good = df[df['Class']==0]\n",
    "df_fraud = df[df['Class']==1]\n",
    "\n",
    "df_train_good, df_test_good   = train_test_split(df_good, test_size=0.20)\n",
    "df_train_fraud, df_test_fraud = train_test_split(df_fraud, test_size=0.20)\n",
    "\n",
    "df_train = pd.concat([df_train_good, df_train_fraud], axis=0)\n",
    "df_test  = pd.concat([df_test_good, df_test_fraud], axis=0)\n",
    "\n",
    "print(f\"TRAIN num fraud {np.sum(df_train['Class']==1)}/{len(df_train)} = {100*np.sum(df_train['Class']==1)/len(df_train):.2f}%\")\n",
    "print(f\"TEST num fraud {np.sum(df_test['Class']==1)}/{len(df_test)} = {100*np.sum(df_test['Class']==1)/len(df_test):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "artistic-dispatch",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep the workspace tidy\n",
    "df_good, df_fraud, df_train_good, df_test_good, df_train_fraud, df_test_fraud, df_train, df_test =None,None,None,None, None, None, None,None\n",
    "del df_good, df_fraud, df_train_good, df_test_good, df_train_fraud, df_test_fraud, df_train, df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "embedded-defeat",
   "metadata": {},
   "source": [
    "we can also do this with a sklearn data-set splitter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "comfortable-costs",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "splitter = StratifiedShuffleSplit(n_splits=2, test_size=0.2, train_size=0.8)\n",
    "idx = next(splitter.split(df, df.Class))\n",
    "train_idx = idx[0]\n",
    "test_idx = idx[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "metallic-inspection",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20099"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "compressed-contamination",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN num fraud 394/80393 = 0.49%\n",
      "TEST num fraud 98/20099 = 0.49%\n"
     ]
    }
   ],
   "source": [
    "df_train = df.loc[train_idx]\n",
    "df_test = df.loc[test_idx]\n",
    "print(f\"TRAIN num fraud {np.sum(df_train['Class']==1)}/{len(df_train)} = {100*np.sum(df_train['Class']==1)/len(df_train):.2f}%\")\n",
    "print(f\"TEST num fraud {np.sum(df_test['Class']==1)}/{len(df_test)} = {100*np.sum(df_test['Class']==1)/len(df_test):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "registered-calculation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F</th>\n",
       "      <th>T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F</th>\n",
       "      <td>19980</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T</th>\n",
       "      <td>29</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       F   T\n",
       "F  19980  21\n",
       "T     29  69"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train = df_train.drop('Class', axis=1), df_train['Class']\n",
    "X_test, y_test = df_test.drop('Class', axis=1), df_test['Class']\n",
    "clf = copy(model)\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "df_conf = pd.DataFrame(confusion, columns=['F','T'], index=['F','T'])\n",
    "df_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "occupied-petroleum",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision 0.767, Recall 0.704\n",
      "F1 0.73, Accuracy 0.9975\n",
      "ROC 0.86, AUC PR 0.72\n"
     ]
    }
   ],
   "source": [
    "y_pred_proba = clf.predict_proba(X_test)[:,1] # 2nd column is p(fraud)\n",
    "AUC = roc_auc_score(y_test, y_pred_proba)\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_pred_proba, pos_label=1)\n",
    "PR = auc(recall, precision)\n",
    "print(f\"Precision {precision_score(y_test, y_pred):.3f}, Recall {recall_score(y_test, y_pred):.3f}\")\n",
    "print(f\"F1 {f1_score(y_test, y_pred):.2f}, Accuracy {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(f\"ROC {AUC:.2f}, AUC PR {PR:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "particular-clear",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, None, None, None, None, None, None, None, None)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keep workspace tidy\n",
    "df, idx, df_train, df_test, clf, precision, recall, y_pred, y_pred_proba = None, None, None, None, None, None, None, None,None\n",
    "df, idx, df_train, df_test, clf, precision, recall, y_pred, y_pred_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "equal-peeing",
   "metadata": {},
   "source": [
    "# Strategies for the imbalanced case:\n",
    " - oversample the minority class\n",
    " - undersample the majority class\n",
    " - do both of the former two suggestions\n",
    " - oversample only the cases that get missclassified\n",
    " - set `is_unbalance` and/or `scale_pos_weight` parameters in lightgbm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "turned-medicaid",
   "metadata": {},
   "source": [
    "## oversample fraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "beautiful-governor",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imblearn\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "X_train_ov, y_train_ov = SMOTE(sampling_strategy=0.1).fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "adjustable-little",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F</th>\n",
       "      <th>T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F</th>\n",
       "      <td>19997</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T</th>\n",
       "      <td>17</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       F   T\n",
       "F  19997   4\n",
       "T     17  81"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = copy(model)\n",
    "clf.fit(X_train_ov,y_train_ov)\n",
    "y_pred = clf.predict(X_test)\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "df_conf = pd.DataFrame(confusion, columns=['F','T'], index=['F','T'])\n",
    "df_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "compliant-newspaper",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision 0.953, Recall 0.827\n",
      "F1 0.89, Accuracy 0.9990\n",
      "ROC 0.98, AUC PR 0.89\n"
     ]
    }
   ],
   "source": [
    "y_pred_proba = clf.predict_proba(X_test)[:,1] # 2nd column is p(fraud)\n",
    "AUC = roc_auc_score(y_test, y_pred_proba)\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_pred_proba, pos_label=1)\n",
    "PR = auc(recall, precision)\n",
    "print(f\"Precision {precision_score(y_test, y_pred):.3f}, Recall {recall_score(y_test, y_pred):.3f}\")\n",
    "print(f\"F1 {f1_score(y_test, y_pred):.2f}, Accuracy {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(f\"ROC {AUC:.2f}, AUC PR {PR:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "genetic-maria",
   "metadata": {},
   "outputs": [],
   "source": [
    "# needs too much RAM: X_train_ov, y_train_ov = ADASYN().fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "developmental-cement",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ov, y_train_ov, y_pred, y_pred_proba, precision, recall, clf = None, None, None, None, None, None, None\n",
    "del X_train_ov, y_train_ov, y_pred, y_pred_proba, precision, recall, clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "placed-dimension",
   "metadata": {},
   "outputs": [],
   "source": [
    "# needs to much RAM for me:\n",
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "X_train_ov, y_train_ov = BorderlineSMOTE(sampling_strategy=0.05).fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "floral-matrix",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F</th>\n",
       "      <th>T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F</th>\n",
       "      <td>19996</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T</th>\n",
       "      <td>19</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       F   T\n",
       "F  19996   5\n",
       "T     19  79"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = copy(model)\n",
    "clf.fit(X_train_ov,y_train_ov)\n",
    "y_pred = clf.predict(X_test)\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "df_conf = pd.DataFrame(confusion, columns=['F','T'], index=['F','T'])\n",
    "df_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "boring-girlfriend",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision 0.940, Recall 0.806\n",
      "F1 0.87, Accuracy 0.9988\n",
      "ROC 0.98, AUC PR 0.89\n"
     ]
    }
   ],
   "source": [
    "y_pred_proba = clf.predict_proba(X_test)[:,1] # 2nd column is p(fraud)\n",
    "AUC = roc_auc_score(y_test, y_pred_proba)\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_pred_proba, pos_label=1)\n",
    "PR = auc(recall, precision)\n",
    "print(f\"Precision {precision_score(y_test, y_pred):.3f}, Recall {recall_score(y_test, y_pred):.3f}\")\n",
    "print(f\"F1 {f1_score(y_test, y_pred):.2f}, Accuracy {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(f\"ROC {AUC:.2f}, AUC PR {PR:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "honest-meeting",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ov, y_train_ov, y_pred, y_pred_proba, precision, recall, clf = None, None, None, None, None, None, None\n",
    "del X_train_ov, y_train_ov, y_pred, y_pred_proba, precision, recall, clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "continued-combine",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SVMSMOTE\n",
    "X_train_ov, y_train_ov = SVMSMOTE(sampling_strategy=0.1).fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "becoming-credit",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F</th>\n",
       "      <th>T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F</th>\n",
       "      <td>19995</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T</th>\n",
       "      <td>19</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       F   T\n",
       "F  19995   6\n",
       "T     19  79"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = copy(model)\n",
    "clf.fit(X_train_ov,y_train_ov)\n",
    "y_pred = clf.predict(X_test)\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "df_conf = pd.DataFrame(confusion, columns=['F','T'], index=['F','T'])\n",
    "df_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "subsequent-toronto",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep the workspace tidy\n",
    "X_train_ov, y_train_ovm, y_pred, clf = None, None, None, None\n",
    "del X_train_ov, y_train_ovm, y_pred, clf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gothic-petersburg",
   "metadata": {},
   "source": [
    "## weigh minority class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "consistent-phenomenon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(is_unbalance=True, n_estimators=500, objective='binary',\n",
       "               scale_pos_weight=1.0, subsample_for_bin=20000)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = copy(model)\n",
    "clf.set_params(is_unbalance = True)\n",
    "#, scale_pos_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "boolean-focus",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F</th>\n",
       "      <th>T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F</th>\n",
       "      <td>19154</td>\n",
       "      <td>847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T</th>\n",
       "      <td>13</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       F    T\n",
       "F  19154  847\n",
       "T     13   85"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train,y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "df_conf = pd.DataFrame(confusion, columns=['F','T'], index=['F','T'])\n",
    "df_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "therapeutic-legend",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision 0.091, Recall 0.867\n",
      "F1 0.17, Accuracy 0.9572\n",
      "ROC 0.91, AUC PR 0.48\n"
     ]
    }
   ],
   "source": [
    "y_pred_proba = clf.predict_proba(X_test)[:,1] # 2nd column is p(fraud)\n",
    "AUC = roc_auc_score(y_test, y_pred_proba)\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_pred_proba, pos_label=1)\n",
    "PR = auc(recall, precision)\n",
    "print(f\"Precision {precision_score(y_test, y_pred):.3f}, Recall {recall_score(y_test, y_pred):.3f}\")\n",
    "print(f\"F1 {f1_score(y_test, y_pred):.2f}, Accuracy {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(f\"ROC {AUC:.2f}, AUC PR {PR:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "decreased-skiing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F</th>\n",
       "      <th>T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F</th>\n",
       "      <td>19732</td>\n",
       "      <td>269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T</th>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       F    T\n",
       "F  19732  269\n",
       "T     98    0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.set_params(is_unbalance=False, scale_pos_weight=9.0)\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "df_conf = pd.DataFrame(confusion, columns=['F','T'], index=['F','T'])\n",
    "df_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "found-folder",
   "metadata": {},
   "outputs": [],
   "source": [
    "# house-keeping\n",
    "y_pred_proba, precision, recall, clf, y_pred = None, None, None, None, None\n",
    "del y_pred_proba, precision, recall, clf, y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "macro-seminar",
   "metadata": {},
   "source": [
    "## Undersample Fraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "hearing-laugh",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80393, 31) (1182, 31)\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "X_train_u, y_train_u = RandomUnderSampler(sampling_strategy=0.5).fit_resample(X_train, y_train)\n",
    "print(X_train.shape, X_train_u.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "emotional-blackjack",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F</th>\n",
       "      <th>T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F</th>\n",
       "      <td>19672</td>\n",
       "      <td>329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T</th>\n",
       "      <td>8</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       F    T\n",
       "F  19672  329\n",
       "T      8   90"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = copy(model)\n",
    "clf.fit(X_train_u,y_train_u)\n",
    "y_pred = clf.predict(X_test)\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "df_conf = pd.DataFrame(confusion, columns=['F','T'], index=['F','T'])\n",
    "df_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "connected-subscriber",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision 0.215, Recall 0.918\n",
      "F1 0.35, Accuracy 0.9832\n",
      "ROC 0.98, AUC PR 0.85\n"
     ]
    }
   ],
   "source": [
    "y_pred_proba = clf.predict_proba(X_test)[:,1] # 2nd column is p(fraud)\n",
    "AUC = roc_auc_score(y_test, y_pred_proba)\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_pred_proba, pos_label=1)\n",
    "PR = auc(recall, precision)\n",
    "print(f\"Precision {precision_score(y_test, y_pred):.3f}, Recall {recall_score(y_test, y_pred):.3f}\")\n",
    "print(f\"F1 {f1_score(y_test, y_pred):.2f}, Accuracy {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(f\"ROC {AUC:.2f}, AUC PR {PR:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "processed-delivery",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, None, None, None, None, None, None)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_proba, y_pred, precision, recall, clf, X_train_u, y_train_u = None, None, None, None, None, None, None\n",
    "y_pred_proba, y_pred, precision, recall, clf, X_train_u, y_train_u"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "narrative-sponsorship",
   "metadata": {},
   "source": [
    "## do both: oversample minority class and undersample majority class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "tired-corrections",
   "metadata": {},
   "outputs": [],
   "source": [
    "# not enough RAM\n",
    "# from imblearn.combine import SMOTEENN\n",
    "# X_train_uo, y_train_uo = SMOTEENN().fit_resample(X_train, y_train)\n",
    "# X_train_uo, y_train_uo = SMOTETomek(random_state=0).fit_resample(X_train, y_train)\n",
    "# print(X_train.shape, X_train_uo.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complicated-geometry",
   "metadata": {},
   "source": [
    "## get best combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "involved-pointer",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/creditcard_subsampled.csv\")\n",
    "X, y = df.drop('Class', axis=1), df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "incoming-sentence",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7663259684096551"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "clf = copy(model)\n",
    "clf.set_params(num_leaves=64)\n",
    "borderline = BorderlineSMOTE(random_state=88)\n",
    "grid = {'class__n_estimators': [200, 500],\n",
    "        'class__neg_bagging_fraction': [0.1, 0.3],\n",
    "        'class__max_depth' : [4, 6, 8, -1],\n",
    "        'class__learning_rate' :[0.05, 0.1],\n",
    "        'sampling__sampling_strategy' :[0.1, 0.3, 0.5]}\n",
    "pipeline = Pipeline([('sampling', borderline), ('class', clf)])\n",
    "grid_cv = GridSearchCV(pipeline, grid, scoring = 'f1', cv = 5)\n",
    "   \n",
    "grid_cv.fit(X, y)\n",
    "display(grid_cv.best_score_, grid_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cardiovascular-lottery",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class__learning_rate': 0.1,\n",
       " 'class__max_depth': 4,\n",
       " 'class__n_estimators': 500,\n",
       " 'class__neg_bagging_fraction': 0.1,\n",
       " 'sampling__sampling_strategy': 0.3}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "documentary-basis",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x, y, and format string must not be None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-c542cd649092>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'b.-'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarkersize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"recall\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"precision\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Upsampled credit card $\\\\bf PR$ curve\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/tmp/PR-curve-balanced.png\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdpi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2840\u001b[0m     return gca().plot(\n\u001b[1;32m   2841\u001b[0m         \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscalex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscalex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaley\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscaley\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2842\u001b[0;31m         **({\"data\": data} if data is not None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2843\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2844\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1741\u001b[0m         \"\"\"\n\u001b[1;32m   1742\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1743\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1744\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m    271\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs)\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0;31m# element array of None which causes problems downstream.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"x, y, and format string must not be None\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m         \u001b[0mkw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: x, y, and format string must not be None"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(recall, precision, 'b.-', markersize=1, alpha=0.5)\n",
    "plt.xlabel(\"recall\")\n",
    "plt.ylabel(\"precision\")\n",
    "plt.title(f\"Upsampled credit card $\\\\bf PR$ curve\")\n",
    "plt.savefig(\"/tmp/PR-curve-balanced.png\", dpi=200)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
