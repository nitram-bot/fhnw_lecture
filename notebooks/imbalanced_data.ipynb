{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "relevant-ecology",
   "metadata": {},
   "source": [
    "found here:\n",
    "https://github.com/parrt/msds621"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hybrid-container",
   "metadata": {},
   "source": [
    "## Creditcard-Fraud: imbalanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "starting-making",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error, f1_score, accuracy_score,\\\n",
    "                            roc_auc_score, average_precision_score, precision_recall_curve, auc,\\\n",
    "                            roc_curve, precision_score, recall_score\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from copy import copy\n",
    "from numpy import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%config InlineBackend.figure_format = 'png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "upper-report",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807, 31)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://www.kaggle.com/mlg-ulb/creditcardfraud\n",
    "df = pd.read_csv(\"../data/creditcard.csv\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ruled-camping",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_fraud = df.index[df['Class']==0]\n",
    "fraud = df.index[df['Class']==1].tolist()\n",
    "sampled = random.choice(no_fraud, size=100000, replace=False).tolist()\n",
    "df = df.loc[fraud + sampled, ].reset_index()\n",
    "df.to_csv(\"../data/creditcard_subsampled.csv\", header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "first-funds",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num anomalies 492/100492 = 0.49%\n"
     ]
    }
   ],
   "source": [
    "print(f\"num anomalies {np.sum(df['Class']==1)}/{len(df)} = {100*np.sum(df['Class']==1)/len(df):.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "simple-anchor",
   "metadata": {},
   "source": [
    "## what will our accuracy be ad hoc?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "israeli-personality",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0_Actual</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0_true</th>\n",
       "      <td>100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_true</th>\n",
       "      <td>492</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0   0_Actual\n",
       "Class           \n",
       "0_true    100000\n",
       "1_true       492"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from sklearn.metrics.classification import precision_recall_fscore_support\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score\n",
    "pd.crosstab(df.Class.astype(str) + \"_true\", pd.Series(np.zeros_like(df.Class)).astype(str) + \"_Actual\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secure-compression",
   "metadata": {},
   "source": [
    " - $\\text{accuracy} = \\frac{\\text{true positives + true negatives}}{\\text{true negatives + false negatives + true positives + false positives}} = \\frac{0 + 284315}{492 + 284315} = 0.998$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mental-lingerie",
   "metadata": {},
   "source": [
    "## get a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cardiovascular-canadian",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm\n",
    "model = lightgbm.LGBMClassifier(boosting_type='gbdt', num_leaves=31, max_depth=- 1, learning_rate=0.1, \n",
    "                                n_estimators=500, subsample_for_bin=20000, objective='binary', \n",
    "                                subsample=1.0, subsample_freq=0, colsample_bytree=1.0, \n",
    "                                n_jobs=- 1, silent=True, importance_type='split',\n",
    "                                is_unbalance = False, scale_pos_weight = 1.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "orange-component",
   "metadata": {},
   "source": [
    "## train / test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "criminal-reservoir",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(is_unbalance=False, n_estimators=500, objective='binary',\n",
       "               scale_pos_weight=1.0, subsample_for_bin=20000)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = df.drop('Class', axis=1), df['Class']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)\n",
    "clf = copy(model)\n",
    "clf.fit(X_train,y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "revised-battlefield",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>non-Fraud</th>\n",
       "      <th>Fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>non-Fraud</th>\n",
       "      <td>19996</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fraud</th>\n",
       "      <td>45</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           non-Fraud  Fraud\n",
       "non-Fraud      19996     11\n",
       "Fraud             45     47"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "y_pred_proba = clf.predict_proba(X_test)[:,1] # 2nd column is p(fraud)\n",
    "AUC = roc_auc_score(y_test, y_pred_proba)\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_pred_proba, pos_label=1)\n",
    "PR = auc(recall, precision)\n",
    "FPR, TPR, _ = roc_curve(y_test, y_pred_proba)\n",
    "df_conf = pd.DataFrame(confusion, columns=['non-Fraud','Fraud'], index=['non-Fraud','Fraud'])\n",
    "df_conf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hydraulic-mainland",
   "metadata": {},
   "source": [
    " - $\\text{Precision}=\\frac{\\text{TP}}{\\text{TP + FP}}$\n",
    " - $\\text{Recall}=\\frac{\\text{TP}}{\\text{TP + FN}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "voluntary-reminder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision 0.810, Recall 0.511\n",
      "F1 0.63, Accuracy 0.9972\n",
      "ROC 0.76, AUC PR 0.64\n"
     ]
    }
   ],
   "source": [
    "print(f\"Precision {precision_score(y_test, y_pred):.3f}, Recall {recall_score(y_test, y_pred):.3f}\")\n",
    "print(f\"F1 {f1_score(y_test, y_pred):.2f}, Accuracy {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(f\"ROC {AUC:.2f}, AUC PR {PR:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "surprising-fitting",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(FPR, TPR, 'b.-', markersize=1, alpha=0.5)\n",
    "plt.xlabel(\"FPR\")\n",
    "plt.ylabel(\"TPR\")\n",
    "plt.title(f\"credit card $\\\\bf ROC$ curve\")\n",
    "plt.savefig(\"/tmp/ROC-curve.png\", dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "elect-flavor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(recall, precision, 'b.-', markersize=1, alpha=0.5)\n",
    "plt.xlabel(\"recall\")\n",
    "plt.ylabel(\"precision\")\n",
    "plt.title(f\"credit card $\\\\bf PR$ curve\")\n",
    "plt.savefig(\"/tmp/PR-curve.png\", dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "interior-latest",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep the workspace tidy\n",
    "y_pred, confusion, y_pred_proba, recision, recall = None, None, None, None, None\n",
    "del y_pred, confusion, y_pred_proba, recision, recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subtle-accident",
   "metadata": {},
   "source": [
    "## proper test set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "impressive-cornell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN num fraud 393/80393 = 0.49%\n",
      "TEST num fraud 99/20099 = 0.49%\n"
     ]
    }
   ],
   "source": [
    "# must split out test set first but get 20% from each class at original ratio of fraud/good\n",
    "df_good = df[df['Class']==0]\n",
    "df_fraud = df[df['Class']==1]\n",
    "\n",
    "df_train_good, df_test_good   = train_test_split(df_good, test_size=0.20)\n",
    "df_train_fraud, df_test_fraud = train_test_split(df_fraud, test_size=0.20)\n",
    "\n",
    "df_train = pd.concat([df_train_good, df_train_fraud], axis=0)\n",
    "df_test  = pd.concat([df_test_good, df_test_fraud], axis=0)\n",
    "\n",
    "print(f\"TRAIN num fraud {np.sum(df_train['Class']==1)}/{len(df_train)} = {100*np.sum(df_train['Class']==1)/len(df_train):.2f}%\")\n",
    "print(f\"TEST num fraud {np.sum(df_test['Class']==1)}/{len(df_test)} = {100*np.sum(df_test['Class']==1)/len(df_test):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "thrown-snowboard",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep the workspace tidy\n",
    "df_good, df_fraud, df_train_good, df_test_good, df_train_fraud, df_test_fraud, df_train, df_test =None,None,None,None, None, None, None,None\n",
    "del df_good, df_fraud, df_train_good, df_test_good, df_train_fraud, df_test_fraud, df_train, df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amazing-independence",
   "metadata": {},
   "source": [
    "we can also do this with a sklearn data-set splitter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "alien-effort",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "splitter = StratifiedShuffleSplit(n_splits=2, test_size=0.2, train_size=0.8)\n",
    "idx = next(splitter.split(df, df.Class))\n",
    "train_idx = idx[0]\n",
    "test_idx = idx[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "canadian-twist",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20099"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "missing-amplifier",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN num fraud 394/80393 = 0.49%\n",
      "TEST num fraud 98/20099 = 0.49%\n"
     ]
    }
   ],
   "source": [
    "df_train = df.loc[train_idx]\n",
    "df_test = df.loc[test_idx]\n",
    "print(f\"TRAIN num fraud {np.sum(df_train['Class']==1)}/{len(df_train)} = {100*np.sum(df_train['Class']==1)/len(df_train):.2f}%\")\n",
    "print(f\"TEST num fraud {np.sum(df_test['Class']==1)}/{len(df_test)} = {100*np.sum(df_test['Class']==1)/len(df_test):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "registered-calculation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F</th>\n",
       "      <th>T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F</th>\n",
       "      <td>19988</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T</th>\n",
       "      <td>50</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       F   T\n",
       "F  19988  13\n",
       "T     50  48"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train = df_train.drop('Class', axis=1), df_train['Class']\n",
    "X_test, y_test = df_test.drop('Class', axis=1), df_test['Class']\n",
    "clf = copy(model)\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "df_conf = pd.DataFrame(confusion, columns=['F','T'], index=['F','T'])\n",
    "df_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "occupied-petroleum",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision 0.787, Recall 0.490\n",
      "F1 0.60, Accuracy 0.9969\n",
      "ROC 0.74, AUC PR 0.63\n"
     ]
    }
   ],
   "source": [
    "y_pred_proba = clf.predict_proba(X_test)[:,1] # 2nd column is p(fraud)\n",
    "AUC = roc_auc_score(y_test, y_pred_proba)\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_pred_proba, pos_label=1)\n",
    "PR = auc(recall, precision)\n",
    "print(f\"Precision {precision_score(y_test, y_pred):.3f}, Recall {recall_score(y_test, y_pred):.3f}\")\n",
    "print(f\"F1 {f1_score(y_test, y_pred):.2f}, Accuracy {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(f\"ROC {AUC:.2f}, AUC PR {PR:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "simple-brunswick",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep workspace tidy\n",
    "df, idx, df_train, df_test, clf, precision, recall, y_pred, y_pred_proba = None, None, None, None, None, None, None, None,None\n",
    "del df, idx, df_train, df_test, clf, precision, recall, y_pred, y_pred_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stunning-jordan",
   "metadata": {},
   "source": [
    "# Strategies for the imbalanced case:\n",
    " - oversample the minority class\n",
    " - undersample the majority class\n",
    " - do both of the former two suggestions\n",
    " - oversample only the cases that get missclassified\n",
    " - set `is_unbalance` and/or `scale_pos_weight` parameters in lightgbm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "binding-version",
   "metadata": {},
   "source": [
    "## oversample fraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "armed-workshop",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imblearn\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "X_train_ov, y_train_ov = SMOTE(sampling_strategy=0.1).fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "unlimited-boost",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F</th>\n",
       "      <th>T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F</th>\n",
       "      <td>19998</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T</th>\n",
       "      <td>21</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       F   T\n",
       "F  19998   3\n",
       "T     21  77"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = copy(model)\n",
    "clf.fit(X_train_ov,y_train_ov)\n",
    "y_pred = clf.predict(X_test)\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "df_conf = pd.DataFrame(confusion, columns=['F','T'], index=['F','T'])\n",
    "df_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "grand-bracket",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision 0.963, Recall 0.786\n",
      "F1 0.87, Accuracy 0.9988\n",
      "ROC 0.98, AUC PR 0.87\n"
     ]
    }
   ],
   "source": [
    "y_pred_proba = clf.predict_proba(X_test)[:,1] # 2nd column is p(fraud)\n",
    "AUC = roc_auc_score(y_test, y_pred_proba)\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_pred_proba, pos_label=1)\n",
    "PR = auc(recall, precision)\n",
    "print(f\"Precision {precision_score(y_test, y_pred):.3f}, Recall {recall_score(y_test, y_pred):.3f}\")\n",
    "print(f\"F1 {f1_score(y_test, y_pred):.2f}, Accuracy {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(f\"ROC {AUC:.2f}, AUC PR {PR:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "defensive-arbor",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ov, y_train_ov, y_pred, y_pred_proba, precision, recall, clf = None, None, None, None, None, None, None\n",
    "del X_train_ov, y_train_ov, y_pred, y_pred_proba, precision, recall, clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "deadly-stomach",
   "metadata": {},
   "outputs": [],
   "source": [
    "# needs too much RAM: \n",
    "X_train_ov, y_train_ov = ADASYN(sampling_strategy=0.05).fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "elect-dream",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F</th>\n",
       "      <th>T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F</th>\n",
       "      <td>19998</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T</th>\n",
       "      <td>21</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       F   T\n",
       "F  19998   3\n",
       "T     21  77"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = copy(model)\n",
    "clf.fit(X_train_ov,y_train_ov)\n",
    "y_pred = clf.predict(X_test)\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "df_conf = pd.DataFrame(confusion, columns=['F','T'], index=['F','T'])\n",
    "df_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "continental-announcement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision 0.963, Recall 0.786\n",
      "F1 0.87, Accuracy 0.9988\n",
      "ROC 0.98, AUC PR 0.88\n"
     ]
    }
   ],
   "source": [
    "y_pred_proba = clf.predict_proba(X_test)[:,1] # 2nd column is p(fraud)\n",
    "AUC = roc_auc_score(y_test, y_pred_proba)\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_pred_proba, pos_label=1)\n",
    "PR = auc(recall, precision)\n",
    "print(f\"Precision {precision_score(y_test, y_pred):.3f}, Recall {recall_score(y_test, y_pred):.3f}\")\n",
    "print(f\"F1 {f1_score(y_test, y_pred):.2f}, Accuracy {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(f\"ROC {AUC:.2f}, AUC PR {PR:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "loose-polymer",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ov, y_train_ov, y_pred, y_pred_proba, precision, recall, clf = None, None, None, None, None, None, None\n",
    "del X_train_ov, y_train_ov, y_pred, y_pred_proba, precision, recall, clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "outer-peeing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# needs to much RAM for me:\n",
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "X_train_ov, y_train_ov = BorderlineSMOTE(sampling_strategy=0.1).fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "subsequent-peripheral",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F</th>\n",
       "      <th>T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F</th>\n",
       "      <td>19998</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T</th>\n",
       "      <td>21</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       F   T\n",
       "F  19998   3\n",
       "T     21  77"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = copy(model)\n",
    "clf.fit(X_train_ov,y_train_ov)\n",
    "y_pred = clf.predict(X_test)\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "df_conf = pd.DataFrame(confusion, columns=['F','T'], index=['F','T'])\n",
    "df_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "altered-foster",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision 0.963, Recall 0.786\n",
      "F1 0.87, Accuracy 0.9988\n",
      "ROC 0.97, AUC PR 0.87\n"
     ]
    }
   ],
   "source": [
    "y_pred_proba = clf.predict_proba(X_test)[:,1] # 2nd column is p(fraud)\n",
    "AUC = roc_auc_score(y_test, y_pred_proba)\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_pred_proba, pos_label=1)\n",
    "PR = auc(recall, precision)\n",
    "print(f\"Precision {precision_score(y_test, y_pred):.3f}, Recall {recall_score(y_test, y_pred):.3f}\")\n",
    "print(f\"F1 {f1_score(y_test, y_pred):.2f}, Accuracy {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(f\"ROC {AUC:.2f}, AUC PR {PR:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "stock-berlin",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ov, y_train_ov, y_pred, y_pred_proba, precision, recall, clf = None, None, None, None, None, None, None\n",
    "del X_train_ov, y_train_ov, y_pred, y_pred_proba, precision, recall, clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "accessible-windows",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SVMSMOTE\n",
    "X_train_ov, y_train_ov = SVMSMOTE(sampling_strategy=0.1).fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "neural-accounting",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F</th>\n",
       "      <th>T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F</th>\n",
       "      <td>19998</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T</th>\n",
       "      <td>20</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       F   T\n",
       "F  19998   3\n",
       "T     20  78"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = copy(model)\n",
    "clf.fit(X_train_ov,y_train_ov)\n",
    "y_pred = clf.predict(X_test)\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "df_conf = pd.DataFrame(confusion, columns=['F','T'], index=['F','T'])\n",
    "df_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "reported-function",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision 0.963, Recall 0.796\n",
      "F1 0.87, Accuracy 0.9989\n",
      "ROC 0.97, AUC PR 0.87\n"
     ]
    }
   ],
   "source": [
    "y_pred_proba = clf.predict_proba(X_test)[:,1] # 2nd column is p(fraud)\n",
    "AUC = roc_auc_score(y_test, y_pred_proba)\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_pred_proba, pos_label=1)\n",
    "PR = auc(recall, precision)\n",
    "print(f\"Precision {precision_score(y_test, y_pred):.3f}, Recall {recall_score(y_test, y_pred):.3f}\")\n",
    "print(f\"F1 {f1_score(y_test, y_pred):.2f}, Accuracy {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(f\"ROC {AUC:.2f}, AUC PR {PR:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "entire-stereo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep the workspace tidy\n",
    "X_train_ov, y_train_ovm, y_pred, clf = None, None, None, None\n",
    "del X_train_ov, y_train_ovm, y_pred, clf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wireless-pointer",
   "metadata": {},
   "source": [
    "## weigh minority class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "referenced-atlantic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(is_unbalance=True, n_estimators=500, objective='binary',\n",
       "               scale_pos_weight=1.0, subsample_for_bin=20000)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = copy(model)\n",
    "clf.set_params(is_unbalance = True)\n",
    "#, scale_pos_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "potential-implementation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F</th>\n",
       "      <th>T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F</th>\n",
       "      <td>19154</td>\n",
       "      <td>847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T</th>\n",
       "      <td>13</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       F    T\n",
       "F  19154  847\n",
       "T     13   85"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train,y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "df_conf = pd.DataFrame(confusion, columns=['F','T'], index=['F','T'])\n",
    "df_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "color-template",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision 0.091, Recall 0.867\n",
      "F1 0.17, Accuracy 0.9572\n",
      "ROC 0.91, AUC PR 0.48\n"
     ]
    }
   ],
   "source": [
    "y_pred_proba = clf.predict_proba(X_test)[:,1] # 2nd column is p(fraud)\n",
    "AUC = roc_auc_score(y_test, y_pred_proba)\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_pred_proba, pos_label=1)\n",
    "PR = auc(recall, precision)\n",
    "print(f\"Precision {precision_score(y_test, y_pred):.3f}, Recall {recall_score(y_test, y_pred):.3f}\")\n",
    "print(f\"F1 {f1_score(y_test, y_pred):.2f}, Accuracy {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(f\"ROC {AUC:.2f}, AUC PR {PR:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "peaceful-herald",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F</th>\n",
       "      <th>T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F</th>\n",
       "      <td>19732</td>\n",
       "      <td>269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T</th>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       F    T\n",
       "F  19732  269\n",
       "T     98    0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.set_params(is_unbalance=False, scale_pos_weight=9.0)\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "df_conf = pd.DataFrame(confusion, columns=['F','T'], index=['F','T'])\n",
    "df_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "organizational-alignment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# house-keeping\n",
    "y_pred_proba, precision, recall, clf, y_pred = None, None, None, None, None\n",
    "del y_pred_proba, precision, recall, clf, y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "duplicate-sterling",
   "metadata": {},
   "source": [
    "## Undersample Fraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "conventional-plain",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80393, 31) (1182, 31)\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "X_train_u, y_train_u = RandomUnderSampler(sampling_strategy=0.5).fit_resample(X_train, y_train)\n",
    "print(X_train.shape, X_train_u.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "enormous-argentina",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F</th>\n",
       "      <th>T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F</th>\n",
       "      <td>19672</td>\n",
       "      <td>329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T</th>\n",
       "      <td>8</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       F    T\n",
       "F  19672  329\n",
       "T      8   90"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = copy(model)\n",
    "clf.fit(X_train_u,y_train_u)\n",
    "y_pred = clf.predict(X_test)\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "df_conf = pd.DataFrame(confusion, columns=['F','T'], index=['F','T'])\n",
    "df_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "connected-subscriber",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision 0.215, Recall 0.918\n",
      "F1 0.35, Accuracy 0.9832\n",
      "ROC 0.98, AUC PR 0.85\n"
     ]
    }
   ],
   "source": [
    "y_pred_proba = clf.predict_proba(X_test)[:,1] # 2nd column is p(fraud)\n",
    "AUC = roc_auc_score(y_test, y_pred_proba)\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_pred_proba, pos_label=1)\n",
    "PR = auc(recall, precision)\n",
    "print(f\"Precision {precision_score(y_test, y_pred):.3f}, Recall {recall_score(y_test, y_pred):.3f}\")\n",
    "print(f\"F1 {f1_score(y_test, y_pred):.2f}, Accuracy {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(f\"ROC {AUC:.2f}, AUC PR {PR:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "confident-sympathy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, None, None, None, None, None, None)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_proba, y_pred, precision, recall, clf, X_train_u, y_train_u = None, None, None, None, None, None, None\n",
    "y_pred_proba, y_pred, precision, recall, clf, X_train_u, y_train_u"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unusual-replacement",
   "metadata": {},
   "source": [
    "## do both: oversample minority class and undersample majority class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "personalized-august",
   "metadata": {},
   "outputs": [],
   "source": [
    "# not enough RAM\n",
    "# from imblearn.combine import SMOTEENN\n",
    "# X_train_uo, y_train_uo = SMOTEENN().fit_resample(X_train, y_train)\n",
    "# X_train_uo, y_train_uo = SMOTETomek(random_state=0).fit_resample(X_train, y_train)\n",
    "# print(X_train.shape, X_train_uo.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worthy-wrong",
   "metadata": {},
   "source": [
    "## get best combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "possible-maria",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/creditcard_subsampled.csv\")\n",
    "X, y = df.drop('Class', axis=1), df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "incoming-sentence",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7663259684096551"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "clf = copy(model)\n",
    "clf.set_params(num_leaves=64)\n",
    "borderline = BorderlineSMOTE(random_state=88)\n",
    "grid = {'class__n_estimators': [200, 500],\n",
    "        'class__neg_bagging_fraction': [0.1, 0.3],\n",
    "        'class__max_depth' : [4, 6, 8, -1],\n",
    "        'class__learning_rate' :[0.05, 0.1],\n",
    "        'sampling__sampling_strategy' :[0.1, 0.3, 0.5]}\n",
    "pipeline = Pipeline([('sampling', borderline), ('class', clf)])\n",
    "grid_cv = GridSearchCV(pipeline, grid, scoring = 'f1', cv = 5)\n",
    "   \n",
    "grid_cv.fit(X, y)\n",
    "display(grid_cv.best_score_, grid_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "expired-instruction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class__learning_rate': 0.1,\n",
       " 'class__max_depth': 4,\n",
       " 'class__n_estimators': 500,\n",
       " 'class__neg_bagging_fraction': 0.1,\n",
       " 'sampling__sampling_strategy': 0.3}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "honest-amount",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x, y, and format string must not be None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-c542cd649092>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'b.-'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarkersize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"recall\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"precision\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Upsampled credit card $\\\\bf PR$ curve\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/tmp/PR-curve-balanced.png\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdpi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2840\u001b[0m     return gca().plot(\n\u001b[1;32m   2841\u001b[0m         \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscalex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscalex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaley\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscaley\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2842\u001b[0;31m         **({\"data\": data} if data is not None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2843\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2844\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1741\u001b[0m         \"\"\"\n\u001b[1;32m   1742\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1743\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1744\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m    271\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs)\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0;31m# element array of None which causes problems downstream.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"x, y, and format string must not be None\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m         \u001b[0mkw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: x, y, and format string must not be None"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(recall, precision, 'b.-', markersize=1, alpha=0.5)\n",
    "plt.xlabel(\"recall\")\n",
    "plt.ylabel(\"precision\")\n",
    "plt.title(f\"Upsampled credit card $\\\\bf PR$ curve\")\n",
    "plt.savefig(\"/tmp/PR-curve-balanced.png\", dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "challenging-passenger",
   "metadata": {},
   "source": [
    "## One-Class SVM\n",
    "Train on majority class only and classifiy test-set in in-class examples and out-class examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "selective-affair",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import OneClassSVM \n",
    "\n",
    "train_normal = X_train[y_train == 0] \n",
    "train_outliers = X_train[y_train == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "partial-scoop",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneClassSVM(gamma=1e-06, nu=0.004874817194355212)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outlier_prop = len(train_outliers) / len(train_normal) \n",
    "svm = OneClassSVM(kernel='rbf', nu=outlier_prop, gamma=0.000001) \n",
    "svm.fit(train_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "roman-morocco",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svm.predict(X_test)\n",
    "y_pred_corrected = np.zeros_like(y_pred)\n",
    "y_pred_corrected[y_pred == -1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "egyptian-lending",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision 0.040, Recall 0.343\n",
      "F1 0.07, Accuracy 0.9547\n",
      "ROC 0.65, AUC PR 0.19\n"
     ]
    }
   ],
   "source": [
    "AUC = roc_auc_score(y_test, y_pred_corrected)\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_pred_corrected, pos_label=1)\n",
    "PR = auc(recall, precision)\n",
    "print(f\"Precision {precision_score(y_test, y_pred_corrected):.3f}, Recall {recall_score(y_test, y_pred_corrected):.3f}\")\n",
    "print(f\"F1 {f1_score(y_test, y_pred_corrected):.2f}, Accuracy {accuracy_score(y_test, y_pred_corrected):.4f}\")\n",
    "print(f\"ROC {AUC:.2f}, AUC PR {PR:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wrong-mouth",
   "metadata": {},
   "source": [
    "Pros:\n",
    "It works really well with a clear margin of separation\n",
    "It is effective in high dimensional spaces.\n",
    "It is effective in cases where the number of dimensions is greater than the number of samples.\n",
    "It uses a subset of training points in the decision function (called support vectors), so it is also memory efficient.\n",
    "\n",
    "Cons:\n",
    "It doesn’t perform well when we have large data set because the required training time is higher\n",
    "It also doesn’t perform very well, when the data set has more noise i.e. target classes are overlapping\n",
    "SVM doesn’t directly provide probability estimates, these are calculated using an expensive five-fold cross-validation. It is included in the related SVC method of Python scikit-learn library."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:imbalanced]",
   "language": "python",
   "name": "conda-env-imbalanced-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
