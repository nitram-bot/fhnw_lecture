{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "411e3e9a",
   "metadata": {},
   "source": [
    "## OCR\n",
    " - easyocr\n",
    " - tesseract"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36f0a83",
   "metadata": {},
   "source": [
    "### easyocr\n",
    "[easyocr on github](https://github.com/JaidedAI/EasyOCR#api-documentation)<br>\n",
    "The easyocr-Algorithm dates from [2015](https://arxiv.org/pdf/1507.05717.pdf). Considered, that we use neural networks, this is rather 'old'. However, for a first check, to see if the whole pipeline could work with OCR it's good enough. Perhaps it will turn out that it's even not the processing step in the pipeline that has to be improved upon the most.<br>\n",
    "The model consists of several steps:<br>\n",
    "1. a convolutional layer extracting feature maps (VGG is one of the most often used networks for this task)\n",
    "2. the vectors (columns) representing the different positions in the input image are fed to a Recurrent Neural Network (RNN) (LSTM). This RNN predicts the most probable sequence of characters (and blanks) over the input feature maps.\n",
    "3. The Transcription Layer uses a 'dictionary approach' to clean the previous predictions and to return entire words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0daa6121",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image('../images/easyocr1.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438ad857",
   "metadata": {},
   "source": [
    "### tesseract\n",
    "Tesseract is around for more than 15 years. It is open-source and used in most non-commercial software with OCR-capabilities. In [2016](https://github.com/tesseract-ocr/docs/blob/main/das_tutorial2016/6ModernizationEfforts.pdf) a LSTM was added to its processing pipeline.<br>\n",
    "Good explanations and instructions (also for installing) can be found [here](https://nanonets.com/blog/ocr-with-tesseract/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2cebaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "    Image('../images/tessearct1.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31fe4194",
   "metadata": {},
   "source": [
    "data is taken form [here](https://www.kaggle.com/datasets/volkandl/optical-character-recognition-ocr-texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908ffad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "import os\n",
    "from random import sample\n",
    "import easyocr\n",
    "from IPython.display import Image\n",
    "\n",
    "path = '/home/martin/python/fhnw_lecture/data/OCR_TEXT'\n",
    "reader = easyocr.Reader(['de', 'it', 'fr', 'en'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626b490e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pics = os.listdir(path)\n",
    "imgs = sample(all_pics, 10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0204054c",
   "metadata": {},
   "source": [
    "For an explanation of the tesseract configuration possibilities, please have a look [here](https://learnopencv.com/deep-learning-based-text-recognition-ocr-using-tesseract-and-opencv/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6089b19",
   "metadata": {},
   "source": [
    "get the correct eng.traineddata version as described here:\n",
    "https://stackoverflow.com/questions/14800730/tesseract-running-error\n",
    "\n",
    "do this:\n",
    "/usr/share/tesseract-ocr/4.00/tessdata# wget https://github.com/tesseract-ocr/tessdata/raw/main/eng.traineddata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460ac66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_config = r'--oem 3 --psm 6'\n",
    "\n",
    "j = 7\n",
    "img_path = os.path.join(path,imgs[j])\n",
    "img = cv2.imread(img_path, 0)\n",
    "display(pytesseract.image_to_string(img, config=custom_config))\n",
    "\n",
    "display(reader.readtext(img, detail=0))\n",
    "\n",
    "Image(img_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tesseract]",
   "language": "python",
   "name": "conda-env-tesseract-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
