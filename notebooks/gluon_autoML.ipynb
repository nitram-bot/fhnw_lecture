{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a21afdb1",
   "metadata": {},
   "source": [
    "conda env automl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4de0930",
   "metadata": {},
   "source": [
    "# autogluon.tabular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ad78305",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23622/3159152723.py:11: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  X=X[set(X.columns.values.tolist())]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "train = pd.read_csv('../data/train.csv', sep=\",\")\n",
    "test = pd.read_csv('../data/test.csv')\n",
    "\n",
    "import sklearn\n",
    "y = train['SalePrice']\n",
    "X = train.drop('SalePrice', axis=1)\n",
    "X=X[set(X.columns.values.tolist())]\n",
    "categorical = [var for var in X.columns if X[var].dtype=='O']\n",
    "numerical = [var for var in X.columns if X[var].dtype!='O']\n",
    "X[categorical] = X[categorical].fillna('None')\n",
    "\n",
    "# auto-sklearn can not deal with categorical variables\n",
    "X= pd.concat([pd.get_dummies(X[categorical], dummy_na=True), X[numerical]], axis=1)\n",
    "\n",
    "y = np.log1p(y)\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(X, y, random_state=42, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "727a8596",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/martin/miniconda3/envs/automl/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20240406_120855/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=20\n",
      "Beginning AutoGluon training ... Time limit = 5000s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20240406_120855/\"\n",
      "AutoGluon Version:  0.7.0\n",
      "Python Version:     3.9.16\n",
      "Operating System:   Linux\n",
      "Platform Machine:   aarch64\n",
      "Platform Version:   #1 SMP PREEMPT Thu May 25 07:27:39 UTC 2023\n",
      "Train Data Rows:    1168\n",
      "Train Data Columns: 347\n",
      "Label Column: SalePrice\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (13.521140839642674, 10.460270761075149, 12.03066, 0.39061)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    24776.34 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.71 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 265 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 45): ['SaleType_nan', 'GarageType_nan', 'Fence_nan', 'BsmtFinType2_nan', 'HouseStyle_nan', 'Condition1_nan', 'Condition2_nan', 'PavedDrive_nan', 'BsmtFinType1_nan', 'BldgType_nan', 'Neighborhood_nan', 'Exterior2nd_nan', 'MSZoning_nan', 'FireplaceQu_nan', 'Foundation_nan', 'Heating_nan', 'GarageCond_nan', 'LandSlope_nan', 'Street_nan', 'BsmtQual_nan', 'LotShape_nan', 'CentralAir_nan', 'ExterQual_nan', 'PoolQC_nan', 'LandContour_nan', 'Functional_nan', 'SaleCondition_nan', 'KitchenQual_nan', 'ExterCond_nan', 'MiscFeature_nan', 'BsmtExposure_nan', 'RoofMatl_Membran', 'RoofMatl_nan', 'BsmtCond_nan', 'MasVnrType_nan', 'Alley_nan', 'GarageQual_nan', 'Exterior1st_nan', 'Utilities_nan', 'Electrical_Mix', 'Electrical_nan', 'LotConfig_nan', 'GarageFinish_nan', 'HeatingQC_nan', 'RoofStyle_nan']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) :   3 | ['MasVnrArea', 'LotFrontage', 'GarageYrBlt']\n",
      "\t\t('int', [])   : 299 | ['SaleType_COD', 'SaleType_CWD', 'SaleType_Con', 'SaleType_ConLD', 'SaleType_ConLI', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     :   3 | ['MasVnrArea', 'LotFrontage', 'GarageYrBlt']\n",
      "\t\t('int', [])       :  34 | ['KitchenAbvGr', 'ScreenPorch', 'MSSubClass', 'Id', 'WoodDeckSF', ...]\n",
      "\t\t('int', ['bool']) : 265 | ['SaleType_COD', 'SaleType_CWD', 'SaleType_Con', 'SaleType_ConLD', 'SaleType_ConLI', ...]\n",
      "\t0.1s = Fit runtime\n",
      "\t302 features in original data used to generate 302 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.66 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.13s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 3332.42s of the 4999.87s of remaining time.\n",
      "\t-0.2314\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 3332.27s of the 4999.73s of remaining time.\n",
      "\t-0.2298\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 3332.24s of the 4999.7s of remaining time.\n",
      "Will use sequential fold fitting strategy because import of ray failed. Reason: ray is required to train folds in parallel. A quick tip is to install via `pip install ray==2.2.0`, or use sequential fold fitting by passing `sequential_local` to `ag_args_ensemble` when calling tabular.fitFor example: `predictor.fit(..., ag_args_ensemble={'fold_fitting_strategy': 'sequential_local'})`\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused LightGBMXT_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. A quick tip is to install via `pip install autogluon.tabular[lightgbm]==0.7.0`.\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 3332.2s of the 4999.66s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused LightGBM_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. A quick tip is to install via `pip install autogluon.tabular[lightgbm]==0.7.0`.\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 3332.16s of the 4999.62s of remaining time.\n",
      "\t-0.1453\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.87s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 3330.81s of the 4998.27s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused CatBoost_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==0.7.0`.\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 3330.77s of the 4998.22s of remaining time.\n",
      "\t-0.1461\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.55s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 3329.73s of the 4997.19s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused NeuralNetFastAI_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\tImport fastai failed. A quick tip is to install via `pip install autogluon.tabular[fastai]==0.7.0`. \n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 3329.69s of the 4997.14s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused XGBoost_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import xgboost` failed. A quick tip is to install via `pip install autogluon.tabular[xgboost]==0.7.0`.\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 3329.64s of the 4997.09s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused NeuralNetTorch_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\tUnable to import dependency torch\n",
      "A quick tip is to install via `pip install torch`.\n",
      "The minimum torch version is currently 1.6.\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 3329.59s of the 4997.05s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tWarning: Exception caused LightGBMLarge_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. A quick tip is to install via `pip install autogluon.tabular[lightgbm]==0.7.0`.\n",
      "Repeating k-fold bagging: 2/20\n",
      "Repeating k-fold bagging: 3/20\n",
      "Repeating k-fold bagging: 4/20\n",
      "Repeating k-fold bagging: 5/20\n",
      "Repeating k-fold bagging: 6/20\n",
      "Repeating k-fold bagging: 7/20\n",
      "Repeating k-fold bagging: 8/20\n",
      "Repeating k-fold bagging: 9/20\n",
      "Repeating k-fold bagging: 10/20\n",
      "Repeating k-fold bagging: 11/20\n",
      "Repeating k-fold bagging: 12/20\n",
      "Repeating k-fold bagging: 13/20\n",
      "Repeating k-fold bagging: 14/20\n",
      "Repeating k-fold bagging: 15/20\n",
      "Repeating k-fold bagging: 16/20\n",
      "Repeating k-fold bagging: 17/20\n",
      "Repeating k-fold bagging: 18/20\n",
      "Repeating k-fold bagging: 19/20\n",
      "Repeating k-fold bagging: 20/20\n",
      "Completed 20/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 4997.0s of remaining time.\n",
      "\t-0.1416\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.04s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 9 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 4996.95s of the 4996.94s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused LightGBMXT_BAG_L2 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. A quick tip is to install via `pip install autogluon.tabular[lightgbm]==0.7.0`.\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 4996.9s of the 4996.9s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused LightGBM_BAG_L2 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. A quick tip is to install via `pip install autogluon.tabular[lightgbm]==0.7.0`.\n",
      "Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 4996.86s of the 4996.85s of remaining time.\n",
      "\t-0.1396\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.99s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ... Training model for up to 4995.41s of the 4995.4s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused CatBoost_BAG_L2 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==0.7.0`.\n",
      "Fitting model: ExtraTreesMSE_BAG_L2 ... Training model for up to 4995.36s of the 4995.36s of remaining time.\n",
      "\t-0.1362\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.62s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 4994.26s of the 4994.25s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused NeuralNetFastAI_BAG_L2 to fail during training (ImportError)... Skipping this model.\n",
      "\t\tImport fastai failed. A quick tip is to install via `pip install autogluon.tabular[fastai]==0.7.0`. \n",
      "Fitting model: XGBoost_BAG_L2 ... Training model for up to 4994.22s of the 4994.21s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused XGBoost_BAG_L2 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import xgboost` failed. A quick tip is to install via `pip install autogluon.tabular[xgboost]==0.7.0`.\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 4994.17s of the 4994.16s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused NeuralNetTorch_BAG_L2 to fail during training (ImportError)... Skipping this model.\n",
      "\t\tUnable to import dependency torch\n",
      "A quick tip is to install via `pip install torch`.\n",
      "The minimum torch version is currently 1.6.\n",
      "Fitting model: LightGBMLarge_BAG_L2 ... Training model for up to 4994.13s of the 4994.12s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused LightGBMLarge_BAG_L2 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. A quick tip is to install via `pip install autogluon.tabular[lightgbm]==0.7.0`.\n",
      "Repeating k-fold bagging: 2/20\n",
      "Repeating k-fold bagging: 3/20\n",
      "Repeating k-fold bagging: 4/20\n",
      "Repeating k-fold bagging: 5/20\n",
      "Repeating k-fold bagging: 6/20\n",
      "Repeating k-fold bagging: 7/20\n",
      "Repeating k-fold bagging: 8/20\n",
      "Repeating k-fold bagging: 9/20\n",
      "Repeating k-fold bagging: 10/20\n",
      "Repeating k-fold bagging: 11/20\n",
      "Repeating k-fold bagging: 12/20\n",
      "Repeating k-fold bagging: 13/20\n",
      "Repeating k-fold bagging: 14/20\n",
      "Repeating k-fold bagging: 15/20\n",
      "Repeating k-fold bagging: 16/20\n",
      "Repeating k-fold bagging: 17/20\n",
      "Repeating k-fold bagging: 18/20\n",
      "Repeating k-fold bagging: 19/20\n",
      "Repeating k-fold bagging: 20/20\n",
      "Completed 20/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 499.69s of the 4994.08s of remaining time.\n",
      "\t-0.1358\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 5.98s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20240406_120855/\")\n"
     ]
    }
   ],
   "source": [
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "X_train = pd.concat([X_train, y_train], axis=1)\n",
    "X_test = pd.concat([X_test, y_test], axis=1)\n",
    "train_data = TabularDataset(X_train)\n",
    "test_data = TabularDataset(X_test)\n",
    "predictor = TabularPredictor(label='SalePrice',eval_metric = 'root_mean_squared_error').fit(train_data, time_limit=5000,\n",
    "                                                   presets='best_quality',auto_stack=True,)  # For a fair comparison with auto-sklearn\n",
    "# leaderboard = predictor.leaderboard(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c957a8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: root_mean_squared_error on test data: -0.13554196496527673\n",
      "\tNote: Scores are always higher_is_better. This metric score can be multiplied by -1 to get the metric value.\n",
      "Evaluations on test data:\n",
      "{\n",
      "    \"root_mean_squared_error\": -0.13554196496527673,\n",
      "    \"mean_squared_error\": -0.018371624266648307,\n",
      "    \"mean_absolute_error\": -0.0895835047512191,\n",
      "    \"r2\": 0.9015512194348443,\n",
      "    \"pearsonr\": 0.9508906461329354,\n",
      "    \"median_absolute_error\": -0.05542907908809358\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "y_test = test_data['SalePrice']  # values to predict\n",
    "test_data_nolab = test_data.drop(columns=['SalePrice'])  # delete label column to prove we're not cheating\n",
    "y_pred = predictor.predict(test_data_nolab)\n",
    "\n",
    "perf = predictor.evaluate_predictions(y_true=y_test, y_pred=y_pred, auxiliary_metrics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b632c03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                    model  score_val  pred_time_val  fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0     WeightedEnsemble_L3  -0.136934       0.399790  3.075252                0.000137           0.022314            3       True          8\n",
      "1    ExtraTreesMSE_BAG_L2  -0.137130       0.326495  2.019529                0.071598           0.610772            2       True          7\n",
      "2  RandomForestMSE_BAG_L2  -0.140685       0.328055  2.442166                0.073159           1.033409            2       True          6\n",
      "3     WeightedEnsemble_L2  -0.142021       0.147970  1.441790                0.000138           0.036772            2       True          5\n",
      "4  RandomForestMSE_BAG_L1  -0.146030       0.071166  0.835099                0.071166           0.835099            1       True          3\n",
      "5    ExtraTreesMSE_BAG_L1  -0.146088       0.073959  0.565807                0.073959           0.565807            1       True          4\n",
      "6   KNeighborsDist_BAG_L1  -0.229760       0.002706  0.004112                0.002706           0.004112            1       True          2\n",
      "7   KNeighborsUnif_BAG_L1  -0.231418       0.107065  0.003739                0.107065           0.003739            1       True          1\n",
      "Number of models trained: 8\n",
      "Types of models trained:\n",
      "{'StackerEnsembleModel_XT', 'StackerEnsembleModel_RF', 'WeightedEnsembleModel', 'StackerEnsembleModel_KNN'}\n",
      "Bagging used: True  (with 8 folds)\n",
      "Multi-layer stack-ensembling used: True  (with 3 levels)\n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('float', [])     :   3 | ['GarageYrBlt', 'LotFrontage', 'MasVnrArea']\n",
      "('int', [])       :  34 | ['EnclosedPorch', 'OpenPorchSF', 'MoSold', 'FullBath', 'YrSold', ...]\n",
      "('int', ['bool']) : 265 | ['LandContour_Bnk', 'LandContour_HLS', 'LandContour_Low', 'LandContour_Lvl', 'LotConfig_Corner', ...]\n",
      "*** End of fit() summary ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/martin/miniconda3/envs/automl/lib/python3.9/site-packages/autogluon/core/utils/plots.py:138: UserWarning: AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: \"pip install bokeh==2.0.1\"\n",
      "  warnings.warn('AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: \"pip install bokeh==2.0.1\"')\n"
     ]
    }
   ],
   "source": [
    "results = predictor.fit_summary(show_plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46427d58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f799ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:automl]",
   "language": "python",
   "name": "conda-env-automl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
