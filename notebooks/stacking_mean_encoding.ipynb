{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "finished-counter",
   "metadata": {},
   "source": [
    "# Classification example demonstrating stacking and mean-encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3843a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184c016d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import catboost\n",
    "print(catboost.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97783dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets\n",
    "print(ipywidgets.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4034052",
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n",
    "print(graphviz.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2536dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "print(numpy.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c459ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import six, matplotlib, plotly, scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e278febe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "print(pandas.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "answering-figure",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "julian-designer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install ipywidgets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9efbc22",
   "metadata": {},
   "source": [
    "## This is the data-set, catboost became famous for:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "certified-staff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost.datasets import amazon\n",
    "employee_train, employee_test = amazon()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fuzzy-switzerland",
   "metadata": {},
   "source": [
    "The data is taken from a kaggle competition where catboost was shining:<br>\n",
    "[https://www.kaggle.com/c/amazon-employee-access-challenge](https://www.kaggle.com/c/amazon-employee-access-challenge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alternative-journey",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "injured-prediction",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = employee_train['ACTION']\n",
    "X = employee_train.drop('ACTION', axis=1)\n",
    "\n",
    "# Split into train & validation set\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, train_size=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unsigned-supplier",
   "metadata": {},
   "source": [
    "### catboost\n",
    "\n",
    "[2018: catboost the new kid on the block from russia](https://arxiv.org/pdf/1810.11363.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alert-serum",
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "# import ipywidgets\n",
    "cat_features = [*range(8)]\n",
    "model = CatBoostClassifier(custom_metric=['TotalF1'], early_stopping_rounds=100, eval_metric='AUC')\n",
    "\n",
    "model.fit(X_train, y_train, cat_features=cat_features,\n",
    "          eval_set=(X_val, y_val), plot=True, verbose=False, use_best_model=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moderate-island",
   "metadata": {},
   "source": [
    "### lightgbm in comparison\n",
    "\n",
    "Remark, that for catboost, we did no hyperparameter tuning at all.<br>\n",
    "\n",
    "Now, let's try lightgbm:\n",
    "\n",
    "__BUT__: since catboost has a early-stopping mechanism, we give the lightgbm-algorithm an eval_set and specify the 'early_stopping_rounds'. When the score on the validation-set is not becoming better than the best current score for the next 'early_stopping_rounds'-iterations, then the algorithm stops and returns the currently best result. We evaluate as well on the trainings-set to get a feeling for the degree of overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adverse-sellers",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm\n",
    "model = lightgbm.LGBMClassifier(metric='auc', n_estimators=5000, learning_rate=0.02, random_state=42, verbose=100,early_stopping_rounds=100)\n",
    "model.fit(X_train, y_train, eval_set=[(X_train, y_train), (X_val, y_val)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worthy-luther",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(X_train.shape, X_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liable-maximum",
   "metadata": {},
   "source": [
    "## Now, we add the mean-encoding manually as a preprocessing step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "understanding-spider",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install category_encoders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664cc4d1",
   "metadata": {},
   "source": [
    "### this is how lightgbm could mimick catboost:\n",
    "\n",
    "Since all variables are categorical, we add an OneHotEncoder. Since catboost became famous for its category-encoding, we add this as a second step. However, doing category-encoding always bears the risk of overfitting. This is why we do it via __stacking__.<br>\n",
    "If we improve on the solution above it could also be because of the OneHotEncoder and not because of the ValidatedStackedMeanEncoder. Hence, we have to test the pipeline first with just the OneHotEncoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stone-premium",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "sys.path.append(os.path.abspath('../scripts'))\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from validatedstackedmeanencoder import ValidatedStackedMeanEncoder\n",
    "numerical = []\n",
    "categorical = X_train.columns\n",
    "\n",
    "# not relevant\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(missing_values=np.nan, strategy='median')),\n",
    "    ('scaler', StandardScaler())])\n",
    "      \n",
    "    \n",
    "preprocessor2 = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numerical),\n",
    "        ('ohe', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical),\n",
    "        ('mean_enc', ValidatedStackedMeanEncoder(), categorical)\n",
    "        ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "falling-battlefield",
   "metadata": {},
   "source": [
    "### without mean-encoding\n",
    "The setup is the same, except that instead of the ValidatedStackedMeanEncoder, we pass FunctionTransformer(None) to the categorical variables - everything else is the same.<br>\n",
    "\n",
    "__Attentions__: because we want to keep the early_stopping_round (in order to mimick catboost), we first have to one-hot-encode also the validation data set. Otherwise it would have a different number of columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developed-switch",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "model = lightgbm.LGBMClassifier(boosting_type='gbdt', num_leaves=31, max_depth=- 1, learning_rate=0.02, \n",
    "                                n_estimators=5000, subsample_for_bin=20000, objective='binary', \n",
    "                                subsample=1.0, subsample_freq=0, colsample_bytree=1.0, \n",
    "                                n_jobs=- 1, silent=True, importance_type='split',\n",
    "                                is_unbalance = False, scale_pos_weight = 1.0, random_state=42, metric='auc',\n",
    "                                verbose=1, early_stopping_rounds=100\n",
    "                              )\n",
    "\n",
    "\n",
    "preprocessor1 = ColumnTransformer(transformers=[('num', numeric_transformer, numerical), \n",
    "                                            ('ohe', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical),\n",
    "                                            ('empty', FunctionTransformer(None), categorical)])\n",
    "custom_pipeline1 = make_pipeline(    \n",
    "            preprocessor1,\n",
    "            model\n",
    "            )\n",
    "X_train_preprocessed = preprocessor1.fit_transform(X_train)\n",
    "X_val_preprocessed = preprocessor1.transform(X_val)\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "custom_pipeline1.fit(X_train, y_train, lgbmclassifier__eval_set=[(X_train_preprocessed, y_train), (X_val_preprocessed, y_val)])\n",
    "#custom_pipeline.predict(test)\n",
    "print(\"model score: %.3f\" % custom_pipeline1.score(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handed-synthesis",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "print(classification_report(y_val, custom_pipeline1.predict(X_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "trying-hands",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"AUC score: \", roc_auc_score(y_val, custom_pipeline1.predict_proba(X_val)[:, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5407810f",
   "metadata": {},
   "source": [
    "### Conclusion: the OneHotEncoder did not improve the result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "injured-monaco",
   "metadata": {},
   "source": [
    "### Now with proper mean-encoding as done in catboost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorporate-exchange",
   "metadata": {},
   "source": [
    "we first transform the train and test set for the early stopping:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alike-floor",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "new_X = preprocessor2.fit_transform(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coated-observer",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_X_val = preprocessor2.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceramic-storage",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_pipeline = make_pipeline(\n",
    "            preprocessor2,\n",
    "            model\n",
    "            )\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "custom_pipeline.fit(X_train, y_train, lgbmclassifier__eval_set=[(new_X, y_train), (new_X_val, y_val)])\n",
    "#custom_pipeline.predict(test)\n",
    "print(\"model score: %.3f\" % custom_pipeline.score(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "headed-shoulder",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix, precision_recall_curve, roc_curve, roc_auc_score, log_loss\n",
    "\n",
    "print(classification_report(y_val, custom_pipeline.predict(X_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "municipal-worker",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"AUC score: \", roc_auc_score(y_val, custom_pipeline.predict_proba(X_val)[:, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "micro-diana",
   "metadata": {},
   "source": [
    "### Can we tune the parameters? HPO? - to be left as an exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conditional-chart",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "removable-reunion",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5f30b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('/Users/bima/Downloads/train.csv')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879d1a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['factor','idhogar','agesq','Target', 'Index', 'Id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3a213d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('/Users/bima/Downloads/costa_rica/train.csv')\n",
    "df2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d815bf7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df[['Id', 'Target']].merge(df2[['Id', 'Target']], on='Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6473b0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new[['Target_x', 'Target_y']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "matching",
   "language": "python",
   "name": "matching"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
