{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install dtreeviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# box cox transform\n",
    "from scipy.stats import boxcox\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data, descriptions of the variables and some examples can be found here:\n",
    "[house-pricese-from-kaggle-competition](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/martin/python/fhnw_lecture/notebooks\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data is from a kaggle-competition\n",
    "Attention, the test data-set has no target; This is the part you are supposed to upload to kaggle for estimation of your modelling performance;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/train.csv', sep=\",\")\n",
    "test = pd.read_csv('../data/test.csv')\n",
    "\n",
    "train_ID = train['Id']\n",
    "test_ID = test['Id']\n",
    "\n",
    "train.drop('Id', axis = 1, inplace = True)\n",
    "test.drop('Id', axis = 1, inplace = True)\n",
    "\n",
    "SalePrice = train['SalePrice']\n",
    "train.drop('SalePrice', axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### now, we want data-leakage\n",
    "We discussed at length, that train and test-set should be standardized and preprocessed independently; This is only true if we want a fair estimate of our algorithm's performance with new, unseen data.<br>\n",
    "In the current case we want our training-procedure to be biased towards the test-set, because the test-set performance is what counts in kaggle-competitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat((train, test))\n",
    "data.reset_index(drop = True, inplace = True)\n",
    "# categorical and numericalvariables:\n",
    "\n",
    "categorical = [var for var in train.columns if train[var].dtype=='O']\n",
    "numerical = [var for var in train.columns if train[var].dtype!='O']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some preprocessing steps\n",
    "### we fill missing values with the mean and add an extra variable indicating the missing position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_47978/4085472443.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data[val].fillna(data[val].mean(), inplace = True)\n",
      "/tmp/ipykernel_47978/4085472443.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data[val].fillna(data[val].mean(), inplace = True)\n",
      "/tmp/ipykernel_47978/4085472443.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data[val].fillna(data[val].mean(), inplace = True)\n",
      "/tmp/ipykernel_47978/4085472443.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data[val].fillna(data[val].mean(), inplace = True)\n",
      "/tmp/ipykernel_47978/4085472443.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data[val].fillna(data[val].mean(), inplace = True)\n",
      "/tmp/ipykernel_47978/4085472443.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data[val].fillna(data[val].mean(), inplace = True)\n",
      "/tmp/ipykernel_47978/4085472443.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data[val].fillna(data[val].mean(), inplace = True)\n",
      "/tmp/ipykernel_47978/4085472443.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data[val].fillna(data[val].mean(), inplace = True)\n",
      "/tmp/ipykernel_47978/4085472443.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data[val].fillna(data[val].mean(), inplace = True)\n",
      "/tmp/ipykernel_47978/4085472443.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data[val].fillna(data[val].mean(), inplace = True)\n",
      "/tmp/ipykernel_47978/4085472443.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data[val].fillna(data[val].mean(), inplace = True)\n",
      "/tmp/ipykernel_47978/4085472443.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data[val].fillna(data[val].mean(), inplace = True)\n",
      "/tmp/ipykernel_47978/4085472443.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data[val].fillna(data[val].mean(), inplace = True)\n",
      "/tmp/ipykernel_47978/4085472443.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data[val].fillna(data[val].mean(), inplace = True)\n",
      "/tmp/ipykernel_47978/4085472443.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data[val].fillna(data[val].mean(), inplace = True)\n",
      "/tmp/ipykernel_47978/4085472443.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data[val].fillna(data[val].mean(), inplace = True)\n",
      "/tmp/ipykernel_47978/4085472443.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data[val].fillna(data[val].mean(), inplace = True)\n",
      "/tmp/ipykernel_47978/4085472443.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data[val].fillna(data[val].mean(), inplace = True)\n",
      "/tmp/ipykernel_47978/4085472443.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data[val].fillna(data[val].mean(), inplace = True)\n",
      "/tmp/ipykernel_47978/4085472443.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data[val].fillna(data[val].mean(), inplace = True)\n",
      "/tmp/ipykernel_47978/4085472443.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data[val].fillna(data[val].mean(), inplace = True)\n",
      "/tmp/ipykernel_47978/4085472443.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data[val].fillna(data[val].mean(), inplace = True)\n",
      "/tmp/ipykernel_47978/4085472443.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data[val].fillna(data[val].mean(), inplace = True)\n",
      "/tmp/ipykernel_47978/4085472443.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data[val].fillna(data[val].mean(), inplace = True)\n",
      "/tmp/ipykernel_47978/4085472443.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data[val].fillna(data[val].mean(), inplace = True)\n",
      "/tmp/ipykernel_47978/4085472443.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data[val].fillna(data[val].mean(), inplace = True)\n",
      "/tmp/ipykernel_47978/4085472443.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data[val].fillna(data[val].mean(), inplace = True)\n",
      "/tmp/ipykernel_47978/4085472443.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data[val].fillna(data[val].mean(), inplace = True)\n",
      "/tmp/ipykernel_47978/4085472443.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data[val].fillna(data[val].mean(), inplace = True)\n",
      "/tmp/ipykernel_47978/4085472443.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data[val].fillna(data[val].mean(), inplace = True)\n",
      "/tmp/ipykernel_47978/4085472443.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data[val].fillna(data[val].mean(), inplace = True)\n",
      "/tmp/ipykernel_47978/4085472443.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data[val].fillna(data[val].mean(), inplace = True)\n",
      "/tmp/ipykernel_47978/4085472443.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data[val].fillna(data[val].mean(), inplace = True)\n",
      "/tmp/ipykernel_47978/4085472443.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data[val].fillna(data[val].mean(), inplace = True)\n",
      "/tmp/ipykernel_47978/4085472443.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data[val].fillna(data[val].mean(), inplace = True)\n",
      "/tmp/ipykernel_47978/4085472443.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data[val].fillna(data[val].mean(), inplace = True)\n"
     ]
    }
   ],
   "source": [
    "data[categorical] = data[categorical].fillna('None')\n",
    "\n",
    "\n",
    "## next, we substitute missing values with the mean of the variable and form new variables\n",
    "## indicating the missing values. Sometimes data is not missing at random and the fact that\n",
    "## data is missing might contain valuable information\n",
    "variables_na = []\n",
    "for val in numerical:\n",
    "    data[val + '_na'] = pd.isnull(data[val])\n",
    "    variables_na.append(val + '_na')\n",
    "    data[val].fillna(data[val].mean(), inplace = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### we transform the continuous variables to be more normally distributed\n",
    "[box-cox transform in short](https://www.statisticshowto.com/box-cox-transformation/#:~:text=A%20Box%20Cox%20transformation%20is,a%20broader%20number%20of%20tests.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_47978/3204645832.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[val + '_box_cox'] = new_vals\n",
      "/tmp/ipykernel_47978/3204645832.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[val + '_box_cox'] = new_vals\n",
      "/tmp/ipykernel_47978/3204645832.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[val + '_box_cox'] = new_vals\n",
      "/tmp/ipykernel_47978/3204645832.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[val + '_box_cox'] = new_vals\n",
      "/tmp/ipykernel_47978/3204645832.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[val + '_box_cox'] = new_vals\n",
      "/tmp/ipykernel_47978/3204645832.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[val + '_box_cox'] = new_vals\n",
      "/tmp/ipykernel_47978/3204645832.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[val + '_box_cox'] = new_vals\n",
      "/tmp/ipykernel_47978/3204645832.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[val + '_box_cox'] = new_vals\n",
      "/tmp/ipykernel_47978/3204645832.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[val + '_box_cox'] = new_vals\n",
      "/tmp/ipykernel_47978/3204645832.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[val + '_box_cox'] = new_vals\n",
      "/tmp/ipykernel_47978/3204645832.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[val + '_box_cox'] = new_vals\n",
      "/tmp/ipykernel_47978/3204645832.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[val + '_box_cox'] = new_vals\n",
      "/tmp/ipykernel_47978/3204645832.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[val + '_box_cox'] = new_vals\n",
      "/tmp/ipykernel_47978/3204645832.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[val + '_box_cox'] = new_vals\n",
      "/tmp/ipykernel_47978/3204645832.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[val + '_box_cox'] = new_vals\n",
      "/tmp/ipykernel_47978/3204645832.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[val + '_box_cox'] = new_vals\n",
      "/tmp/ipykernel_47978/3204645832.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[val + '_box_cox'] = new_vals\n",
      "/tmp/ipykernel_47978/3204645832.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[val + '_box_cox'] = new_vals\n",
      "/tmp/ipykernel_47978/3204645832.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[val + '_box_cox'] = new_vals\n",
      "/tmp/ipykernel_47978/3204645832.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[val + '_box_cox'] = new_vals\n",
      "/tmp/ipykernel_47978/3204645832.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[val + '_box_cox'] = new_vals\n",
      "/tmp/ipykernel_47978/3204645832.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[val + '_box_cox'] = new_vals\n",
      "/tmp/ipykernel_47978/3204645832.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[val + '_box_cox'] = new_vals\n",
      "/tmp/ipykernel_47978/3204645832.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[val + '_box_cox'] = new_vals\n"
     ]
    }
   ],
   "source": [
    "## box-cox transform is variance stabilizing. It is meant to make \n",
    "## the variable more normaly distributed    \n",
    "box_cox = []\n",
    "for val in numerical:\n",
    "    new_vals, lamb = boxcox(data[val] + 1)\n",
    "    if np.abs(lamb) < 8:\n",
    "        data[val + '_box_cox'] = new_vals\n",
    "        box_cox.append(val)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### we demonstrate the effect of the box-cox transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnYAAAHWCAYAAAD6oMSKAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/H5lhTAAAACXBIWXMAAA9hAAAPYQGoP6dpAABAS0lEQVR4nO3df1RU953H/9dEYECKU5HAMA1a2qJrA7GKKUK6FaOiNGhbszGJSs2pNUmNpqz6tSGebEi+KWTtRu3ixk1cq0a05Ow3MU1PLBGaiLFoolg2alhqGhIwYSS4OIjiQPR+/0i8zfBLUX5eno9z7jnM5/Oemc/HcS4v7sz9XJthGIYAAAAw4N3Q1wMAAABA9yDYAQAAWATBDgAAwCIIdgAAABZBsAMAALAIgh0AAIBFEOwAAAAsgmAHAABgEX59PYCecunSJX3yyScKCQmRzWbr6+EA6EWGYejs2bNyuVy64QZr/P3KPg0YvLqyT7NssPvkk08UFRXV18MA0Ieqq6t100039fUwugX7NABXs0+zbLALCQmR9Pk/wrBhw/p4NAB6U0NDg6Kiosz9gBWwTwMGr67s0ywb7C5/VDFs2DB2gsAgZaWPLNmnAbiafZo1vnwCAAAAgh0AAIBVEOwA4Ao+/vhjLViwQCNGjNDQoUP1ne98R6WlpWa/YRjKysqSy+VSUFCQkpOTdfz4cZ/H8Hq9WrZsmcLCwhQcHKzZs2fr5MmTvT0VABZHsAOATtTX1+u2226Tv7+//vjHP+q9997TM888o69+9atmzZo1a7R27Vpt2LBBhw4dktPp1PTp03X27FmzJiMjQ7t27VJ+fr7279+vxsZGpaWl6eLFi30wKwBWZTMMw+jrQfSEhoYGORwOeTwevmgMDDLd+f5/5JFH9Oc//1lvvfVWu/2GYcjlcikjI0O//OUvJX1+dC4iIkL/+q//qgceeEAej0c33nijtm/frrvvvlvS35cv2b17t2bMmNGrcwIwsHTl/c8ROwDoxKuvvqqJEyfqrrvuUnh4uMaPH69NmzaZ/ZWVlXK73UpJSTHb7Ha7Jk+erJKSEklSaWmpWlpafGpcLpdiY2PNGgDoDgQ7AOjEBx98oI0bNyomJkavv/66HnzwQT388MN64YUXJElut1uSFBER4XO/iIgIs8/tdisgIEDDhw/vsKY1r9erhoYGnw0ArsSy69gBQHe4dOmSJk6cqOzsbEnS+PHjdfz4cW3cuFE/+clPzLrW60sZhnHFNac6q8nJydETTzxxnaMHMNhwxA4AOhEZGalvf/vbPm1jx45VVVWVJMnpdEpSmyNvtbW15lE8p9Op5uZm1dfXd1jTWmZmpjwej7lVV1d3y3wAWBvBDgA6cdttt6miosKn7a9//atGjRolSYqOjpbT6VRhYaHZ39zcrOLiYiUlJUmS4uPj5e/v71NTU1OjY8eOmTWt2e128yoTXG0CwNXio1gA6MQ///M/KykpSdnZ2Zo7d67eeecdPf/883r++eclff4RbEZGhrKzsxUTE6OYmBhlZ2dr6NChmjdvniTJ4XBo0aJFWrFihUaMGKHQ0FCtXLlScXFxmjZtWl9OD4DFEOwAoBO33nqrdu3apczMTD355JOKjo7W+vXrNX/+fLNm1apVampq0pIlS1RfX6+EhATt2bPH54Ld69atk5+fn+bOnaumpiZNnTpVW7du1ZAhQ/piWgAsinXsAFiOFd//VpwTgKvDOnYAAACDEMEOAADAIgh2AAAAFsHJE1ehqqpKdXV17faFhYVp5MiRvTwiAMD16Gi/zj4dAx3B7gqqqqo0ZsxYXbhwvt3+wMChqqgoZ0cAAANEZ/t19ukY6Ah2V1BXV/fFmz9P0thWveW6cGGB6urq2AkAwADR8X6dfToGPoLdVRsraUJfDwIA0G3Yr8N6OHkCAADAIgh2AAAAFkGwAwAAsAiCHQAAgEUQ7AAAACyCYAcAAGARBDsAAACLINgBAABYRJeD3b59+zRr1iy5XC7ZbDa98sorPv02m63d7de//rVZk5yc3Kb/nnvu8Xmc+vp6paeny+FwyOFwKD09XWfOnLmmSQIAAAwGXQ52586d07hx47Rhw4Z2+2tqany23/72t7LZbLrzzjt96hYvXuxT99xzz/n0z5s3T2VlZSooKFBBQYHKysqUnp7e1eECAAAMGl2+pFhqaqpSU1M77Hc6nT63f//732vKlCn6xje+4dM+dOjQNrWXlZeXq6CgQAcPHlRCQoIkadOmTUpMTFRFRYXGjBnT1WEDAABYXo9+x+7UqVN67bXXtGjRojZ9O3bsUFhYmG6++WatXLlSZ8+eNfsOHDggh8NhhjpJmjRpkhwOh0pKStp9Lq/Xq4aGBp8NAABgMOnyEbuu2LZtm0JCQjRnzhyf9vnz5ys6OlpOp1PHjh1TZmam/ud//keFhYWSJLfbrfDw8DaPFx4eLrfb3e5z5eTk6Iknnuj+SQAAAAwQPRrsfvvb32r+/PkKDAz0aV+8eLH5c2xsrGJiYjRx4kQdOXJEEyZMkPT5SRitGYbRbrskZWZmavny5ebthoYGRUVFdcc0AAAABoQeC3ZvvfWWKioq9OKLL16xdsKECfL399eJEyc0YcIEOZ1OnTp1qk3dp59+qoiIiHYfw263y263X/e4AQAABqoe+47d5s2bFR8fr3Hjxl2x9vjx42ppaVFkZKQkKTExUR6PR++8845Z8/bbb8vj8SgpKamnhgwAADCgdfmIXWNjo95//33zdmVlpcrKyhQaGqqRI0dK+vxj0P/+7//WM8880+b+f/vb37Rjxw794Ac/UFhYmN577z2tWLFC48eP12233SZJGjt2rGbOnKnFixeby6Dcf//9SktL44xYAACADnT5iN3hw4c1fvx4jR8/XpK0fPlyjR8/Xv/yL/9i1uTn58swDN17771t7h8QEKA//elPmjFjhsaMGaOHH35YKSkpKioq0pAhQ8y6HTt2KC4uTikpKUpJSdEtt9yi7du3X8scAQAABoUuH7FLTk6WYRid1tx///26//772+2LiopScXHxFZ8nNDRUeXl5XR0eAADAoMW1YgEAACyCYAcAAGARBDsAAACLINgBAABYBMEOAADAIgh2AAAAFkGwAwAAsAiCHQAAgEUQ7AAAACyCYAcAAGARBDsAAACLINgBAABYBMEOAADAIgh2AAAAFkGwAwAAsAiCHQAAgEUQ7AAAACzCr68HAABAT6iqqlJdXV2b9vLy8j4YDdA7CHYAAMupqqrSmDFjdeHC+b4eCtCrCHYAAMupq6v7ItTlSRrbqne3pMd6f1BALyDYAQAsbKykCa3a+CgW1sXJEwAAABZBsAMAALAIgh0AAIBFEOwAAAAsgmAHAABgEQQ7AAAAiyDYAQAAWATBDgAAwCIIdgAAABZBsAMAALAIgh0AAIBFEOwAAAAsgmAHAJ3IysqSzWbz2ZxOp9lvGIaysrLkcrkUFBSk5ORkHT9+3OcxvF6vli1bprCwMAUHB2v27Nk6efJkb08FwCBAsAOAK7j55ptVU1NjbkePHjX71qxZo7Vr12rDhg06dOiQnE6npk+frrNnz5o1GRkZ2rVrl/Lz87V//341NjYqLS1NFy9e7IvpALAwv74eAAD0d35+fj5H6S4zDEPr16/X6tWrNWfOHEnStm3bFBERoZ07d+qBBx6Qx+PR5s2btX37dk2bNk2SlJeXp6ioKBUVFWnGjBm9OhcA1sYROwC4ghMnTsjlcik6Olr33HOPPvjgA0lSZWWl3G63UlJSzFq73a7JkyerpKREklRaWqqWlhafGpfLpdjYWLOmPV6vVw0NDT4bAFwJwQ4AOpGQkKAXXnhBr7/+ujZt2iS3262kpCSdPn1abrdbkhQREeFzn4iICLPP7XYrICBAw4cP77CmPTk5OXI4HOYWFRXVzTMDYEUEOwDoRGpqqu68807FxcVp2rRpeu211yR9/pHrZTabzec+hmG0aWvtSjWZmZnyeDzmVl1dfR2zADBYEOwAoAuCg4MVFxenEydOmN+7a33krba21jyK53Q61dzcrPr6+g5r2mO32zVs2DCfDQCuhGAHAF3g9XpVXl6uyMhIRUdHy+l0qrCw0Oxvbm5WcXGxkpKSJEnx8fHy9/f3qampqdGxY8fMGgDoLpwVCwCdWLlypWbNmqWRI0eqtrZWTz31lBoaGrRw4ULZbDZlZGQoOztbMTExiomJUXZ2toYOHap58+ZJkhwOhxYtWqQVK1ZoxIgRCg0N1cqVK82PdgGgOxHsAKATJ0+e1L333qu6ujrdeOONmjRpkg4ePKhRo0ZJklatWqWmpiYtWbJE9fX1SkhI0J49exQSEmI+xrp16+Tn56e5c+eqqalJU6dO1datWzVkyJC+mhYAiyLYAUAn8vPzO+232WzKyspSVlZWhzWBgYHKzc1Vbm5uN48OAHzxHTsAAACL6HKw27dvn2bNmiWXyyWbzaZXXnnFp/++++5rc13FSZMm+dRczXUT6+vrlZ6ebq7hlJ6erjNnznR5ggAAAINFl4PduXPnNG7cOG3YsKHDmpkzZ/pcV3H37t0+/Vdz3cR58+aprKxMBQUFKigoUFlZmdLT07s6XAAAgEGjy9+xS01NVWpqaqc1dru93esqSrqq6yaWl5eroKBABw8eVEJCgiRp06ZNSkxMVEVFhcaMGdPVYQMAAFhej3zHbu/evQoPD9fo0aO1ePFi1dbWmn1Xc93EAwcOyOFwmKFOkiZNmiSHw9HhtRW5riIAABjsuj3YpaamaseOHXrjjTf0zDPP6NChQ7r99tvl9XolXd11E91ut8LDw9s8dnh4eIfXVuS6igAAYLDr9uVO7r77bvPn2NhYTZw4UaNGjdJrr72mOXPmdHi/1tdNbO8aip1dWzEzM1PLly83bzc0NBDuAADAoNLjy51ERkZq1KhROnHihKSru26i0+nUqVOn2jzWp59+2uG1FbmuIgAAGOx6PNidPn1a1dXVioyMlHR1101MTEyUx+PRO++8Y9a8/fbb8ng8XFsRAACgA13+KLaxsVHvv/++ebuyslJlZWUKDQ1VaGiosrKydOeddyoyMlIffvihHn30UYWFhenHP/6xpKu7buLYsWM1c+ZMLV68WM8995wk6f7771daWhpnxAIAAHSgy8Hu8OHDmjJlinn78vfaFi5cqI0bN+ro0aN64YUXdObMGUVGRmrKlCl68cUXu3zdxB07dujhhx82z56dPXt2p2vnAQAADHZdDnbJyckyDKPD/tdff/2Kj3E1100MDQ1VXl5eV4cHAAAwaHGtWAAAAIsg2AEAAFgEwQ4AAMAiCHYAAAAWQbADAACwCIIdAACARRDsAAAALIJgBwAAYBEEOwAAAIsg2AEAAFgEwQ4AAMAiCHYAAAAWQbADAACwCIIdAACARRDsAAAALIJgBwAAYBEEOwAAAIsg2AEAAFgEwQ4AAMAi/Pp6AAAA9Cfl5eXttoeFhWnkyJG9PBqgawh2AABIkmok3aAFCxa02xsYOFQVFeWEO/RrBDsAACRJZyRdkpQnaWyrvnJduLBAdXV1BDv0awQ7AAB8jJU0oa8HAVwTTp4AAACwCIIdAACARRDsAAAALIJgBwAAYBEEOwAAAIsg2AEAAFgEwQ4AAMAiCHYAAAAWQbADAACwCIIdAACARRDsAAAALIJgBwAAYBEEOwAAAIsg2AEAAFgEwQ4AAMAiCHYAAAAWQbADAACwCIIdAACARRDsAAAALIJgBwAAYBEEOwAAAIsg2AEAAFhEl4Pdvn37NGvWLLlcLtlsNr3yyitmX0tLi375y18qLi5OwcHBcrlc+slPfqJPPvnE5zGSk5Nls9l8tnvuucenpr6+Xunp6XI4HHI4HEpPT9eZM2euaZIAAACDQZeD3blz5zRu3Dht2LChTd/58+d15MgRPfbYYzpy5Ihefvll/fWvf9Xs2bPb1C5evFg1NTXm9txzz/n0z5s3T2VlZSooKFBBQYHKysqUnp7e1eECQLfKycmRzWZTRkaG2WYYhrKysuRyuRQUFKTk5GQdP37c535er1fLli1TWFiYgoODNXv2bJ08ebKXRw/A6vy6eofU1FSlpqa22+dwOFRYWOjTlpubq+9+97uqqqrSyJEjzfahQ4fK6XS2+zjl5eUqKCjQwYMHlZCQIEnatGmTEhMTVVFRoTFjxnR12ABw3Q4dOqTnn39et9xyi0/7mjVrtHbtWm3dulWjR4/WU089penTp6uiokIhISGSpIyMDP3hD39Qfn6+RowYoRUrVigtLU2lpaUaMmRIX0wHgAX1+HfsPB6PbDabvvrVr/q079ixQ2FhYbr55pu1cuVKnT171uw7cOCAHA6HGeokadKkSXI4HCopKWn3ebxerxoaGnw2AOgujY2Nmj9/vjZt2qThw4eb7YZhaP369Vq9erXmzJmj2NhYbdu2TefPn9fOnTslfb4f3Lx5s5555hlNmzZN48ePV15eno4ePaqioqK+mhIAC+rRYHfhwgU98sgjmjdvnoYNG2a2z58/X7/73e+0d+9ePfbYY3rppZc0Z84cs9/tdis8PLzN44WHh8vtdrf7XDk5Oeb38RwOh6Kiorp/QgAGrYceekh33HGHpk2b5tNeWVkpt9utlJQUs81ut2vy5MnmH6KlpaVqaWnxqXG5XIqNje3wj1UAuBZd/ij2arW0tOiee+7RpUuX9Oyzz/r0LV682Pw5NjZWMTExmjhxoo4cOaIJEyZIkmw2W5vHNAyj3XZJyszM1PLly83bDQ0NhDsA3SI/P19HjhzRoUOH2vRd/mMzIiLCpz0iIkIfffSRWRMQEOBzpO9yTUd/rHq9Xnm9XvM2n0IAuBo9csSupaVFc+fOVWVlpQoLC32O1rVnwoQJ8vf314kTJyRJTqdTp06dalP36aefttl5Xma32zVs2DCfDQCuV3V1tX7xi18oLy9PgYGBHda1/qOzsz9Er6aGTyEAXItuD3aXQ92JEydUVFSkESNGXPE+x48fV0tLiyIjIyVJiYmJ8ng8euedd8yat99+Wx6PR0lJSd09ZADoUGlpqWpraxUfHy8/Pz/5+fmpuLhY//7v/y4/Pz/zj83WR95qa2vNPqfTqebmZtXX13dY01pmZqY8Ho+5VVdX98DsAFhNl4NdY2OjysrKVFZWJunz75eUlZWpqqpKn332mf7pn/5Jhw8f1o4dO3Tx4kW53W653W41NzdLkv72t7/pySef1OHDh/Xhhx9q9+7duuuuuzR+/HjddtttkqSxY8dq5syZWrx4sQ4ePKiDBw9q8eLFSktL44xYAL1q6tSpOnr0qLnfKysr08SJEzV//nyVlZXpG9/4hpxOp8+KAM3NzSouLjb/EI2Pj5e/v79PTU1NjY4dO9bhH6t8CgHgWnT5O3aHDx/WlClTzNuXv9e2cOFCZWVl6dVXX5Ukfec73/G535tvvqnk5GQFBAToT3/6k37zm9+osbFRUVFRuuOOO/T444/7nPK/Y8cOPfzww+aXjWfPnt3u2nkA0JNCQkIUGxvr0xYcHKwRI0aY7RkZGcrOzlZMTIxiYmKUnZ2toUOHat68eZI+Xwpq0aJFWrFihUaMGKHQ0FCtXLlScXFxbU7GAIDr0eVgl5ycLMMwOuzvrE+SoqKiVFxcfMXnCQ0NVV5eXleHBwC9btWqVWpqatKSJUtUX1+vhIQE7dmzx1zDTpLWrVsnPz8/zZ07V01NTZo6daq2bt3KGnYAulWPnRULAFa1d+9en9s2m01ZWVnKysrq8D6BgYHKzc1Vbm5uzw4OwKDW4wsUAwAAoHcQ7AAAACyCYAcAAGARBDsAAACLINgBAABYBMEOAADAIgh2AAAAFkGwAwAAsAiCHQAAgEUQ7AAAACyCYAcAAGARBDsAAACLINgBAABYBMEOAADAIgh2AAAAFkGwAwAAsAiCHQAAgEUQ7AAAACyCYAcAAGARBDsAAACLINgBAABYBMEOAADAIgh2AAAAFkGwAwAAsAiCHQAAgEUQ7AAAACyCYAcAAGARBDsAAACLINgBAABYBMEOAADAIgh2AAAAFkGwAwAAsAiCHQAAgEUQ7AAAACyCYAcAAGARBDsAAACLINgBAABYBMEOAADAIgh2AAAAFkGwAwAAsAiCHQAAgEUQ7AAAACyCYAcAAGARXQ52+/bt06xZs+RyuWSz2fTKK6/49BuGoaysLLlcLgUFBSk5OVnHjx/3qfF6vVq2bJnCwsIUHBys2bNn6+TJkz419fX1Sk9Pl8PhkMPhUHp6us6cOdPlCQIAAAwWXQ52586d07hx47Rhw4Z2+9esWaO1a9dqw4YNOnTokJxOp6ZPn66zZ8+aNRkZGdq1a5fy8/O1f/9+NTY2Ki0tTRcvXjRr5s2bp7KyMhUUFKigoEBlZWVKT0+/hikCAAAMDn5dvUNqaqpSU1Pb7TMMQ+vXr9fq1as1Z84cSdK2bdsUERGhnTt36oEHHpDH49HmzZu1fft2TZs2TZKUl5enqKgoFRUVacaMGSovL1dBQYEOHjyohIQESdKmTZuUmJioiooKjRkz5lrnCwAAYFnd+h27yspKud1upaSkmG12u12TJ09WSUmJJKm0tFQtLS0+NS6XS7GxsWbNgQMH5HA4zFAnSZMmTZLD4TBrAAAA4KvLR+w643a7JUkRERE+7REREfroo4/MmoCAAA0fPrxNzeX7u91uhYeHt3n88PBws6Y1r9crr9dr3m5oaLj2iQAAAAxAPXJWrM1m87ltGEabttZa17RX39nj5OTkmCdaOBwORUVFXcPIAQAABq5uDXZOp1OS2hxVq62tNY/iOZ1ONTc3q76+vtOaU6dOtXn8Tz/9tM3RwMsyMzPl8XjMrbq6+rrnAwAAMJB0a7CLjo6W0+lUYWGh2dbc3Kzi4mIlJSVJkuLj4+Xv7+9TU1NTo2PHjpk1iYmJ8ng8euedd8yat99+Wx6Px6xpzW63a9iwYT4bAADAYNLl79g1Njbq/fffN29XVlaqrKxMoaGhGjlypDIyMpSdna2YmBjFxMQoOztbQ4cO1bx58yRJDodDixYt0ooVKzRixAiFhoZq5cqViouLM8+SHTt2rGbOnKnFixfrueeekyTdf//9SktL44xYAACADnQ52B0+fFhTpkwxby9fvlyStHDhQm3dulWrVq1SU1OTlixZovr6eiUkJGjPnj0KCQkx77Nu3Tr5+flp7ty5ampq0tSpU7V161YNGTLErNmxY4cefvhh8+zZ2bNnd7h2HgAAAK4h2CUnJ8swjA77bTabsrKylJWV1WFNYGCgcnNzlZub22FNaGio8vLyujo8AACAQYtrxQIAAFgEwQ4AAMAiCHYAAAAWQbADAACwCIIdAACARRDsAKATGzdu1C233GIufJ6YmKg//vGPZr9hGMrKypLL5VJQUJCSk5N1/Phxn8fwer1atmyZwsLCFBwcrNmzZ+vkyZO9PRUAgwDBDgA6cdNNN+npp5/W4cOHdfjwYd1+++364Q9/aIa3NWvWaO3atdqwYYMOHTokp9Op6dOn6+zZs+ZjZGRkaNeuXcrPz9f+/fvV2NiotLQ0Xbx4sa+mBcCiCHYA0IlZs2bpBz/4gUaPHq3Ro0frV7/6lb7yla/o4MGDMgxD69ev1+rVqzVnzhzFxsZq27ZtOn/+vHbu3ClJ8ng82rx5s5555hlNmzZN48ePV15eno4ePaqioqI+nh0AqyHYAcBVunjxovLz83Xu3DklJiaqsrJSbrfbvEKO9Pl1qydPnqySkhJJUmlpqVpaWnxqXC6XYmNjzZr2eL1eNTQ0+GwAcCUEOwC4gqNHj+orX/mK7Ha7HnzwQe3atUvf/va35Xa7JUkRERE+9REREWaf2+1WQECAhg8f3mFNe3JycuRwOMwtKiqqm2cFwIoIdgBwBWPGjFFZWZkOHjyon//851q4cKHee+89s99ms/nUG4bRpq21K9VkZmbK4/GYW3V19fVNAsCgQLADgCsICAjQt771LU2cOFE5OTkaN26cfvOb38jpdEpSmyNvtbW15lE8p9Op5uZm1dfXd1jTHrvdbp6Je3kDgCsh2AFAFxmGIa/Xq+joaDmdThUWFpp9zc3NKi4uVlJSkiQpPj5e/v7+PjU1NTU6duyYWQMA3cWvrwcAAP3Zo48+qtTUVEVFRens2bPKz8/X3r17VVBQIJvNpoyMDGVnZysmJkYxMTHKzs7W0KFDNW/ePEmSw+HQokWLtGLFCo0YMUKhoaFauXKl4uLiNG3atD6enTVUVVWprq7Op628vLyPRgP0LYIdAHTi1KlTSk9PV01NjRwOh2655RYVFBRo+vTpkqRVq1apqalJS5YsUX19vRISErRnzx6FhISYj7Fu3Tr5+flp7ty5ampq0tSpU7V161YNGTKkr6ZlGVVVVRozZqwuXDjf10MB+gWCHQB0YvPmzZ3222w2ZWVlKSsrq8OawMBA5ebmKjc3t5tHh7q6ui9CXZ6ksV/q2S3psb4ZFNCHCHYAAAsYK2nCl27zUSwGJ06eAAAAsAiCHQAAgEUQ7AAAACyCYAcAAGARBDsAAACLINgBAABYBMEOAADAIgh2AAAAFkGwAwAAsAiCHQAAgEUQ7AAAACyCYAcAAGARBDsAAACLINgBAABYBMEOAADAIgh2AAAAFkGwAwAAsAi/vh4AAAADRXl5eZu2sLAwjRw5sg9GA7RFsAMA4IpqJN2gBQsWtOkJDByqiopywh36BT6KBQDgis5IuiQpT1Lpl7Y8XbhwXnV1dX04NuDvOGIHAMBVGytpQl8PAugQR+wAAAAsgmAHAABgEQQ7AAAAiyDYAQAAWATBDgAAwCIIdgAAABZBsAMAALCIbg92X//612Wz2dpsDz30kCTpvvvua9M3adIkn8fwer1atmyZwsLCFBwcrNmzZ+vkyZPdPVQAAABL6fZgd+jQIdXU1JhbYWGhJOmuu+4ya2bOnOlTs3v3bp/HyMjI0K5du5Sfn6/9+/ersbFRaWlpunjxYncPFwAAwDK6/coTN954o8/tp59+Wt/85jc1efJks81ut8vpdLZ7f4/Ho82bN2v79u2aNm2aJCkvL09RUVEqKirSjBkzunvIAAAAltCj37Frbm5WXl6efvrTn8pms5nte/fuVXh4uEaPHq3FixertrbW7CstLVVLS4tSUlLMNpfLpdjYWJWUlPTkcAEAAAa0Hr1W7CuvvKIzZ87ovvvuM9tSU1N11113adSoUaqsrNRjjz2m22+/XaWlpbLb7XK73QoICNDw4cN9HisiIkJut7vD5/J6vfJ6vebthoaGbp8PAABAf9ajwW7z5s1KTU2Vy+Uy2+6++27z59jYWE2cOFGjRo3Sa6+9pjlz5nT4WIZh+Bz1ay0nJ0dPPPFE9wwcAABgAOqxj2I/+ugjFRUV6Wc/+1mndZGRkRo1apROnDghSXI6nWpublZ9fb1PXW1trSIiIjp8nMzMTHk8HnOrrq6+/kkAAAAMID0W7LZs2aLw8HDdcccdndadPn1a1dXVioyMlCTFx8fL39/fPJtWkmpqanTs2DElJSV1+Dh2u13Dhg3z2QAAAAaTHvko9tKlS9qyZYsWLlwoP7+/P0VjY6OysrJ05513KjIyUh9++KEeffRRhYWF6cc//rEkyeFwaNGiRVqxYoVGjBih0NBQrVy5UnFxceZZsgAAAGirR4JdUVGRqqqq9NOf/tSnfciQITp69KheeOEFnTlzRpGRkZoyZYpefPFFhYSEmHXr1q2Tn5+f5s6dq6amJk2dOlVbt27VkCFDemK4AAAAltAjwS4lJUWGYbRpDwoK0uuvv37F+wcGBio3N1e5ubk9MTwAAABL4lqxAAAAFkGwAwAAsAiCHQAAgEUQ7AAAACyCYAcAAGARBDsAAACLINgBAABYBMEOAADAInpkgeKBqqqqSnV1dT5t5eXlfTQaAACAriHYfaGqqkpjxozVhQvn+3ooAAAA14Rg94W6urovQl2epLFf6tkt6bG+GRQAAEAXEOzaGCtpwpdu81EsAAAYGDh5AgAAwCIIdgAAABZBsAMAALAIgh0AAIBFEOwAAAAsgmAHAABgEQQ7AOhETk6Obr31VoWEhCg8PFw/+tGPVFFR4VNjGIaysrLkcrkUFBSk5ORkHT9+3KfG6/Vq2bJlCgsLU3BwsGbPnq2TJ0/25lQADAIEOwDoRHFxsR566CEdPHhQhYWF+uyzz5SSkqJz586ZNWvWrNHatWu1YcMGHTp0SE6nU9OnT9fZs2fNmoyMDO3atUv5+fnav3+/GhsblZaWposXL/bFtABYFAsUA0AnCgoKfG5v2bJF4eHhKi0t1fe//30ZhqH169dr9erVmjNnjiRp27ZtioiI0M6dO/XAAw/I4/Fo8+bN2r59u6ZNmyZJysvLU1RUlIqKijRjxoxenxcAa+KIHQB0gcfjkSSFhoZKkiorK+V2u5WSkmLW2O12TZ48WSUlJZKk0tJStbS0+NS4XC7FxsaaNa15vV41NDT4bABwJQQ7ALhKhmFo+fLl+t73vqfY2FhJktvtliRFRET41EZERJh9brdbAQEBGj58eIc1reXk5MjhcJhbVFRUd08HgAUR7ADgKi1dulTvvvuufve737Xps9lsPrcNw2jT1lpnNZmZmfJ4POZWXV197QMHMGgQ7ADgKixbtkyvvvqq3nzzTd10001mu9PplKQ2R95qa2vNo3hOp1PNzc2qr6/vsKY1u92uYcOG+WwAcCUEOwDohGEYWrp0qV5++WW98cYbio6O9umPjo6W0+lUYWGh2dbc3Kzi4mIlJSVJkuLj4+Xv7+9TU1NTo2PHjpk1ANAdOCsWADrx0EMPaefOnfr973+vkJAQ88icw+FQUFCQbDabMjIylJ2drZiYGMXExCg7O1tDhw7VvHnzzNpFixZpxYoVGjFihEJDQ7Vy5UrFxcWZZ8kCQHcg2AFAJzZu3ChJSk5O9mnfsmWL7rvvPknSqlWr1NTUpCVLlqi+vl4JCQnas2ePQkJCzPp169bJz89Pc+fOVVNTk6ZOnaqtW7dqyJAhvTUVAIMAwQ4AOmEYxhVrbDabsrKylJWV1WFNYGCgcnNzlZub242jAwBffMcOAADAIgh2AAAAFkGwAwAAsAiCHQAAgEUQ7AAAACyCYAcAAGARBDsAAACLINgBAABYBMEOAADAIgh2AAAAFkGwAwAAsAiCHQAAgEUQ7AAAACyCYAcAAGARBDsAAACLINgBAABYRLcHu6ysLNlsNp/N6XSa/YZhKCsrSy6XS0FBQUpOTtbx48d9HsPr9WrZsmUKCwtTcHCwZs+erZMnT3b3UAEAACzFryce9Oabb1ZRUZF5e8iQIebPa9as0dq1a7V161aNHj1aTz31lKZPn66KigqFhIRIkjIyMvSHP/xB+fn5GjFihFasWKG0tDSVlpb6PBYAYHCoqqpSXV1dm/by8vI+GA3Qf/VIsPPz8/M5SneZYRhav369Vq9erTlz5kiStm3bpoiICO3cuVMPPPCAPB6PNm/erO3bt2vatGmSpLy8PEVFRamoqEgzZszoiSEDAPqpqqoqjRkzVhcunO/roQD9Xo98x+7EiRNyuVyKjo7WPffcow8++ECSVFlZKbfbrZSUFLPWbrdr8uTJKikpkSSVlpaqpaXFp8blcik2NtasAQAMHnV1dV+EujxJpa22/7cvhwb0O91+xC4hIUEvvPCCRo8erVOnTumpp55SUlKSjh8/LrfbLUmKiIjwuU9ERIQ++ugjSZLb7VZAQICGDx/epuby/dvj9Xrl9XrN2w0NDd01JQBAvzBW0oRWbXwUC3xZtwe71NRU8+e4uDglJibqm9/8prZt26ZJkyZJkmw2m899DMNo09balWpycnL0xBNPXMfIAQAABrYeX+4kODhYcXFxOnHihPm9u9ZH3mpra82jeE6nU83Nzaqvr++wpj2ZmZnyeDzmVl1d3c0zAQAA6N96PNh5vV6Vl5crMjJS0dHRcjqdKiwsNPubm5tVXFyspKQkSVJ8fLz8/f19ampqanTs2DGzpj12u13Dhg3z2QAAAAaTbv8oduXKlZo1a5ZGjhyp2tpaPfXUU2poaNDChQtls9mUkZGh7OxsxcTEKCYmRtnZ2Ro6dKjmzZsnSXI4HFq0aJFWrFihESNGKDQ0VCtXrlRcXJx5liwAAADa6vZgd/LkSd17772qq6vTjTfeqEmTJungwYMaNWqUJGnVqlVqamrSkiVLVF9fr4SEBO3Zs8dcw06S1q1bJz8/P82dO1dNTU2aOnWqtm7dyhp2AAAAnej2YJefn99pv81mU1ZWlrKysjqsCQwMVG5urnJzc7t5dAAAANbFtWIBAAAsgmAHAABgEQQ7AAAAiyDYAQAAWATBDgAAwCIIdgAAABZBsAMAALAIgh0AAIBFEOwAAAAsgmAHAABgEQQ7AAAAiyDYAQAAWATBDgAAwCIIdgAAABZBsAMAALAIgh0AAIBFEOwAAAAsgmAHAABgEQQ7AAAAiyDYAQAAWATBDgAAwCIIdgAAABbh19cDAABgoCsvL2+3PSwsTCNHjuzl0WAwI9gBAHDNaiTdoAULFrTbGxg4VBUV5YQ79BqCHQAA1+yMpEuS8iSNbdVXrgsXFqiuro5gh15DsAMA4LqNlTShrwcBcPIEAACAVRDsAAAALIJgBwAAYBEEOwAAAIsg2AEAAFgEwQ4AOrFv3z7NmjVLLpdLNptNr7zyik+/YRjKysqSy+VSUFCQkpOTdfz4cZ8ar9erZcuWKSwsTMHBwZo9e7ZOnjzZi7MAMFgQ7ACgE+fOndO4ceO0YcOGdvvXrFmjtWvXasOGDTp06JCcTqemT5+us2fPmjUZGRnatWuX8vPztX//fjU2NiotLU0XL17srWkAGCRYxw4AOpGamqrU1NR2+wzD0Pr167V69WrNmTNHkrRt2zZFRERo586deuCBB+TxeLR582Zt375d06ZNkyTl5eUpKipKRUVFmjFjRq/NBYD1Eey6QXvXCOT6gID1VVZWyu12KyUlxWyz2+2aPHmySkpK9MADD6i0tFQtLS0+NS6XS7GxsSopKSHYAehWBLvr0vE1Ark+IGB9brdbkhQREeHTHhERoY8++sisCQgI0PDhw9vUXL5/e7xer7xer3m7oaGhu4YNwML4jt11OaO/XyOw9Etbni5cOK+6uro+HBuA3mKz2XxuG4bRpq21K9Xk5OTI4XCYW1RUVLeMFYC1Eey6xeVrBF7eWl8IGoAVOZ1OSWpz5K22ttY8iud0OtXc3Kz6+voOa9qTmZkpj8djbtXV1d08egBWRLADgGsUHR0tp9OpwsJCs625uVnFxcVKSkqSJMXHx8vf39+npqamRseOHTNr2mO32zVs2DCfDQCuhO/YAUAnGhsb9f7775u3KysrVVZWptDQUI0cOVIZGRnKzs5WTEyMYmJilJ2draFDh2revHmSJIfDoUWLFmnFihUaMWKEQkNDtXLlSsXFxZlnyQJAdyHYAUAnDh8+rClTppi3ly9fLklauHChtm7dqlWrVqmpqUlLlixRfX29EhIStGfPHoWEhJj3Wbdunfz8/DR37lw1NTVp6tSp2rp1q4YMGdLr8wFgbQQ7AOhEcnKyDMPosN9msykrK0tZWVkd1gQGBio3N1e5ubk9MEIA+Du+YwcAAGARBDsAAACLINgBAABYRLcHu5ycHN16660KCQlReHi4fvSjH6miosKn5r777pPNZvPZJk2a5FPj9Xq1bNkyhYWFKTg4WLNnz9bJkye7e7gAAACW0e3Brri4WA899JAOHjyowsJCffbZZ0pJSdG5c+d86mbOnKmamhpz2717t09/RkaGdu3apfz8fO3fv1+NjY1KS0vTxYsXu3vIAAAAltDtZ8UWFBT43N6yZYvCw8NVWlqq73//+2a73W43V21vzePxaPPmzdq+fbu5zlNeXp6ioqJUVFTERbMBAADa0ePfsfN4PJKk0NBQn/a9e/cqPDxco0eP1uLFi1VbW2v2lZaWqqWlRSkpKWaby+VSbGysSkpK2n0er9erhoYGnw0AAGAw6dF17AzD0PLly/W9731PsbGxZntqaqruuusujRo1SpWVlXrsscd0++23q7S0VHa7XW63WwEBARo+fLjP40VERLS5JuNlOTk5euKJJ3pyOgCAHlZVVaW6ujqftvLy8j4aDTDw9GiwW7p0qd59913t37/fp/3uu+82f46NjdXEiRM1atQovfbaa5ozZ06Hj2cYhmw2W7t9mZmZ5orwktTQ0KCoqKjrnAEAoLdUVVVpzJixunDhfF8PBRiweizYLVu2TK+++qr27dunm266qdPayMhIjRo1SidOnJAkOZ1ONTc3q76+3ueoXW1tbYcXzbbb7bLb7d03AQBAr6qrq/si1OVJGvulnt2SHuubQQEDTLd/x84wDC1dulQvv/yy3njjDUVHR1/xPqdPn1Z1dbUiIyMlSfHx8fL391dhYaFZU1NTo2PHjnUY7AAAVjFW0oQvbVf+PQLgc91+xO6hhx7Szp079fvf/14hISHmd+IcDoeCgoLU2NiorKws3XnnnYqMjNSHH36oRx99VGFhYfrxj39s1i5atEgrVqzQiBEjFBoaqpUrVyouLs48SxYAAAC+uj3Ybdy4UdLnF87+si1btui+++7TkCFDdPToUb3wwgs6c+aMIiMjNWXKFL344osKCQkx69etWyc/Pz/NnTtXTU1Nmjp1qrZu3aohQ4Z095ABAAAsoduDnWEYnfYHBQXp9ddfv+LjBAYGKjc3V7m5ud01NAAAAEvjWrEAAAAW0aPLnQAA0B7WqwN6BsEOANCrWK8O6DkEOwBAr2K9OqDnEOwAAH3k8np1l/FRLHC9OHkCAADAIjhiBwBAD2rvpJCwsDCNHDmyD0YDqyPYAQDQI2ok3aAFCxa06QkMHKqKinLCHbodH8UCANAjzki6pM9PEin90panCxfOt1nuBegOHLEDAPSI9taqkwbjenWtTxIBeg7BDgDQ7VirDugbBDsAQLfreK06ifXqgJ5DsAMA9KD2PoYcbB/FAr2HkycAAAAsgmAHAABgEQQ7AAAAiyDYAQAAWATBDgAAwCIIdgAAABZBsAMAALAI1rEDAKAPdHRptbCwMI0cObKXRwOrINgBANCraiTdoAULFrTbGxg4VBUV5YQ7XBOCHQDgulRVVamurs6nraOjUZCkM5Iuqf3LrZXrwoUFqqurI9jhmhDsAACm9kKa1PHHg1VVVRozZuwX14VF17R3uTXg+hDsAGCQ6Si81dTU6M4775LX29Smr6OPB+vq6r4Ida2PPu2W9Fi3jhvAlRHsAGAQubojbK1D2tV8PNj66BMfxQJ9gWAHAINIx0fYpL8fZeMjQmCgItgBwKDUXnjr/ChbeydEcJIE0L8Q7AAAV9D58hwA+g+CHQDgCs6o4+U5OEkC6E8IdgCAq9T1j28B9C6uFQsAAGARBDsAAACLINgBAABYBMEOAADAIgh2AAAAFsFZsT2oo4U7O7qYNgAAUvu/P/jdgatBsOsRnS/m2dHFtAGgO1VVVamurs6njStF9Hcd//7gdweuBsGuR5xRx4t5Xs3FtAHg+lRVVWnMmLFfXBcWA8cZtf/7g98duDoEux7FhbQB9I26urovQl3rgMCVIgYGfn/g2hDsAMDSWgcEPooFrIyzYgEAACyCI3YAAAwQrLaAKyHYAQDQ73W+2oLdHqiXXvr/FBkZ6dNO4Bt8CHYAAPR7Z9TxagtvyetdrrS0tDb36s4lUtpbPucyAmT/0e+D3bPPPqtf//rXqqmp0c0336z169frH//xH/t6WNeNxSeBwceq+zP0pvbOli1XZ0ukvPXWWxo71jcMer1e2e32dp+hvb6amhrdeedd8nqb2r0Pa+z1H/062L344ovKyMjQs88+q9tuu03PPfecUlNT9d577w3g/zwdH07v6FC6ROgDBjpr7s/Qv7QOfZ19fDtE0sUOHqezPtZn7e/6dbBbu3atFi1apJ/97GeSpPXr1+v111/Xxo0blZOT08eju1Zn1P5fVh0fSpc6Dn1d/atLIiQCfcGa+zP0b2fU/u+by2sZthfSOuq73N7x+nqD4ZOojj6O7k/z7LfBrrm5WaWlpXrkkUd82lNSUlRSUtKm3uv1yuv1mrc9Ho8kqaGh4aqer7Gx8YufSiU1fqmnvIP2zvqu5j7nW/V9qs/fgP+PpKhW9zkur/f5DkLfDV/crz3t9wUEBCov7wVFRET4Vt9wgy5dav+xOurjPv33+a12H6fTKafT2e5jtXb5fW8YxlXV97Su7s+kgbhP68n79PXzD/T7tP59c6GD9s76Lre39/wHJNnaPTLY0e8bqf/uazrqO3XqlBYsWKjm5rYfR1/LPHtsn2b0Ux9//LEhyfjzn//s0/6rX/3KGD16dJv6xx9/3JDExsbGZm7V1dW9tcvqVFf3Z4bBPo2Nja3tdjX7tH57xO4ym83mc9swjDZtkpSZmanly5ebty9duqT/+7//04gRI9qtv6yhoUFRUVGqrq7WsGHDum/g/YBV58a8Bp7enpthGDp79qxcLlePP1dXXO3+TLr2fdpAYeX/71fC3Jl7V+felX1avw12YWFhGjJkiNxut097bW1tu4c67XZ7m++TffWrX73q5xs2bJhl/5NZdW7Ma+Dpzbk5HI5eeZ6r0dX9mXT9+7SBwsr/36+EuTP3rrjafVq/vaRYQECA4uPjVVhY6NNeWFiopKSkPhoVAHQd+zMAvaXfHrGTpOXLlys9PV0TJ05UYmKinn/+eVVVVenBBx/s66EBQJewPwPQG/p1sLv77rt1+vRpPfnkk6qpqVFsbKx2796tUaNGddtz2O12Pf744x0uGTKQWXVuzGvgsfLcrlZv7M8GksH8f4K5M/eeZDOMfrIeAAAAAK5Lv/2OHQAAALqGYAcAAGARBDsAAACLINgBAABYxKAPds8++6yio6MVGBio+Ph4vfXWW302lqysLNlsNp/ty9eRMwxDWVlZcrlcCgoKUnJyso4fP+7zGF6vV8uWLVNYWJiCg4M1e/ZsnTx50qemvr5e6enpcjgccjgcSk9P15kzZ3xqqqqqNGvWLAUHByssLEwPP/ywmpubr2oe+/bt06xZs+RyuWSz2fTKK6/49Pe3eRw9elSTJ09WUFCQvva1r+nJJ59s93p8V5rXfffd1+b1mzRpUr+fV05Ojm699VaFhIQoPDxcP/rRj1RRUeFTM1BfM/St7njPDFTd9b4aiK5m7lZ97Tdu3KhbbrnFXIQ4MTFRf/zjH83+XnnNr/HSh5aQn59v+Pv7G5s2bTLee+894xe/+IURHBxsfPTRR30ynscff9y4+eabjZqaGnOrra01+59++mkjJCTEeOmll4yjR48ad999txEZGWk0NDSYNQ8++KDxta99zSgsLDSOHDliTJkyxRg3bpzx2WefmTUzZ840YmNjjZKSEqOkpMSIjY010tLSzP7PPvvMiI2NNaZMmWIcOXLEKCwsNFwul7F06dKrmsfu3buN1atXGy+99JIhydi1a5dPf3+ah8fjMSIiIox77rnHOHr0qPHSSy8ZISEhxr/92791eV4LFy40Zs6c6fP6nT592qemP85rxowZxpYtW4xjx44ZZWVlxh133GGMHDnSaGxsHPCvGfpWd7xnBqruel8NRFczd6u+9q+++qrx2muvGRUVFUZFRYXx6KOPGv7+/saxY8cMw+id13xQB7vvfve7xoMPPujT9g//8A/GI4880ifjefzxx41x48a123fp0iXD6XQaTz/9tNl24cIFw+FwGP/5n/9pGIZhnDlzxvD39zfy8/PNmo8//ti44YYbjIKCAsMwDOO9994zJBkHDx40aw4cOGBIMv73f//XMIzPd8Y33HCD8fHHH5s1v/vd7wy73W54PJ4uzan1zry/zePZZ581HA6HceHCBbMmJyfHcLlcxqVLl656Xobx+Y7qhz/8YYf3GQjzMgzDqK2tNSQZxcXFhmFY5zVD37qW94yVXMv7yipaz90wBtdrP3z4cOO//uu/eu01H7QfxTY3N6u0tFQpKSk+7SkpKSopKemjUUknTpyQy+VSdHS07rnnHn3wwQeSpMrKSrndbp/x2u12TZ482RxvaWmpWlpafGpcLpdiY2PNmgMHDsjhcCghIcGsmTRpkhwOh09NbGysz8WGZ8yYIa/Xq9LS0uuaX3+bx4EDBzR58mSfBSNnzJihTz75RB9++GGX57d3716Fh4dr9OjRWrx4sWpra82+gTIvj8cjSQoNDZVk/dcMfauz94yVXMv7yipaz/0yq7/2Fy9eVH5+vs6dO6fExMRee80HbbCrq6vTxYsX21yAOyIios2FuntLQkKCXnjhBb3++uvatGmT3G63kpKSdPr0aXNMnY3X7XYrICBAw4cP77QmPDy8zXOHh4f71LR+nuHDhysgIOC6/2362zzaq7l8u6tzTU1N1Y4dO/TGG2/omWee0aFDh3T77bfL6/UOmHkZhqHly5fre9/7nmJjY33qrfiaoW9d6T1jFdf6vrKC9uYuWfu1P3r0qL7yla/IbrfrwQcf1K5du/Ttb3+7117zfn1Jsd5gs9l8bhuG0aatt6Smppo/x8XFKTExUd/85je1bds280ul1zLe1jXt1V9LzfXoT/Nobywd3bczd999t/lzbGysJk6cqFGjRum1117TnDlzOrxff5rX0qVL9e6772r//v1t+qz4mqFvXet7ZqDp7vfVQNLR3K382o8ZM0ZlZWU6c+aMXnrpJS1cuFDFxcVmf0+/5oP2iF1YWJiGDBnSJiXX1ta2SdN9JTg4WHFxcTpx4oR5dmxn43U6nWpublZ9fX2nNadOnWrzXJ9++qlPTevnqa+vV0tLy3X/2/S3ebRXc/njgOuda2RkpEaNGqUTJ04MiHktW7ZMr776qt58803ddNNNZvtges3Qt1q/Z6zget5XA11Hc2+PlV77gIAAfetb39LEiROVk5OjcePG6Te/+U2vveaDNtgFBAQoPj5ehYWFPu2FhYVKSkrqo1H58nq9Ki8vV2RkpKKjo+V0On3G29zcrOLiYnO88fHx8vf396mpqanRsWPHzJrExER5PB698847Zs3bb78tj8fjU3Ps2DHV1NSYNXv27JHdbld8fPx1zam/zSMxMVH79u3zWU5jz549crlc+vrXv35dcz19+rSqq6sVGRnZr+dlGIaWLl2ql19+WW+88Yaio6N9+gfTa4a+1fo9M5B1x/tqoLrS3Ntjpde+NcMw5PV6e+8177bTMAagy8udbN682XjvvfeMjIwMIzg42Pjwww/7ZDwrVqww9u7da3zwwQfGwYMHjbS0NCMkJMQcz9NPP204HA7j5ZdfNo4ePWrce++97S45cdNNNxlFRUXGkSNHjNtvv73dJSduueUW48CBA8aBAweMuLi4dpecmDp1qnHkyBGjqKjIuOmmm656uZOzZ88af/nLX4y//OUvhiRj7dq1xl/+8hdzGZn+NI8zZ84YERERxr333mscPXrUePnll41hw4a1u3RGZ/M6e/assWLFCqOkpMSorKw03nzzTSMxMdH42te+1u/n9fOf/9xwOBzG3r17fZYeOH/+vFkzUF8z9K3ueM8MVN31vhqIrjR3K7/2mZmZxr59+4zKykrj3XffNR599FHjhhtuMPbs2WMYRu+85oM62BmGYfzHf/yHMWrUKCMgIMCYMGGCz+nYve3yejb+/v6Gy+Uy5syZYxw/ftzsv3TpkvH4448bTqfTsNvtxve//33j6NGjPo/R1NRkLF261AgNDTWCgoKMtLQ0o6qqyqfm9OnTxvz5842QkBAjJCTEmD9/vlFfX+9T89FHHxl33HGHERQUZISGhhpLly71WV6iM2+++aYhqc22cOHCfjmPd9991/jHf/xHw263G06n08jKymp32YzO5nX+/HkjJSXFuPHGGw1/f39j5MiRxsKFC9uMuT/Oq705STK2bNli1gzU1wx9qzveMwNVd72vBqIrzd3Kr/1Pf/pTM1PceOONxtSpU81QZxi985rbDIPl2gEAAKxg0H7HDgAAwGoIdgAAABZBsAMAALAIgh0AAIBFEOwAAAAsgmAHAABgEQQ7AAAAiyDYAQAAWATBDgAAwCIIdgAAABZBsAMAALAIgh0AAIBF/P8Za1oCv0+w5gAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "var = 'LotArea'\n",
    "# 2 fitures\n",
    "ax = plt.subplot(1, 2, 1)\n",
    "# non-transformed variable    \n",
    "ax.hist(data[var], bins = int(180/5),\n",
    "         color = 'blue', edgecolor = 'black')\n",
    "\n",
    "ax = plt.subplot(1, 2, 2)\n",
    "# transformed_variable\n",
    "ax.hist(data[var + '_box_cox'], bins = int(180/5),\n",
    "         color = 'blue', edgecolor = 'black')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### we encode categorical data as dummy-variables (aka one-hot encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as already announced, categorical data is one-hot encoded (dummy-coded)  \n",
    "\n",
    "data_base = pd.get_dummies(data[[col for col in data.columns if col not in variables_na]])\n",
    "data_na = pd.get_dummies(data[variables_na])\n",
    "\n",
    "# we have to cast every variable's data type to float32 for our next 'trick' \n",
    "data_base = data_base.astype(np.float32)\n",
    "data_na = data_na.astype(np.float32)\n",
    "data_numerical = data[numerical]\n",
    "\n",
    "data = pd.concat([data_base, data_na], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### we compute the feature importance in order to get the most relevant variable\n",
    "With this trick we identify the most relevant variables. Like this, we are adding interaction-terms only for the most relevant variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingRegressor(max_depth=4, n_estimators=32)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;GradientBoostingRegressor<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html\">?<span>Documentation for GradientBoostingRegressor</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>GradientBoostingRegressor(max_depth=4, n_estimators=32)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingRegressor(max_depth=4, n_estimators=32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the number of variables is quiet high. We want to add interaction terms for the most important\n",
    "# variables. Therefore, we want to compute some variable-importance measure. This is\n",
    "# done by the help of gradient boosted trees:\n",
    "gbm = GradientBoostingRegressor(n_estimators = 32, max_depth = 4)\n",
    "gbm.fit(data.iloc[0:len(train_ID)].values, SalePrice.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# we sort the variables (indizes) by variable importance\n",
    "indizes = np.argsort(gbm.feature_importances_)\n",
    "result = permutation_importance(gbm, data.iloc[0:len(train_ID)], SalePrice, n_repeats=10,\n",
    "                                random_state=42, n_jobs=2)\n",
    "sorted_idx = result.importances_mean.argsort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 1, 1)\n",
    "plt.boxplot(result.importances[sorted_idx[-15:]].T,\n",
    "            vert=False, labels=np.array(data.columns)[sorted_idx[-15:]])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## for the most important features we compute the interactions\n",
    "### in the first step we include only the most important 15 variables to form interaction-terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_47978/1353596089.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/1353596089.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/1353596089.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/1353596089.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/1353596089.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/1353596089.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/1353596089.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n"
     ]
    }
   ],
   "source": [
    "# import a tool for getting all possible n over 2 combinations of these variables\n",
    "from itertools import combinations\n",
    "# and add the interactions\n",
    "interactions = []\n",
    "for comb in list(combinations(data.columns[sorted_idx[-15:]], 2)):\n",
    "    data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
    "    interactions.append(comb[0] + '_x_' + comb[1])\n",
    "\n",
    "data_interactions = data[interactions]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### in the second step we include even 55 variables to form interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
      "/tmp/ipykernel_47978/305782326.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n"
     ]
    }
   ],
   "source": [
    "interactions2 = []\n",
    "for comb in list(combinations(data.columns[sorted_idx[-55:]], 2)):\n",
    "    data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
    "    interactions2.append(comb[0] + '_x_' + comb[1])\n",
    "\n",
    "data_interactions2 = data[interactions2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1.\n",
    "# now, we have different data sets\n",
    "# the base set with missing values imputed by the mean and no other feature engineering\n",
    "# box-cox transformed variables are removen\n",
    "base = data_base[[col for col in data_base.columns if not col.endswith('_box_cox')]]\n",
    "## 2.\n",
    "# box_cox is admitted; original variables removed\n",
    "with_box_cox = data_base[[col for col in data_base.columns if not col in box_cox]]\n",
    "## 3.\n",
    "# variables indicating formerly missing values are included\n",
    "with_na = pd.concat([with_box_cox, data_na], axis = 1)\n",
    "## 4.\n",
    "# all interaction terms of the 55 most important variables are added\n",
    "with_interactions = pd.concat([with_na, data_interactions], axis = 1)\n",
    "## 5.\n",
    "## we exagerate the number of interactions\n",
    "with_interactions2 = pd.concat([with_na, data_interactions2], axis=1)\n",
    "## the target variable is log-transformed\n",
    "y = np.log1p(SalePrice)\n",
    "\n",
    "## since we want to try elasticnet, we have to find the optimal parameter for \n",
    "# lambda (amount of regularization) and for alpha (ratio of lasso and ridge mixing)\n",
    "lamb = 10**(np.linspace(-1, 0.2, 15))\n",
    "# ratio\n",
    "ratio = np.linspace(0, 1, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### excurs: parameter sampling on a logarithmic scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sample some of the parameters on a logrithmic scale:\n",
    "https://www.coursera.org/lecture/deep-neural-network/using-an-appropriate-scale-to-pick-hyperparameters-3rdqN\n",
    "\n",
    "$b^y = x; \\; y = log_b(x)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0001  , 0.025075, 0.05005 , 0.075025, 0.1     ])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linspace(0.0001, 0.1, 5) # 5 equally spaced values from 0.0001 to 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, there is no value between 0.0001 and 0.001 and no value between 0.001 and 0.01. But there are three values between 0.01 and 0.1<br>\n",
    "Now, compare to this solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0001    , 0.00056234, 0.00316228, 0.01778279, 0.1       ])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10**np.linspace(-4, -1, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### we transform the SalePrice (y) as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_47978/991790603.py:2: RuntimeWarning: divide by zero encountered in log\n",
      "  display(np.log(0), np.log(1), np.log(2),\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-inf"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.6931471805599453"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.6931471805599453"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# the function np.log1p is well defined at 0\n",
    "display(np.log(0), np.log(1), np.log(2),\n",
    "        np.log1p(1), np.log1p(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = plt.subplot(1, 2, 1)\n",
    "# non-transformed variable    \n",
    "ax.hist(SalePrice, bins = int(180/5),\n",
    "         color = 'blue', edgecolor = 'black')\n",
    "\n",
    "ax = plt.subplot(1, 2, 2)\n",
    "# transformed_variable\n",
    "ax.hist(np.log1p(SalePrice), bins = int(180/5),\n",
    "         color = 'blue', edgecolor = 'black')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### polynomial features\n",
    "We can even do more. The function `sklearn.preprocessing.PolynomialFeatures`generates all polynomials of a certain degree; for example, if the degree = 2 and there are two variables (a and b) it generates all $a, b, a\\cdot b, a^2\\,\\, \\text{and}\\,\\,  b^2$ terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "pl = PolynomialFeatures(3, interaction_only = False, include_bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "polies = pl.fit_transform(data[data.columns[sorted_idx[-15:]]])\n",
    "X_polynomial = pd.concat([with_na, pd.DataFrame(polies,columns = [str(i) for i in range(polies.shape[1])])], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['YearBuilt', 'YearRemodAdd', 'LowQualFinSF', 'BsmtHalfBath',\n",
       "       '3SsnPorch', 'PoolArea', 'YrSold', 'MSSubClass_box_cox',\n",
       "       'LotFrontage_box_cox', 'LotArea_box_cox',\n",
       "       ...\n",
       "       'SaleType_New', 'SaleType_None', 'SaleType_Oth', 'SaleType_WD',\n",
       "       'SaleCondition_Abnorml', 'SaleCondition_AdjLand',\n",
       "       'SaleCondition_Alloca', 'SaleCondition_Family', 'SaleCondition_Normal',\n",
       "       'SaleCondition_Partial'],\n",
       "      dtype='object', length=310)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_box_cox.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.878e+00, tolerance: 1.891e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.055e+00, tolerance: 1.800e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.908e+00, tolerance: 1.901e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.591e+00, tolerance: 1.881e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.209e+00, tolerance: 1.837e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.861e+00, tolerance: 1.881e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.211e+00, tolerance: 1.901e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.358e+00, tolerance: 1.800e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.541e+00, tolerance: 1.837e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.189e+00, tolerance: 1.891e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.549e+00, tolerance: 1.891e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.561e+00, tolerance: 1.901e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.176e+00, tolerance: 1.881e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.921e+00, tolerance: 1.837e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.707e+00, tolerance: 1.800e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.356e+00, tolerance: 1.837e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.963e+00, tolerance: 1.891e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.542e+00, tolerance: 1.881e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.965e+00, tolerance: 1.901e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.109e+00, tolerance: 1.800e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.440e+00, tolerance: 1.891e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.570e+00, tolerance: 1.800e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.851e+00, tolerance: 1.837e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.966e+00, tolerance: 1.881e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.429e+00, tolerance: 1.901e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.098e+00, tolerance: 1.800e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.986e+00, tolerance: 1.891e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.961e+00, tolerance: 1.901e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.456e+00, tolerance: 1.881e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.414e+00, tolerance: 1.837e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.020e+00, tolerance: 1.881e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.610e+00, tolerance: 1.891e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.053e+00, tolerance: 1.837e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.700e+00, tolerance: 1.800e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.568e+00, tolerance: 1.901e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.669e+00, tolerance: 1.881e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.774e+00, tolerance: 1.837e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.387e+00, tolerance: 1.800e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.032e+01, tolerance: 1.891e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.026e+01, tolerance: 1.901e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.017e+01, tolerance: 1.800e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.105e+01, tolerance: 1.901e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.041e+01, tolerance: 1.881e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.113e+01, tolerance: 1.891e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.059e+01, tolerance: 1.837e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.105e+01, tolerance: 1.800e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.150e+01, tolerance: 1.837e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.194e+01, tolerance: 1.901e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.204e+01, tolerance: 1.891e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.126e+01, tolerance: 1.881e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.308e+01, tolerance: 1.891e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.223e+01, tolerance: 1.881e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.295e+01, tolerance: 1.901e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.253e+01, tolerance: 1.837e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.205e+01, tolerance: 1.800e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.369e+01, tolerance: 1.837e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.318e+01, tolerance: 1.800e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.424e+01, tolerance: 1.891e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.333e+01, tolerance: 1.881e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.409e+01, tolerance: 1.901e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.538e+01, tolerance: 1.901e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.498e+01, tolerance: 1.837e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.446e+01, tolerance: 1.800e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.458e+01, tolerance: 1.881e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.555e+01, tolerance: 1.891e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.682e+01, tolerance: 1.901e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.600e+01, tolerance: 1.881e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.589e+01, tolerance: 1.800e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.643e+01, tolerance: 1.837e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.702e+01, tolerance: 1.891e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.804e+01, tolerance: 1.837e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.867e+01, tolerance: 1.891e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.749e+01, tolerance: 1.800e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.844e+01, tolerance: 1.901e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.760e+01, tolerance: 1.881e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "least error is: 0.13822808131208597, best parameters are: [(0.3981071705534972, 0.0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.017e+00, tolerance: 1.800e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.694e+00, tolerance: 1.891e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.040e+00, tolerance: 1.837e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.396e+00, tolerance: 1.881e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.644e+00, tolerance: 1.901e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.947e+00, tolerance: 1.901e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.314e+00, tolerance: 1.800e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.359e+00, tolerance: 1.837e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.680e+00, tolerance: 1.881e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.998e+00, tolerance: 1.891e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.009e+00, tolerance: 1.881e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.351e+00, tolerance: 1.891e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.726e+00, tolerance: 1.837e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.658e+00, tolerance: 1.800e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.297e+00, tolerance: 1.901e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.054e+00, tolerance: 1.800e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.700e+00, tolerance: 1.901e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.758e+00, tolerance: 1.891e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.390e+00, tolerance: 1.881e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.148e+00, tolerance: 1.837e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.630e+00, tolerance: 1.837e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.226e+00, tolerance: 1.891e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.828e+00, tolerance: 1.881e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.510e+00, tolerance: 1.800e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.164e+00, tolerance: 1.901e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.764e+00, tolerance: 1.891e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.180e+00, tolerance: 1.837e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.033e+00, tolerance: 1.800e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.333e+00, tolerance: 1.881e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.696e+00, tolerance: 1.901e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.379e+00, tolerance: 1.891e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.303e+00, tolerance: 1.901e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.805e+00, tolerance: 1.837e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.631e+00, tolerance: 1.800e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.913e+00, tolerance: 1.881e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.315e+00, tolerance: 1.800e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.997e+00, tolerance: 1.901e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.008e+01, tolerance: 1.891e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.515e+00, tolerance: 1.837e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.576e+00, tolerance: 1.881e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.009e+01, tolerance: 1.800e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.088e+01, tolerance: 1.891e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.079e+01, tolerance: 1.901e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.032e+01, tolerance: 1.837e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.033e+01, tolerance: 1.881e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.179e+01, tolerance: 1.891e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.098e+01, tolerance: 1.800e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.168e+01, tolerance: 1.901e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.123e+01, tolerance: 1.837e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.120e+01, tolerance: 1.881e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.270e+01, tolerance: 1.901e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.225e+01, tolerance: 1.837e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.198e+01, tolerance: 1.800e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.282e+01, tolerance: 1.891e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.218e+01, tolerance: 1.881e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.340e+01, tolerance: 1.837e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.311e+01, tolerance: 1.800e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.385e+01, tolerance: 1.901e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.399e+01, tolerance: 1.891e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.330e+01, tolerance: 1.881e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.530e+01, tolerance: 1.891e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.439e+01, tolerance: 1.800e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.469e+01, tolerance: 1.837e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.456e+01, tolerance: 1.881e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.514e+01, tolerance: 1.901e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.599e+01, tolerance: 1.881e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.677e+01, tolerance: 1.891e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.582e+01, tolerance: 1.800e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.659e+01, tolerance: 1.901e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.613e+01, tolerance: 1.837e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.823e+01, tolerance: 1.901e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.775e+01, tolerance: 1.837e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.759e+01, tolerance: 1.881e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.842e+01, tolerance: 1.891e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.743e+01, tolerance: 1.800e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "least error is: 0.13065759218112855, best parameters are: [(0.1, 0.1111111111111111)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.683e+00, tolerance: 1.891e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.010e+00, tolerance: 1.800e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.028e+00, tolerance: 1.837e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.386e+00, tolerance: 1.881e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.640e+00, tolerance: 1.901e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.988e+00, tolerance: 1.891e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.347e+00, tolerance: 1.837e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.308e+00, tolerance: 1.800e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.671e+00, tolerance: 1.881e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.943e+00, tolerance: 1.901e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.293e+00, tolerance: 1.901e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.651e+00, tolerance: 1.800e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.001e+00, tolerance: 1.881e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.341e+00, tolerance: 1.891e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.714e+00, tolerance: 1.837e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.047e+00, tolerance: 1.800e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.697e+00, tolerance: 1.901e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.136e+00, tolerance: 1.837e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.749e+00, tolerance: 1.891e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.382e+00, tolerance: 1.881e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.218e+00, tolerance: 1.891e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.503e+00, tolerance: 1.800e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.618e+00, tolerance: 1.837e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.821e+00, tolerance: 1.881e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.161e+00, tolerance: 1.901e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.756e+00, tolerance: 1.891e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.326e+00, tolerance: 1.881e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.026e+00, tolerance: 1.800e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.169e+00, tolerance: 1.837e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.693e+00, tolerance: 1.901e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.372e+00, tolerance: 1.891e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.907e+00, tolerance: 1.881e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.301e+00, tolerance: 1.901e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.624e+00, tolerance: 1.800e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.795e+00, tolerance: 1.837e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.008e+01, tolerance: 1.891e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.995e+00, tolerance: 1.901e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.505e+00, tolerance: 1.837e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.308e+00, tolerance: 1.800e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.571e+00, tolerance: 1.881e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.009e+01, tolerance: 1.800e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.088e+01, tolerance: 1.891e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.078e+01, tolerance: 1.901e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.031e+01, tolerance: 1.837e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.033e+01, tolerance: 1.881e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.168e+01, tolerance: 1.901e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.179e+01, tolerance: 1.891e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.097e+01, tolerance: 1.800e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.122e+01, tolerance: 1.837e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.119e+01, tolerance: 1.881e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.281e+01, tolerance: 1.891e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.197e+01, tolerance: 1.800e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.218e+01, tolerance: 1.881e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.224e+01, tolerance: 1.837e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.269e+01, tolerance: 1.901e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.311e+01, tolerance: 1.800e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.384e+01, tolerance: 1.901e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.329e+01, tolerance: 1.881e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.398e+01, tolerance: 1.891e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.339e+01, tolerance: 1.837e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.468e+01, tolerance: 1.837e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.456e+01, tolerance: 1.881e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.529e+01, tolerance: 1.891e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.438e+01, tolerance: 1.800e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.513e+01, tolerance: 1.901e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.676e+01, tolerance: 1.891e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.612e+01, tolerance: 1.837e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.598e+01, tolerance: 1.881e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.581e+01, tolerance: 1.800e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.658e+01, tolerance: 1.901e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.841e+01, tolerance: 1.891e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.821e+01, tolerance: 1.901e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.758e+01, tolerance: 1.881e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.742e+01, tolerance: 1.800e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.773e+01, tolerance: 1.837e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "least error is: 0.13065758899111907, best parameters are: [(0.1, 0.1111111111111111)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.820e+00, tolerance: 1.891e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.628e+00, tolerance: 1.881e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.193e+00, tolerance: 1.837e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.190e+00, tolerance: 1.800e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.782e+00, tolerance: 1.901e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.375e+00, tolerance: 1.800e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.976e+00, tolerance: 1.901e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.398e+00, tolerance: 1.837e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.014e+00, tolerance: 1.891e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.817e+00, tolerance: 1.881e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.587e+00, tolerance: 1.800e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.196e+00, tolerance: 1.901e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.236e+00, tolerance: 1.891e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.030e+00, tolerance: 1.881e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.633e+00, tolerance: 1.837e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.490e+00, tolerance: 1.891e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.828e+00, tolerance: 1.800e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.899e+00, tolerance: 1.837e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.271e+00, tolerance: 1.881e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.447e+00, tolerance: 1.901e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.778e+00, tolerance: 1.891e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.103e+00, tolerance: 1.800e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.201e+00, tolerance: 1.837e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.542e+00, tolerance: 1.881e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.733e+00, tolerance: 1.901e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.105e+00, tolerance: 1.891e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.415e+00, tolerance: 1.800e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.846e+00, tolerance: 1.881e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.056e+00, tolerance: 1.901e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.542e+00, tolerance: 1.837e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.421e+00, tolerance: 1.901e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.925e+00, tolerance: 1.837e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.766e+00, tolerance: 1.800e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.186e+00, tolerance: 1.881e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.475e+00, tolerance: 1.891e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.892e+00, tolerance: 1.891e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.162e+00, tolerance: 1.800e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.832e+00, tolerance: 1.901e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.355e+00, tolerance: 1.837e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.565e+00, tolerance: 1.881e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.360e+00, tolerance: 1.891e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.833e+00, tolerance: 1.837e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.607e+00, tolerance: 1.800e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.987e+00, tolerance: 1.881e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.292e+00, tolerance: 1.901e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.884e+00, tolerance: 1.891e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.807e+00, tolerance: 1.901e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.105e+00, tolerance: 1.800e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.366e+00, tolerance: 1.837e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.455e+00, tolerance: 1.881e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.382e+00, tolerance: 1.901e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.956e+00, tolerance: 1.837e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.660e+00, tolerance: 1.800e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.468e+00, tolerance: 1.891e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.975e+00, tolerance: 1.881e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.609e+00, tolerance: 1.837e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.549e+00, tolerance: 1.881e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.012e+01, tolerance: 1.891e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.278e+00, tolerance: 1.800e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.002e+01, tolerance: 1.901e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.073e+01, tolerance: 1.901e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.084e+01, tolerance: 1.891e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.033e+01, tolerance: 1.837e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.019e+01, tolerance: 1.881e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.965e+00, tolerance: 1.800e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.164e+01, tolerance: 1.891e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.152e+01, tolerance: 1.901e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.112e+01, tolerance: 1.837e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.089e+01, tolerance: 1.881e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.073e+01, tolerance: 1.800e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.200e+01, tolerance: 1.837e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.157e+01, tolerance: 1.800e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.240e+01, tolerance: 1.901e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.253e+01, tolerance: 1.891e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.167e+01, tolerance: 1.881e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "least error is: 0.12743868091096364, best parameters are: [(0.12181879120101156, 0.0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.144e+00, tolerance: 1.881e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.331e+00, tolerance: 1.901e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.845e+00, tolerance: 1.800e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.348e+00, tolerance: 1.891e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.834e+00, tolerance: 1.837e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.941e-02, tolerance: 1.881e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.140e-01, tolerance: 1.800e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.085e-01, tolerance: 1.891e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.120e-01, tolerance: 1.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.265e-01, tolerance: 1.901e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.469e-02, tolerance: 1.901e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.761e-02, tolerance: 1.881e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.130e-01, tolerance: 1.891e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.924e-02, tolerance: 1.800e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.053e-01, tolerance: 1.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.919e-02, tolerance: 1.891e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.723e-02, tolerance: 1.881e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.183e-02, tolerance: 1.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.802e-02, tolerance: 1.800e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.775e-02, tolerance: 1.901e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.638e-02, tolerance: 1.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.111e-02, tolerance: 1.891e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.480e+00, tolerance: 1.901e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.496e+00, tolerance: 1.891e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.984e+00, tolerance: 1.800e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.298e+00, tolerance: 1.881e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.992e+00, tolerance: 1.837e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.010e-01, tolerance: 1.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.422e-02, tolerance: 1.901e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.315e-01, tolerance: 1.891e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.154e-01, tolerance: 1.881e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.329e-01, tolerance: 1.800e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.480e-02, tolerance: 1.881e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.191e-02, tolerance: 1.800e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.485e-02, tolerance: 1.891e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.291e-02, tolerance: 1.901e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.488e-02, tolerance: 1.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.106e-02, tolerance: 1.891e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.780e-02, tolerance: 1.901e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.082e-02, tolerance: 1.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.506e-02, tolerance: 1.800e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.409e-02, tolerance: 1.881e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.193e-02, tolerance: 1.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.662e+00, tolerance: 1.891e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.169e+00, tolerance: 1.837e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.142e+00, tolerance: 1.800e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.472e+00, tolerance: 1.881e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.647e+00, tolerance: 1.901e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.415e-02, tolerance: 1.800e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.917e-02, tolerance: 1.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.083e-02, tolerance: 1.901e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.748e-02, tolerance: 1.881e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.150e-02, tolerance: 1.891e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.518e-02, tolerance: 1.901e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.396e-02, tolerance: 1.891e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.285e-02, tolerance: 1.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.524e-02, tolerance: 1.800e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.819e-02, tolerance: 1.881e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.986e-02, tolerance: 1.901e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.583e-02, tolerance: 1.891e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.642e-02, tolerance: 1.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.318e+00, tolerance: 1.800e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.848e+00, tolerance: 1.891e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.833e+00, tolerance: 1.901e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.668e+00, tolerance: 1.881e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.366e+00, tolerance: 1.837e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.624e-02, tolerance: 1.901e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.961e-02, tolerance: 1.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.101e-01, tolerance: 1.800e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.007e-01, tolerance: 1.891e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.093e-02, tolerance: 1.881e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.459e-02, tolerance: 1.881e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.895e-02, tolerance: 1.901e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.381e-02, tolerance: 1.891e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.600e-02, tolerance: 1.800e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.646e-02, tolerance: 1.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.885e+00, tolerance: 1.881e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.515e+00, tolerance: 1.800e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.054e+00, tolerance: 1.891e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.586e+00, tolerance: 1.837e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.041e+00, tolerance: 1.901e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.163e-02, tolerance: 1.891e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.975e-02, tolerance: 1.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.788e-02, tolerance: 1.881e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.609e-02, tolerance: 1.901e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.394e-02, tolerance: 1.800e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.973e-02, tolerance: 1.881e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.108e-02, tolerance: 1.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.127e+00, tolerance: 1.881e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.828e+00, tolerance: 1.837e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.284e+00, tolerance: 1.891e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.270e+00, tolerance: 1.901e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.733e+00, tolerance: 1.800e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.033e-02, tolerance: 1.891e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.418e-02, tolerance: 1.901e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.143e-02, tolerance: 1.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.571e-02, tolerance: 1.881e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.650e-02, tolerance: 1.800e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.886e-02, tolerance: 1.800e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.393e+00, tolerance: 1.881e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.537e+00, tolerance: 1.891e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.975e+00, tolerance: 1.800e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.094e+00, tolerance: 1.837e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.522e+00, tolerance: 1.901e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.264e-02, tolerance: 1.901e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.055e-02, tolerance: 1.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.531e-02, tolerance: 1.800e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.864e-02, tolerance: 1.881e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.248e-02, tolerance: 1.891e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.240e+00, tolerance: 1.800e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.686e+00, tolerance: 1.881e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.815e+00, tolerance: 1.891e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.385e+00, tolerance: 1.837e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.798e+00, tolerance: 1.901e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.480e-02, tolerance: 1.881e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.072e-02, tolerance: 1.891e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.111e-02, tolerance: 1.800e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.530e+00, tolerance: 1.800e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.007e+00, tolerance: 1.881e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.119e+00, tolerance: 1.891e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.101e+00, tolerance: 1.901e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.702e+00, tolerance: 1.837e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.889e-02, tolerance: 1.800e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.048e+00, tolerance: 1.837e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.357e+00, tolerance: 1.881e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.848e+00, tolerance: 1.800e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.453e+00, tolerance: 1.891e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.431e+00, tolerance: 1.901e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.817e+00, tolerance: 1.891e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.738e+00, tolerance: 1.881e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.792e+00, tolerance: 1.901e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.423e+00, tolerance: 1.837e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.194e+00, tolerance: 1.800e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.570e+00, tolerance: 1.800e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.830e+00, tolerance: 1.837e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.215e+00, tolerance: 1.891e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.150e+00, tolerance: 1.881e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.184e+00, tolerance: 1.901e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.980e+00, tolerance: 1.800e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.649e+00, tolerance: 1.891e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.596e+00, tolerance: 1.881e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.611e+00, tolerance: 1.901e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.271e+00, tolerance: 1.837e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.425e+00, tolerance: 1.800e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.123e+00, tolerance: 1.891e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.749e+00, tolerance: 1.837e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.077e+00, tolerance: 1.881e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.076e+00, tolerance: 1.901e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.581e+00, tolerance: 1.901e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.637e+00, tolerance: 1.891e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.266e+00, tolerance: 1.837e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.907e+00, tolerance: 1.800e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.596e+00, tolerance: 1.881e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "least error is: 0.12159654873397648, best parameters are: [(0.8767123872968682, 0.0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.513e+00, tolerance: 1.800e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.797e+00, tolerance: 1.901e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.697e+00, tolerance: 1.891e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.442e+00, tolerance: 1.837e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.743e+00, tolerance: 1.881e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.242e-02, tolerance: 1.901e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.838e-02, tolerance: 1.800e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.380e-02, tolerance: 1.881e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.690e+00, tolerance: 1.800e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.925e+00, tolerance: 1.881e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.883e+00, tolerance: 1.891e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.981e+00, tolerance: 1.901e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.618e+00, tolerance: 1.837e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.436e-02, tolerance: 1.881e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.176e+00, tolerance: 1.901e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.119e+00, tolerance: 1.881e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.081e+00, tolerance: 1.891e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.806e+00, tolerance: 1.837e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.877e+00, tolerance: 1.800e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.902e-02, tolerance: 1.881e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.076e+00, tolerance: 1.800e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.325e+00, tolerance: 1.881e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.008e+00, tolerance: 1.837e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.384e+00, tolerance: 1.901e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.292e+00, tolerance: 1.891e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.544e+00, tolerance: 1.881e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.288e+00, tolerance: 1.800e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.517e+00, tolerance: 1.891e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.223e+00, tolerance: 1.837e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.604e+00, tolerance: 1.901e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.759e+00, tolerance: 1.891e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.778e+00, tolerance: 1.881e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.514e+00, tolerance: 1.800e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.454e+00, tolerance: 1.837e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.839e+00, tolerance: 1.901e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.701e+00, tolerance: 1.837e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.017e+00, tolerance: 1.891e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.025e+00, tolerance: 1.881e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.089e+00, tolerance: 1.901e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.754e+00, tolerance: 1.800e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.008e+00, tolerance: 1.800e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.287e+00, tolerance: 1.881e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.965e+00, tolerance: 1.837e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.293e+00, tolerance: 1.891e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.356e+00, tolerance: 1.901e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.564e+00, tolerance: 1.881e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.278e+00, tolerance: 1.800e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.638e+00, tolerance: 1.901e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.587e+00, tolerance: 1.891e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.247e+00, tolerance: 1.837e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.857e+00, tolerance: 1.881e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.900e+00, tolerance: 1.891e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.938e+00, tolerance: 1.901e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.565e+00, tolerance: 1.800e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.547e+00, tolerance: 1.837e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.166e+00, tolerance: 1.881e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.236e+00, tolerance: 1.891e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.868e+00, tolerance: 1.837e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.258e+00, tolerance: 1.901e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.870e+00, tolerance: 1.800e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.493e+00, tolerance: 1.881e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.594e+00, tolerance: 1.891e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.211e+00, tolerance: 1.837e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.598e+00, tolerance: 1.901e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.195e+00, tolerance: 1.800e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.837e+00, tolerance: 1.881e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.978e+00, tolerance: 1.891e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.578e+00, tolerance: 1.837e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.540e+00, tolerance: 1.800e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.962e+00, tolerance: 1.901e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.203e+00, tolerance: 1.881e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.389e+00, tolerance: 1.891e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.910e+00, tolerance: 1.800e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.351e+00, tolerance: 1.901e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.971e+00, tolerance: 1.837e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.770e+00, tolerance: 1.901e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.831e+00, tolerance: 1.891e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.307e+00, tolerance: 1.800e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.393e+00, tolerance: 1.837e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.593e+00, tolerance: 1.881e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "least error is: 0.12041096696738114, best parameters are: [(0.3981071705534972, 0.0)]\n"
     ]
    }
   ],
   "source": [
    "error = []\n",
    "best_parameters = []\n",
    "# we iterate over list of data-sets\n",
    "# X_polynomial,\n",
    "for d in [base, with_box_cox, with_na, with_interactions, X_polynomial,  with_interactions2]:\n",
    "# for d in [with_interactions, X_polynomial]:\n",
    "    # scale variables\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(d[:len(train_ID)]) #  fit  the scale        \n",
    "\n",
    "    X_train = scaler.transform(d[:len(train_ID)])\n",
    "    X_test = scaler.transform(d[len(train_ID):])\n",
    "    \n",
    "    # the function cross_val_score computes the model passed to it for cv=5-fold \n",
    "    # cross validation; we compute the mean over the 5 folds\n",
    "    get_results = [(la, r, np.mean(np.sqrt(-cross_val_score(ElasticNet(alpha = la,\n",
    "                                                            l1_ratio = r),\n",
    "            X_train, y , scoring = 'neg_mean_squared_error',\n",
    "            cv = 5, n_jobs = -1))))\n",
    "                for la in lamb for r in ratio]\n",
    "    \n",
    "    # the least error is extracted\n",
    "    least_error = np.min([i[2] for i in get_results])\n",
    "    error.append(least_error)\n",
    "    # the parameters belonging to the best result\n",
    "    parameters = [i[0:2] for i in get_results if i[2] == least_error]\n",
    "    best_parameters.append(parameters)\n",
    "    print(f'least error is: {least_error}, best parameters are: {parameters}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.13822808131208597,\n",
       " 0.13065759218112855,\n",
       " 0.13065758899111907,\n",
       " 0.12743868091096364,\n",
       " 0.12159654873397648,\n",
       " 0.12041096696738114]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0.3981071705534972, 0.0)],\n",
       " [(0.1, 0.1111111111111111)],\n",
       " [(0.1, 0.1111111111111111)],\n",
       " [(0.12181879120101156, 0.0)],\n",
       " [(0.8767123872968682, 0.0)],\n",
       " [(0.3981071705534972, 0.0)]]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 1831)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# more variables than training examples, but best cross-validation result:\n",
    "with_interactions2[:len(train_ID)].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "variables": {
     "np.round(100 - (best_parameters[1][0][1] * 100))": {},
     "np.round(best_parameters[0][0][0], 4)": {},
     "np.round(best_parameters[0][0][1], 4)": {},
     "np.round(best_parameters[1][0][0], 4)": {},
     "np.round(best_parameters[1][0][1] * 100)": {},
     "np.round(best_parameters[2][0][0], 4)": {},
     "np.round(error[0], 4)": {},
     "np.round(error[1], 4)": {},
     "np.round(error[2], 4)": {},
     "np.round(error[3], 4)": {}
    }
   },
   "source": [
    "We conclude:\n",
    "1. The error for the base data set (only missing values imputed) is: {{np.round(error[0], 4)}}  (mse); The corresponding lambda is {{np.round(best_parameters[0][0][0], 4)}}, i.e. the amount of regularization; the l1_ratio = {{np.round(best_parameters[0][0][1], 4)}}; the kind of regularization was pure ridge (l2-penalty)\n",
    "2. The error with some of the numeric variables box-cox transformed is {{np.round(error[1], 4)}} (mse); the amount of regularization is far less than before ({{np.round(best_parameters[1][0][0], 4)}}); we have {{np.round(best_parameters[1][0][1] * 100)}}% l1-penalty and {{np.round(100 - (best_parameters[1][0][1] * 100))}}% l2-penalty\n",
    "3. Indicator variables for formerly missing values are included in the data-set; The error ({{np.round(error[2], 4)}}) shrinks by an insignificant amount. The lambda parameter is {{np.round(best_parameters[2][0][0], 4)}}; no l1-penalty is used\n",
    "4. adding the interaction terms has the most pronounced effect. The error drops to {{np.round(error[3], 4)}}; The best parameters are as before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One additional note: By including the interaction2 terms, we have __more variables (1831) than observations (1460)__ in the training set. This situation is not admissable in classical statistics. For machine learning algorithms with regularization and/or iterative optimization, it does not mean any problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, we are doing all the processing steps withing a pipeline\n",
    "this can prevent overfitting as we will see later.<br>\n",
    "\n",
    "We are not adding interaction-terms here; \n",
    "\n",
    "One-hot encoding and adding variables for missing values is not critical: no statistics are fitted<br>\n",
    "\n",
    "we load the data (only train) once again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/train.csv', sep=\",\")\n",
    "train_ID = train['Id']\n",
    "train.drop('Id', axis = 1, inplace = True)\n",
    "SalePrice = train['SalePrice']\n",
    "train.drop('SalePrice', axis=1, inplace = True)\n",
    "categorical = [var for var in train.columns if train[var].dtype=='O']\n",
    "numerical = [var for var in train.columns if train[var].dtype!='O']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we add an indicator variable for every missing value: no statistics are fitted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[categorical] = train[categorical].fillna('None')\n",
    "for val in numerical:\n",
    "    train[val + '_na'] = pd.isnull(train[val])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the follwing statistics however, depend on the data:<br>\n",
    "- filling NAs with mean-values\n",
    "- box-cox transform of variable\n",
    "- fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "sys.path.append(os.path.abspath('../scripts'))\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(missing_values=np.nan, strategy='mean')),\n",
    "    ('scaler', PowerTransformer(method='box-cox'))])\n",
    "\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numerical),\n",
    "        ('cat', categorical_transformer, categorical),\n",
    "        ])\n",
    "\n",
    "clf = GridSearchCV(\n",
    "        make_pipeline(\n",
    "            preprocessor,\n",
    "            ElasticNet()\n",
    "            ),\n",
    "            param_grid={'elasticnet__alpha': 10**(np.linspace(-1, 0.2, 5)),\n",
    "                        'elasticnet__l1_ratio': np.linspace(0, 1, 6)},\n",
    "         cv=5, refit=False, scoring = 'neg_mean_squared_error'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.120e+01, tolerance: 1.891e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.019e+01, tolerance: 1.800e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.062e+01, tolerance: 1.837e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.117e+01, tolerance: 1.901e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.734e+00, tolerance: 1.881e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.308e+01, tolerance: 1.891e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.199e+01, tolerance: 1.800e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.246e+01, tolerance: 1.837e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.305e+01, tolerance: 1.901e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.153e+01, tolerance: 1.881e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.590e+01, tolerance: 1.891e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.471e+01, tolerance: 1.800e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.521e+01, tolerance: 1.837e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.583e+01, tolerance: 1.901e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.428e+01, tolerance: 1.881e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.025e+01, tolerance: 1.891e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.891e+01, tolerance: 1.800e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.946e+01, tolerance: 1.837e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.012e+01, tolerance: 1.901e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.859e+01, tolerance: 1.881e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.693e+01, tolerance: 1.891e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.536e+01, tolerance: 1.800e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.599e+01, tolerance: 1.837e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.674e+01, tolerance: 1.901e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/martin/miniconda3/envs/imbalanced/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.526e+01, tolerance: 1.881e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;columntransformer&#x27;,\n",
       "                                        ColumnTransformer(transformers=[(&#x27;num&#x27;,\n",
       "                                                                         Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                                          SimpleImputer()),\n",
       "                                                                                         (&#x27;scaler&#x27;,\n",
       "                                                                                          PowerTransformer(method=&#x27;box-cox&#x27;))]),\n",
       "                                                                         [&#x27;MSSubClass&#x27;,\n",
       "                                                                          &#x27;LotFrontage&#x27;,\n",
       "                                                                          &#x27;LotArea&#x27;,\n",
       "                                                                          &#x27;OverallQual&#x27;,\n",
       "                                                                          &#x27;OverallCond&#x27;,\n",
       "                                                                          &#x27;YearBuilt&#x27;,\n",
       "                                                                          &#x27;YearRemodAdd&#x27;,\n",
       "                                                                          &#x27;MasVnrArea&#x27;,\n",
       "                                                                          &#x27;BsmtFinSF1&#x27;,\n",
       "                                                                          &#x27;BsmtFinSF2&#x27;,\n",
       "                                                                          &#x27;BsmtUnfSF&#x27;,\n",
       "                                                                          &#x27;TotalBsmt...\n",
       "                                                                          &#x27;Foundation&#x27;,\n",
       "                                                                          &#x27;BsmtQual&#x27;,\n",
       "                                                                          &#x27;BsmtCond&#x27;,\n",
       "                                                                          &#x27;BsmtExposure&#x27;,\n",
       "                                                                          &#x27;BsmtFinType1&#x27;,\n",
       "                                                                          &#x27;BsmtFinType2&#x27;,\n",
       "                                                                          &#x27;Heating&#x27;,\n",
       "                                                                          &#x27;HeatingQC&#x27;,\n",
       "                                                                          &#x27;CentralAir&#x27;,\n",
       "                                                                          &#x27;Electrical&#x27;, ...])])),\n",
       "                                       (&#x27;elasticnet&#x27;, ElasticNet())]),\n",
       "             param_grid={&#x27;elasticnet__alpha&#x27;: array([0.1       , 0.19952623, 0.39810717, 0.79432823, 1.58489319]),\n",
       "                         &#x27;elasticnet__l1_ratio&#x27;: array([0. , 0.2, 0.4, 0.6, 0.8, 1. ])},\n",
       "             refit=False, scoring=&#x27;neg_mean_squared_error&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;GridSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;columntransformer&#x27;,\n",
       "                                        ColumnTransformer(transformers=[(&#x27;num&#x27;,\n",
       "                                                                         Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                                          SimpleImputer()),\n",
       "                                                                                         (&#x27;scaler&#x27;,\n",
       "                                                                                          PowerTransformer(method=&#x27;box-cox&#x27;))]),\n",
       "                                                                         [&#x27;MSSubClass&#x27;,\n",
       "                                                                          &#x27;LotFrontage&#x27;,\n",
       "                                                                          &#x27;LotArea&#x27;,\n",
       "                                                                          &#x27;OverallQual&#x27;,\n",
       "                                                                          &#x27;OverallCond&#x27;,\n",
       "                                                                          &#x27;YearBuilt&#x27;,\n",
       "                                                                          &#x27;YearRemodAdd&#x27;,\n",
       "                                                                          &#x27;MasVnrArea&#x27;,\n",
       "                                                                          &#x27;BsmtFinSF1&#x27;,\n",
       "                                                                          &#x27;BsmtFinSF2&#x27;,\n",
       "                                                                          &#x27;BsmtUnfSF&#x27;,\n",
       "                                                                          &#x27;TotalBsmt...\n",
       "                                                                          &#x27;Foundation&#x27;,\n",
       "                                                                          &#x27;BsmtQual&#x27;,\n",
       "                                                                          &#x27;BsmtCond&#x27;,\n",
       "                                                                          &#x27;BsmtExposure&#x27;,\n",
       "                                                                          &#x27;BsmtFinType1&#x27;,\n",
       "                                                                          &#x27;BsmtFinType2&#x27;,\n",
       "                                                                          &#x27;Heating&#x27;,\n",
       "                                                                          &#x27;HeatingQC&#x27;,\n",
       "                                                                          &#x27;CentralAir&#x27;,\n",
       "                                                                          &#x27;Electrical&#x27;, ...])])),\n",
       "                                       (&#x27;elasticnet&#x27;, ElasticNet())]),\n",
       "             param_grid={&#x27;elasticnet__alpha&#x27;: array([0.1       , 0.19952623, 0.39810717, 0.79432823, 1.58489319]),\n",
       "                         &#x27;elasticnet__l1_ratio&#x27;: array([0. , 0.2, 0.4, 0.6, 0.8, 1. ])},\n",
       "             refit=False, scoring=&#x27;neg_mean_squared_error&#x27;)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">estimator: Pipeline</label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;columntransformer&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;num&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                   SimpleImputer()),\n",
       "                                                                  (&#x27;scaler&#x27;,\n",
       "                                                                   PowerTransformer(method=&#x27;box-cox&#x27;))]),\n",
       "                                                  [&#x27;MSSubClass&#x27;, &#x27;LotFrontage&#x27;,\n",
       "                                                   &#x27;LotArea&#x27;, &#x27;OverallQual&#x27;,\n",
       "                                                   &#x27;OverallCond&#x27;, &#x27;YearBuilt&#x27;,\n",
       "                                                   &#x27;YearRemodAdd&#x27;, &#x27;MasVnrArea&#x27;,\n",
       "                                                   &#x27;BsmtFinSF1&#x27;, &#x27;BsmtFinSF2&#x27;,\n",
       "                                                   &#x27;BsmtUnfSF&#x27;, &#x27;TotalBsmtSF&#x27;,\n",
       "                                                   &#x27;1stFlrSF&#x27;, &#x27;2ndFlrSF&#x27;,\n",
       "                                                   &#x27;L...\n",
       "                                                   &#x27;LandContour&#x27;, &#x27;Utilities&#x27;,\n",
       "                                                   &#x27;LotConfig&#x27;, &#x27;LandSlope&#x27;,\n",
       "                                                   &#x27;Neighborhood&#x27;, &#x27;Condition1&#x27;,\n",
       "                                                   &#x27;Condition2&#x27;, &#x27;BldgType&#x27;,\n",
       "                                                   &#x27;HouseStyle&#x27;, &#x27;RoofStyle&#x27;,\n",
       "                                                   &#x27;RoofMatl&#x27;, &#x27;Exterior1st&#x27;,\n",
       "                                                   &#x27;Exterior2nd&#x27;, &#x27;MasVnrType&#x27;,\n",
       "                                                   &#x27;ExterQual&#x27;, &#x27;ExterCond&#x27;,\n",
       "                                                   &#x27;Foundation&#x27;, &#x27;BsmtQual&#x27;,\n",
       "                                                   &#x27;BsmtCond&#x27;, &#x27;BsmtExposure&#x27;,\n",
       "                                                   &#x27;BsmtFinType1&#x27;,\n",
       "                                                   &#x27;BsmtFinType2&#x27;, &#x27;Heating&#x27;,\n",
       "                                                   &#x27;HeatingQC&#x27;, &#x27;CentralAir&#x27;,\n",
       "                                                   &#x27;Electrical&#x27;, ...])])),\n",
       "                (&#x27;elasticnet&#x27;, ElasticNet())])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;columntransformer: ColumnTransformer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.compose.ColumnTransformer.html\">?<span>Documentation for columntransformer: ColumnTransformer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>ColumnTransformer(transformers=[(&#x27;num&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;imputer&#x27;, SimpleImputer()),\n",
       "                                                 (&#x27;scaler&#x27;,\n",
       "                                                  PowerTransformer(method=&#x27;box-cox&#x27;))]),\n",
       "                                 [&#x27;MSSubClass&#x27;, &#x27;LotFrontage&#x27;, &#x27;LotArea&#x27;,\n",
       "                                  &#x27;OverallQual&#x27;, &#x27;OverallCond&#x27;, &#x27;YearBuilt&#x27;,\n",
       "                                  &#x27;YearRemodAdd&#x27;, &#x27;MasVnrArea&#x27;, &#x27;BsmtFinSF1&#x27;,\n",
       "                                  &#x27;BsmtFinSF2&#x27;, &#x27;BsmtUnfSF&#x27;, &#x27;TotalBsmtSF&#x27;,\n",
       "                                  &#x27;1stFlrSF&#x27;, &#x27;2ndFlrSF&#x27;, &#x27;LowQualFinSF&#x27;,\n",
       "                                  &#x27;GrLivArea&#x27;, &#x27;BsmtFullBat...\n",
       "                                 [&#x27;MSZoning&#x27;, &#x27;Street&#x27;, &#x27;Alley&#x27;, &#x27;LotShape&#x27;,\n",
       "                                  &#x27;LandContour&#x27;, &#x27;Utilities&#x27;, &#x27;LotConfig&#x27;,\n",
       "                                  &#x27;LandSlope&#x27;, &#x27;Neighborhood&#x27;, &#x27;Condition1&#x27;,\n",
       "                                  &#x27;Condition2&#x27;, &#x27;BldgType&#x27;, &#x27;HouseStyle&#x27;,\n",
       "                                  &#x27;RoofStyle&#x27;, &#x27;RoofMatl&#x27;, &#x27;Exterior1st&#x27;,\n",
       "                                  &#x27;Exterior2nd&#x27;, &#x27;MasVnrType&#x27;, &#x27;ExterQual&#x27;,\n",
       "                                  &#x27;ExterCond&#x27;, &#x27;Foundation&#x27;, &#x27;BsmtQual&#x27;,\n",
       "                                  &#x27;BsmtCond&#x27;, &#x27;BsmtExposure&#x27;, &#x27;BsmtFinType1&#x27;,\n",
       "                                  &#x27;BsmtFinType2&#x27;, &#x27;Heating&#x27;, &#x27;HeatingQC&#x27;,\n",
       "                                  &#x27;CentralAir&#x27;, &#x27;Electrical&#x27;, ...])])</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">num</label><div class=\"sk-toggleable__content fitted\"><pre>[&#x27;MSSubClass&#x27;, &#x27;LotFrontage&#x27;, &#x27;LotArea&#x27;, &#x27;OverallQual&#x27;, &#x27;OverallCond&#x27;, &#x27;YearBuilt&#x27;, &#x27;YearRemodAdd&#x27;, &#x27;MasVnrArea&#x27;, &#x27;BsmtFinSF1&#x27;, &#x27;BsmtFinSF2&#x27;, &#x27;BsmtUnfSF&#x27;, &#x27;TotalBsmtSF&#x27;, &#x27;1stFlrSF&#x27;, &#x27;2ndFlrSF&#x27;, &#x27;LowQualFinSF&#x27;, &#x27;GrLivArea&#x27;, &#x27;BsmtFullBath&#x27;, &#x27;BsmtHalfBath&#x27;, &#x27;FullBath&#x27;, &#x27;HalfBath&#x27;, &#x27;BedroomAbvGr&#x27;, &#x27;KitchenAbvGr&#x27;, &#x27;TotRmsAbvGrd&#x27;, &#x27;Fireplaces&#x27;, &#x27;GarageYrBlt&#x27;, &#x27;GarageCars&#x27;, &#x27;GarageArea&#x27;, &#x27;WoodDeckSF&#x27;, &#x27;OpenPorchSF&#x27;, &#x27;EnclosedPorch&#x27;, &#x27;3SsnPorch&#x27;, &#x27;ScreenPorch&#x27;, &#x27;PoolArea&#x27;, &#x27;MiscVal&#x27;, &#x27;MoSold&#x27;, &#x27;YrSold&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;SimpleImputer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.impute.SimpleImputer.html\">?<span>Documentation for SimpleImputer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>SimpleImputer()</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;PowerTransformer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.preprocessing.PowerTransformer.html\">?<span>Documentation for PowerTransformer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>PowerTransformer(method=&#x27;box-cox&#x27;)</pre></div> </div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">cat</label><div class=\"sk-toggleable__content fitted\"><pre>[&#x27;MSZoning&#x27;, &#x27;Street&#x27;, &#x27;Alley&#x27;, &#x27;LotShape&#x27;, &#x27;LandContour&#x27;, &#x27;Utilities&#x27;, &#x27;LotConfig&#x27;, &#x27;LandSlope&#x27;, &#x27;Neighborhood&#x27;, &#x27;Condition1&#x27;, &#x27;Condition2&#x27;, &#x27;BldgType&#x27;, &#x27;HouseStyle&#x27;, &#x27;RoofStyle&#x27;, &#x27;RoofMatl&#x27;, &#x27;Exterior1st&#x27;, &#x27;Exterior2nd&#x27;, &#x27;MasVnrType&#x27;, &#x27;ExterQual&#x27;, &#x27;ExterCond&#x27;, &#x27;Foundation&#x27;, &#x27;BsmtQual&#x27;, &#x27;BsmtCond&#x27;, &#x27;BsmtExposure&#x27;, &#x27;BsmtFinType1&#x27;, &#x27;BsmtFinType2&#x27;, &#x27;Heating&#x27;, &#x27;HeatingQC&#x27;, &#x27;CentralAir&#x27;, &#x27;Electrical&#x27;, &#x27;KitchenQual&#x27;, &#x27;Functional&#x27;, &#x27;FireplaceQu&#x27;, &#x27;GarageType&#x27;, &#x27;GarageFinish&#x27;, &#x27;GarageQual&#x27;, &#x27;GarageCond&#x27;, &#x27;PavedDrive&#x27;, &#x27;PoolQC&#x27;, &#x27;Fence&#x27;, &#x27;MiscFeature&#x27;, &#x27;SaleType&#x27;, &#x27;SaleCondition&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;OneHotEncoder<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.preprocessing.OneHotEncoder.html\">?<span>Documentation for OneHotEncoder</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;, sparse_output=False)</pre></div> </div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;ElasticNet<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.ElasticNet.html\">?<span>Documentation for ElasticNet</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>ElasticNet()</pre></div> </div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('columntransformer',\n",
       "                                        ColumnTransformer(transformers=[('num',\n",
       "                                                                         Pipeline(steps=[('imputer',\n",
       "                                                                                          SimpleImputer()),\n",
       "                                                                                         ('scaler',\n",
       "                                                                                          PowerTransformer(method='box-cox'))]),\n",
       "                                                                         ['MSSubClass',\n",
       "                                                                          'LotFrontage',\n",
       "                                                                          'LotArea',\n",
       "                                                                          'OverallQual',\n",
       "                                                                          'OverallCond',\n",
       "                                                                          'YearBuilt',\n",
       "                                                                          'YearRemodAdd',\n",
       "                                                                          'MasVnrArea',\n",
       "                                                                          'BsmtFinSF1',\n",
       "                                                                          'BsmtFinSF2',\n",
       "                                                                          'BsmtUnfSF',\n",
       "                                                                          'TotalBsmt...\n",
       "                                                                          'Foundation',\n",
       "                                                                          'BsmtQual',\n",
       "                                                                          'BsmtCond',\n",
       "                                                                          'BsmtExposure',\n",
       "                                                                          'BsmtFinType1',\n",
       "                                                                          'BsmtFinType2',\n",
       "                                                                          'Heating',\n",
       "                                                                          'HeatingQC',\n",
       "                                                                          'CentralAir',\n",
       "                                                                          'Electrical', ...])])),\n",
       "                                       ('elasticnet', ElasticNet())]),\n",
       "             param_grid={'elasticnet__alpha': array([0.1       , 0.19952623, 0.39810717, 0.79432823, 1.58489319]),\n",
       "                         'elasticnet__l1_ratio': array([0. , 0.2, 0.4, 0.6, 0.8, 1. ])},\n",
       "             refit=False, scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[numerical] += 1\n",
    "clf.fit(train, np.log1p(SalePrice))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'elasticnet__alpha': 0.1, 'elasticnet__l1_ratio': 0.0}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.13237803319111607"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(clf.best_params_, np.sqrt(-clf.best_score_))\n",
    "# clf.cv_results_.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time', 'param_elasticnet__alpha', 'param_elasticnet__l1_ratio', 'params', 'split0_test_score', 'split1_test_score', 'split2_test_score', 'split3_test_score', 'split4_test_score', 'mean_test_score', 'std_test_score', 'rank_test_score'])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.cv_results_.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.13237803, 0.1493028 , 0.16540801, 0.18267359, 0.19985306,\n",
       "       0.21528227, 0.13500173, 0.168074  , 0.20169271, 0.23435203,\n",
       "       0.26753428, 0.299449  , 0.13929797, 0.2067523 , 0.27600369,\n",
       "       0.33904176, 0.39445307, 0.39954338, 0.14674367, 0.28669422,\n",
       "       0.39540082, 0.39954338, 0.39954338, 0.39954338, 0.16027503,\n",
       "       0.39657224, 0.39954338, 0.39954338, 0.39954338, 0.39954338])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(-clf.cv_results_['mean_test_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reminder\n",
    "We found the best parameters via extensive search over the whole data-set. As we have discussed, theoretically nested-cross-validation (aka double-cross-validation) would have been the better choice. However, it would also be computationally more expensive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:imbalanced]",
   "language": "python",
   "name": "conda-env-imbalanced-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
