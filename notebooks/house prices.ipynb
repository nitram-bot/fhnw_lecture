{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dtreeviz\n",
      "  Downloading dtreeviz-1.3.tar.gz (60 kB)\n",
      "\u001b[K     |████████████████████████████████| 60 kB 658 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting graphviz>=0.9\n",
      "  Downloading graphviz-0.16-py2.py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: pandas in /home/martin/miniconda3/lib/python3.6/site-packages (from dtreeviz) (1.1.5)\n",
      "Requirement already satisfied: numpy in /home/martin/miniconda3/lib/python3.6/site-packages (from dtreeviz) (1.19.2)\n",
      "Requirement already satisfied: scikit-learn in /home/martin/miniconda3/lib/python3.6/site-packages (from dtreeviz) (0.24.1)\n",
      "Requirement already satisfied: matplotlib in /home/martin/miniconda3/lib/python3.6/site-packages (from dtreeviz) (3.3.4)\n",
      "Collecting colour\n",
      "  Downloading colour-0.1.5-py2.py3-none-any.whl (23 kB)\n",
      "Collecting pytest\n",
      "  Downloading pytest-6.2.4-py3-none-any.whl (280 kB)\n",
      "\u001b[K     |████████████████████████████████| 280 kB 750 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pillow>=6.2.0 in /home/martin/miniconda3/lib/python3.6/site-packages (from matplotlib->dtreeviz) (8.1.2)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /home/martin/miniconda3/lib/python3.6/site-packages (from matplotlib->dtreeviz) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/martin/miniconda3/lib/python3.6/site-packages (from matplotlib->dtreeviz) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/martin/miniconda3/lib/python3.6/site-packages (from matplotlib->dtreeviz) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/martin/miniconda3/lib/python3.6/site-packages (from matplotlib->dtreeviz) (2.8.1)\n",
      "Requirement already satisfied: six in /home/martin/miniconda3/lib/python3.6/site-packages (from cycler>=0.10->matplotlib->dtreeviz) (1.15.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/martin/miniconda3/lib/python3.6/site-packages (from pandas->dtreeviz) (2021.1)\n",
      "Collecting pluggy<1.0.0a1,>=0.12\n",
      "  Downloading pluggy-0.13.1-py2.py3-none-any.whl (18 kB)\n",
      "Collecting toml\n",
      "  Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Collecting iniconfig\n",
      "  Downloading iniconfig-1.1.1-py2.py3-none-any.whl (5.0 kB)\n",
      "Collecting py>=1.8.2\n",
      "  Downloading py-1.10.0-py2.py3-none-any.whl (97 kB)\n",
      "\u001b[K     |████████████████████████████████| 97 kB 727 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: importlib-metadata>=0.12 in /home/martin/miniconda3/lib/python3.6/site-packages (from pytest->dtreeviz) (2.0.0)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /home/martin/miniconda3/lib/python3.6/site-packages (from pytest->dtreeviz) (20.3.0)\n",
      "Requirement already satisfied: packaging in /home/martin/miniconda3/lib/python3.6/site-packages (from pytest->dtreeviz) (20.9)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/martin/miniconda3/lib/python3.6/site-packages (from importlib-metadata>=0.12->pytest->dtreeviz) (3.4.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/martin/miniconda3/lib/python3.6/site-packages (from scikit-learn->dtreeviz) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/martin/miniconda3/lib/python3.6/site-packages (from scikit-learn->dtreeviz) (1.0.1)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /home/martin/miniconda3/lib/python3.6/site-packages (from scikit-learn->dtreeviz) (1.5.2)\n",
      "Building wheels for collected packages: dtreeviz\n",
      "  Building wheel for dtreeviz (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for dtreeviz: filename=dtreeviz-1.3-py3-none-any.whl size=66638 sha256=8d5061c0a9af303d6f0083ad259c5e3c8afdf1fd8b1c52b597eae1b6a6fdbcf1\n",
      "  Stored in directory: /home/martin/.cache/pip/wheels/37/35/0b/90a432df982480b9285addd983d37ab7e53ba75481047b7310\n",
      "Successfully built dtreeviz\n",
      "Installing collected packages: toml, py, pluggy, iniconfig, pytest, graphviz, colour, dtreeviz\n",
      "Successfully installed colour-0.1.5 dtreeviz-1.3 graphviz-0.16 iniconfig-1.1.1 pluggy-0.13.1 py-1.10.0 pytest-6.2.4 toml-0.10.2\n"
     ]
    }
   ],
   "source": [
    "!pip install dtreeviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# box cox transform\n",
    "from scipy.stats import boxcox\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data, descriptions of the variables and some examples can be found here:\n",
    "[house-pricese-from-kaggle-competition](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/martin/python/fhnw_lecture/notebooks\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data is from a kaggle-competition\n",
    "Attention, the test data-set has no target; This is the part you are supposed to upload to kaggle for estimation of your modelling performance;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/train.csv', sep=\",\")\n",
    "test = pd.read_csv('../data/test.csv')\n",
    "\n",
    "train_ID = train['Id']\n",
    "test_ID = test['Id']\n",
    "\n",
    "train.drop('Id', axis = 1, inplace = True)\n",
    "test.drop('Id', axis = 1, inplace = True)\n",
    "\n",
    "SalePrice = train['SalePrice']\n",
    "train.drop('SalePrice', axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### now, we want data-leakage\n",
    "We discussed at length, that train and test-set should be standardized and preprocessed independently; This is only true if we want a fair estimate about our algorithm's performance with new, unseen data.<br>\n",
    "In the current case we want our training-procedure to be biased towards the test-set, because the test-set performance is what counts in kaggle-competitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat((train, test))\n",
    "data.reset_index(drop = True, inplace = True)\n",
    "# categorical and numericalvariables:\n",
    "\n",
    "categorical = [var for var in train.columns if train[var].dtype=='O']\n",
    "numerical = [var for var in train.columns if train[var].dtype!='O']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some preprocessing steps\n",
    "### we fill missing values with the mean and add an extra variable indicating the missing position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[categorical] = data[categorical].fillna('None')\n",
    "\n",
    "\n",
    "## next, we substitute missing values with the mean of the variable and form new variables\n",
    "## indicating the missing values. Sometimes data is not missing at random and the fact that\n",
    "## data is missing might contain valuable information\n",
    "variables_na = []\n",
    "for val in numerical:\n",
    "    data[val + '_na'] = pd.isnull(data[val])\n",
    "    variables_na.append(val + '_na')\n",
    "    data[val].fillna(data[val].mean(), inplace = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### we transform the continuous variables to be more normally distributed\n",
    "[box-cox transform in short](https://www.statisticshowto.com/box-cox-transformation/#:~:text=A%20Box%20Cox%20transformation%20is,a%20broader%20number%20of%20tests.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/martin/miniconda3/lib/python3.6/site-packages/numpy/core/_methods.py:205: RuntimeWarning: overflow encountered in multiply\n",
      "  x = um.multiply(x, x, out=x)\n",
      "/home/martin/miniconda3/lib/python3.6/site-packages/scipy/optimize/optimize.py:2116: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  tmp2 = (x - v) * (fx - fw)\n",
      "/home/martin/miniconda3/lib/python3.6/site-packages/scipy/stats/morestats.py:908: RuntimeWarning: divide by zero encountered in log\n",
      "  return (lmb - 1) * np.sum(logdata, axis=0) - N/2 * np.log(variance)\n",
      "/home/martin/miniconda3/lib/python3.6/site-packages/scipy/optimize/optimize.py:2115: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  tmp1 = (x - w) * (fx - fv)\n"
     ]
    }
   ],
   "source": [
    "## box-cox transform is variance stabilizing. It is meant to make \n",
    "## the variable more normaly distributed    \n",
    "box_cox = []\n",
    "for val in numerical:\n",
    "    new_vals, lamb = boxcox(data[val] + 1)\n",
    "    if np.abs(lamb) < 8:\n",
    "        data[val + '_box_cox'] = new_vals\n",
    "        box_cox.append(val)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### we demonstrate the effect of the box-cox transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "var = 'LotArea'\n",
    "# 2 fitures\n",
    "ax = plt.subplot(1, 2, 1)\n",
    "# non-transformed variable    \n",
    "ax.hist(data[var], bins = int(180/5),\n",
    "         color = 'blue', edgecolor = 'black')\n",
    "\n",
    "ax = plt.subplot(1, 2, 2)\n",
    "# transformed_variable\n",
    "ax.hist(data[var + '_box_cox'], bins = int(180/5),\n",
    "         color = 'blue', edgecolor = 'black')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### we encode categorical data as dummy-variables (aka one-hot encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as already announced, categorical data is one-hot encoded (dummy-coded)  \n",
    "\n",
    "data_base = pd.get_dummies(data[[col for col in data.columns if col not in variables_na]])\n",
    "data_na = pd.get_dummies(data[variables_na])\n",
    "\n",
    "# we have to cast every variable's data type to float32 for our next 'trick' \n",
    "data_base = data_base.astype(np.float32)\n",
    "data_na = data_na.astype(np.float32)\n",
    "data_numerical = data[numerical]\n",
    "\n",
    "data = pd.concat([data_base, data_na], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### we compute the feature importance in order to get the most relevant variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(max_depth=4, n_estimators=32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the number of variables is quiet high. We want to add interaction terms for the most important\n",
    "# variables. Therefore, we want to compute some variable-importance measure. This is\n",
    "# done by the help of gradient boosted trees:\n",
    "gbm = GradientBoostingRegressor(n_estimators = 32, max_depth = 4)\n",
    "gbm.fit(data.iloc[0:len(train_ID)].values, SalePrice.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# we sort the variables (indizes) by variable importance\n",
    "indizes = np.argsort(gbm.feature_importances_)\n",
    "result = permutation_importance(gbm, data.iloc[0:len(train_ID)], SalePrice, n_repeats=10,\n",
    "                                random_state=42, n_jobs=2)\n",
    "sorted_idx = result.importances_mean.argsort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 1, 1)\n",
    "plt.boxplot(result.importances[sorted_idx[-15:]].T,\n",
    "            vert=False, labels=np.array(data.columns)[sorted_idx[-15:]])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## for the most important features we compute the interactions\n",
    "### in the first step we include only the most important 15 variables to form interaction-terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import a tool for getting all possible n over 2 combinations of these variables\n",
    "from itertools import combinations\n",
    "# and add the interactions\n",
    "interactions = []\n",
    "for comb in list(combinations(data.columns[sorted_idx[-15:]], 2)):\n",
    "    data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
    "    interactions.append(comb[0] + '_x_' + comb[1])\n",
    "\n",
    "data_interactions = data[interactions]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### in the second step we include even 55 variables to form interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions2 = []\n",
    "for comb in list(combinations(data.columns[sorted_idx[-55:]], 2)):\n",
    "    data[comb[0] + '_x_' + comb[1]] = data[comb[0]] * data[comb[1]]\n",
    "    interactions2.append(comb[0] + '_x_' + comb[1])\n",
    "\n",
    "data_interactions2 = data[interactions2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1.\n",
    "# now, we have different data sets\n",
    "# the base set with missing values imputed by the mean and no other feature engineering\n",
    "# box-cox transformed variables are removen\n",
    "base = data_base[[col for col in data_base.columns if not col.endswith('_box_cox')]]\n",
    "## 2.\n",
    "# box_cox is admitted; original variables removed\n",
    "with_box_cox = data_base[[col for col in data_base.columns if not col in box_cox]]\n",
    "## 3.\n",
    "# variables indicating formerly missing values are included\n",
    "with_na = pd.concat([with_box_cox, data_na], axis = 1)\n",
    "## 4.\n",
    "# all interaction terms of the 55 most important variables are added\n",
    "with_interactions = pd.concat([with_na, data_interactions], axis = 1)\n",
    "## 5.\n",
    "## we exagerate the number of interactions\n",
    "with_interactions2 = pd.concat([with_na, data_interactions2], axis=1)\n",
    "## the target variable is log-transformed\n",
    "y = np.log1p(SalePrice)\n",
    "\n",
    "## since we want to try elasticnet, we have to find the optimal parameter for \n",
    "# lambda (amount of regularization) and for alpha (ratio of lasso and ridge mixing)\n",
    "lamb = 10**(np.linspace(-1, 0.2, 15))\n",
    "# ratio\n",
    "ratio = np.linspace(0, 1, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### excurs: parameter sampling on a logarithmic scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sample some of the parameters on a logrithmic scale:\n",
    "https://www.coursera.org/lecture/deep-neural-network/using-an-appropriate-scale-to-pick-hyperparameters-3rdqN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0001  , 0.025075, 0.05005 , 0.075025, 0.1     ])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linspace(0.0001, 0.1, 5) # 5 equally spaced values from 0.0001 to 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, there is no value between 0.0001 and 0.001 and no value between 0.001 and 0.01. But there are three values between 0.01 and 0.1<br>\n",
    "Now, compare to this solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0001    , 0.00056234, 0.00316228, 0.01778279, 0.1       ])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10**np.linspace(-4, -1, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### we transform the SalePrice (y) as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/martin/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: RuntimeWarning: divide by zero encountered in log\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-inf"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.6931471805599453"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.6931471805599453"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# the function np.log1p is well defined at 0\n",
    "display(np.log(0), np.log(1), np.log(2),\n",
    "        np.log1p(1), np.log1p(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAYoUlEQVR4nO3df4xlZ33f8fena1iKCcWux55lbTomWigmSsCdulBa5MTFNgR5HbWu1grpKrja/jAJtGmJHUulUmXJSVqSVClULna8UYzN1kC8RQ3gLlArUrCzBgO2F8cbjO3Fy+wQJ4Em0pK1v/3jnmHv/NqZnZl7z7lz3y/p6p773HPmfu/unPnc55zzPDdVhSRJXfPX2i5AkqSlGFCSpE4yoCRJnWRASZI6yYCSJHXSGW0XAHDOOefU1NRU22VIp+Whhx76TlVNtF1HP/cljaLl9qVOBNTU1BQHDx5suwzptCR5qu0aFnJf0ihabl/yEJ8kqZMMKGlIktye5FiSRxa0/1ySx5M8muRX+tpvTHK4ee6K4VcstasTh/ikMXEH8JvAb881JPlxYCfwo1V1PMm5TftFwC7g9cArgf+T5DVV9fzQq5ZaYg9KGpKquh94bkHzvwJuqarjzTrHmvadwN1VdbyqngQOA5cMrVipAwwoqV2vAf5hkgeS/N8kf7dp3w4807fekaZtkSR7khxMcnB2dnbA5UrDY0BJ7ToDOAt4E/DvgX1JAmSJdZec2bmqbq2q6aqanpjo1FXv0roYUFK7jgCfqJ4HgReAc5r2C/rWOx94toX6pNYYUFK7fhf4CYAkrwFeDHwH2A/sSrI1yYXADuDBtoqU2uBVfNKQJLkLuBQ4J8kR4APA7cDtzaXn3wd2V+9L2h5Nsg94DDgBXO8VfBo3BpQ0JFV17TJPvWuZ9W8Gbh5cRVK3jfUhvsnJKZLMu01OTrVdlqQhW/i3wL8D3TDWPaiZmadYeGHUzMxSF09J2swW/i3w70A3jHUPSpLUXQaUJKmTDChJUicZUJKkTjKgJEmdZEBJkjrJgJIkdZIBJUnqJANKktRJBpQkqZMMKElSJxlQkqROMqAkSZ1kQEmSOsmAkiR1kgElSeokA0qS1EkGlCSpkwwoSVInGVDSkCS5PcmxJI8s8dy/S1JJzulruzHJ4SSPJ7liuNVK7TOgpOG5A7hyYWOSC4C3AU/3tV0E7AJe32zzoSRbhlOm1A0GlDQkVXU/8NwST/0a8H6g+tp2AndX1fGqehI4DFwy+Cql7hirgJqcnCLJD25S25JcBXyrqr6y4KntwDN9j480bdLYOKPtAoZpZuYp5n9INaTUniQvBW4CLl/q6SXaaok2kuwB9gC86lWv2rD6pLaNVQ9K6pgfBi4EvpLkm8D5wJeSTNLrMV3Qt+75wLNL/ZCqurWqpqtqemJiYsAlS8NjQEktqaqvVdW5VTVVVVP0Quniqvo2sB/YlWRrkguBHcCDLZYrDZ0BJQ1JkruAPwBem+RIkuuWW7eqHgX2AY8Bnwaur6rnh1Op1A1jdQ5KalNVXbvC81MLHt8M3DzImqQuswclSeqkFQMqyQVJPp/kUJJHk7y3aT87yX1Jnmjuz+rbxhHwkja1hcNWkjA5OdV2WZvKanpQJ4BfqKrXAW8Crm9Gud8AHKiqHcCB5rEj4CV13kaMiTw5bOXkrdemjbJiQFXV0ar6UrP8PeAQvQGDO4G9zWp7gaubZUfAS+q0xeGiLjqtc1BJpoA3Ag8A51XVUeiFGHBus9qqRsAn2ZPkYJKDs7OzayhdkrSZrTqgkrwM+Djwvqr67qlWXaJt0UcUBxdKkk5lVQGV5EX0wunOqvpE0zyTZFvz/DbgWNO+6hHwkiQtZzVX8QW4DThUVR/se2o/sLtZ3g3c29fuCHhJ0rqsZqDuW4CfAb6W5OGm7ZeAW4B9zWj4p4FroDcCPsncCPgTOAJekrQGKwZUVf0+y0/7fdky2zgCXpK0Ls4kIUnqJANKktRJBpQkqZMMKElahY2YHkmnx6/bkKRVODk90hxDatDsQUmSOsmAkiR1kgElSeokA0qS1EkGlCSpkwwoSVInGVCSpE4yoKQhSXJ7kmNJHulr+9UkX0/y1SSfTPKKvuduTHI4yeNJrmilaKlFBpQ0PHcAVy5ouw/4kar6UeCPgBsBklwE7AJe32zzoSRbhleq1D4DShqSqrofeG5B22er6kTz8Iv0voEaYCdwd1Udr6ongcPAJUMrVuoAA0rqjncDv9csbwee6XvuSNO2SJI9SQ4mOTg7OzvgEqXhMaCkDkhyE71voL5zrmmJ1WqJNqrq1qqarqrpiYmJQZUoDZ2TxUotS7IbeCdwWVXNhdAR4IK+1c4Hnh12beNrqzOWd4A9qBUsnGJ/cnKq7ZK0iSS5EvhF4Kqq+su+p/YDu5JsTXIhsAN4sI0ax9Nxeh3W/puGzR7UChZOsT8z46cqrU2Su4BLgXOSHAE+QO+qva3Afc0n9i9W1b+sqkeT7AMeo3fo7/qqer6dyqV2GFCL2LXXYFTVtUs033aK9W8Gbh5cRVK3GVCLzHXt5xhWktQGz0FJkjrJgJIkdZIBJUnqJANKktRJBpQkqZMMKElSJxlQkqROMqAkSZ1kQEmSOsmAkiR1kgElSeokA0qS1EkGlCSpkwwoSVInGVCSpE4yoCRJnWRASZI6yYCSJHWSASVJ6iQDSpLUSSsGVJLbkxxL8khf239M8q0kDze3d/Q9d2OSw0keT3LFoAqXRs0y+9LZSe5L8kRzf1bfc+5LGmur6UHdAVy5RPuvVdUbmtv/BkhyEbALeH2zzYeSbNmoYqURdweL96UbgANVtQM40Dx2X5JYRUBV1f3Ac6v8eTuBu6vqeFU9CRwGLllHfdKmscy+tBPY2yzvBa7ua3df0lhbzzmo9yT5anPYYu6wxHbgmb51jjRtiyTZk+RgkoOzs7PrKEMaaedV1VGA5v7cpn3V+5K0Wa01oD4M/DDwBuAo8F+a9iyxbi31A6rq1qqarqrpiYmJNZYhbVqr3pf8sKfNak0BVVUzVfV8Vb0A/A9OHno4AlzQt+r5wLPrK1Ha1GaSbANo7o817avel/ywp81qTQE1t0M1fgqYuyppP7ArydYkFwI7gAfXV6K0qe0HdjfLu4F7+9rdlzTWzlhphSR3AZcC5yQ5AnwAuDTJG+gdcvgm8C8AqurRJPuAx4ATwPVV9fxAKpdGzDL70i3AviTXAU8D14D7kgSrCKiqunaJ5ttOsf7NwM3rKUrajJbZlwAuW2Z99yWNNWeSkCR1kgElSeokA0qS1EkGlCSpkwwoSVInGVCSNrXJySmSzLtpNKx4mbkkjbKZmadYPEuUITUK7EFJkjrJgJIkdZIBJUnqJANKktRJBpQkqZMMKElSJxlQkqROMqAkSZ1kQEmSOsmAkqQNs3XelEqTk1NtFzTSnOpIkjbMcfqnVZqZcUql9bAHJUnqJANKktRJBpQkDYznpNbDc1CSNDCek1oPe1BSByT5N0keTfJIkruSvCTJ2UnuS/JEc39W23VKw2RASS1Lsh34eWC6qn4E2ALsAm4ADlTVDuBA81gaGwaU1A1nAH89yRnAS4FngZ3A3ub5vcDV7ZQmtcOAklpWVd8C/jPwNHAU+POq+ixwXlUdbdY5Cpy71PZJ9iQ5mOTg7OzssMrurMnJqXkXJmh0GVBSy5pzSzuBC4FXAmcmeddqt6+qW6tquqqmJyYmBlXmyJiZeYrehQlzN40qA0pq3z8Cnqyq2ar6K+ATwN8HZpJsA2juj7VYozR0BpTUvqeBNyV5aXrHpC4DDgH7gd3NOruBe1uqT2qF46CkllXVA0nuAb4EnAC+DNwKvAzYl+Q6eiF2TXtVSsNnQEkdUFUfAD6woPk4vd6UNJY8xCdJ6iQDSpLUSQaUJA3N/MljnUD21DZtQC0crOeAPUntm5s89uStN25LS9m0F0mcHKzXz5CSpFGxaXtQkqTRZkBJkjrJgJIkdZIBJUnqJANKktRJBpQkqZNWDKgktyc5luSRvrazk9yX5Inm/qy+525McjjJ40muGFThkqTNbTU9qDuAKxe03QAcqKodwIHmMUkuAnYBr2+2+VCSLRtWrSRpbKwYUFV1P/DcguadwN5meS9wdV/73VV1vKqeBA4Dl2xMqZKkcbLWc1DnVdVRgOb+3KZ9O/BM33pHmrZFkuxJcjDJwdnZ2TWWIUnarDb6Ioml5hJaON9Qr7Hq1qqarqrpiYmJDS5DkjTq1hpQM0m2ATT3x5r2I8AFfeudDzy79vIkSeNqrQG1H9jdLO8G7u1r35Vka5ILgR3Ag+srsWucLl+ShmHF2cyT3AVcCpyT5Ai9r6W+BdiX5DrgaeAagKp6NMk+4DHgBHB9VT0/oNpbMjdd/kkzM86SLkkbbcWAqqprl3nqsmXWvxm4eT1FSZLkTBKSpE4yoKQOSPKKJPck+XqSQ0nefKoZW6RxYEBJ3fAbwKer6m8DPwYcYpkZW6RxYUBJLUvycuCtwG0AVfX9qvozlp+xRRoLBpTUvlcDs8BvJflyko8kOZPlZ2yZx1lZRt1Wh60sw4CS2ncGcDHw4ap6I/AXnMbhPGdlGXVzQ1d6t5mZp1qupzsMKKl9R4AjVfVA8/geeoG13Iwt0lgwoKSWVdW3gWeSvLZpuozeYPflZmyRxsKKA3UlDcXPAXcmeTHwDeBn6X2AXDRjizQuDCipA6rqYWB6iaeWnLFFGgce4pMkdZIBtSG8TFSSNpqH+DbE/BnOnd1cktbPHpQkqZMMKElSJxlQkqROMqAkSZ1kQEmSOsmAkiR10qYJqMnJqXljkSRJo23TjIPqTVFffS2GlCSNsk3Tg5KkzcGZaeZsmh6UJG0Ozkwzxx6UJKmTDChJUicZUJKkTjKgBsKTnJK0Xl4kMRCe5JSk9bIHJUnqJANKktRJBpQkqZMMKElSJxlQUkck2ZLky0k+1Tw+O8l9SZ5o7s9qu0ZpmAwoqTveCxzqe3wDcKCqdgAHmsfS2DCgpA5Icj7wk8BH+pp3Anub5b3A1UMuS2qVASV1w68D7wde6Gs7r6qOAjT35y61YZI9SQ4mOTg7OzvwQqVhMaCkliV5J3Csqh5ay/ZVdWtVTVfV9MTExAZXJ7XHmSSk9r0FuCrJO4CXAC9P8jvATJJtVXU0yTbgWKtVSkNmD0pqWVXdWFXnV9UUsAv4XFW9C9gP7G5W2w3c21KJUisMKKm7bgHeluQJ4G3NY42d+ZNPj9ME1B7ikzqkqr4AfKFZ/hPgsjbrURfMn3waxmcCantQkkbW5OTUot6FNo919aCSfBP4HvA8cKKqppOcDXwMmAK+CfzTqvrT9ZUpSYvNzDzFwt4FGFKbxUb0oH68qt5QVdPNY0e/S5LWbRCH+Bz9vsj4nuSUpLVab0AV8NkkDyXZ07Q5+n2RuZOcJ2+9QxOSpOWsN6DeUlUXA28Hrk/y1tVu6Oh3SStZeBGERx7Gy7oukqiqZ5v7Y0k+CVyCo98lbZCFF0GMy+XV6llzDyrJmUl+aG4ZuBx4BEe/S5I2wHp6UOcBn2zGHZwBfLSqPp3kD4F9Sa4DngauWX+ZkqRxs+aAqqpvAD+2RLuj3yUNyFYH444RpzqSNEIWTvtjWG1mTnUkSeokA0qS1EkGlCSpkwwoSRo5W8diALMB1Zrx+AWTNAjzp0/brFOneRVfa+ZfjeQIeUmazx6UJKmTDChJUicZUJKkTjKgJEmdZEBJLUtyQZLPJzmU5NEk723az05yX5Inmvuz2q5VGiYDSmrfCeAXqup1wJvoffnnRcANwIGq2gEcaB5LY8OAklpWVUer6kvN8veAQ8B2YCewt1ltL3B1KwVKLTGgpA5JMgW8EXgAOK+qjkIvxIBzl9lmT5KDSQ7Ozs4OrVZp0AwoqSOSvAz4OPC+qvruarerqlurarqqpicmJgZXoDRkBlSHTU5OOR3SmEjyInrhdGdVfaJpnkmyrXl+G3CsrfqkNhhQHdabX2vzz7c17tL7itjbgENV9cG+p/YDu5vl3cC9w65tmBZ+IPObc+VcfFL73gL8DPC1JA83bb8E3ALsS3Id8DRwTTvlDcfJD2T9DKlxZkBJLauq32f5v8SXDbMWqUs8xCdJI2/rosOjm+GctT0oSRp587++BzbHV/jYg5KkTWn0vxTVHlRnbPWqJUkbaPS/FNWA6ozFXXSvYJI0zjzEJ0nqJANKktRJIxtQC0edj4fRP+kpSas1suegFo86H4eQGv2TnpK0WiPbg5IkbW4GlCSNhdE7RWBAbTJ+RYekpc2dIhidb0cY2XNQWtrCc3Oep5I0quxBSZI6yYCSJHWSASVJ6iQDaqQt/g4YqQuW+vr2LVvO9AIenRYvkhhpTjCrblrq69tfeCF4AY9Ox0j0oJb6NKbV2pzftClp8xuJgDr5aaz/ptWZP/ZhVMY/SBq0lT+8LtU5GOYH3JEIKG20rZ4bGFODGsi9tsmbt3pUpFUrf3hdqnMwzA+4noMaS/PPXXluYHwMaiD32iZvXngO1d87zTewHlSSK5M8nuRwkhsG9TrSZjb4/ej0z1F6TnjcnXpOv408LDiQgEqyBfhvwNuBi4Brk1w0iNfSICz+o7URhwHbPp69kq7NYzic/ej0z1F6TngzW81h11PP6beRhwUH1YO6BDhcVd+oqu8DdwM7B/Ra2nCL/2i98MJfMv8X7tsr/jFf+Ad/6V/cb58yCBc+HmRwLKyvAxeTuB9pyBbu++0a1Dmo7cAzfY+PAH+vf4Uke4A9zcP/l+RPgO8s/yOXSvOFbSs93qh1cg6Lam2tltVsM6B6T5qZeWqVh3pOvU4vCPlBvc3jNb7WWsz/uSu8zt8aUBFzVtyPYMl96fFT/9iV/69X/vdd9e/qgt+9QewnQ9u3zoGssB+t6ecOaJtTrtP8v2zMz138+3Lav1NL7kuDCqilKpkXx1V1K3DrDzZIDlbV9IDq2VCjVCtY7whbcT+CxftSl2ym/0vfy/AN6hDfEeCCvsfnA88O6LWkzcr9SGNtUAH1h8COJBcmeTGwC9g/oNeSNiv3I421gRziq6oTSd4DfAbYAtxeVY+usFknD1EsY5RqBesdSWvcj7pmM/1f+l6GLFXtX6khSdJCTnUkSeokA0qS1EmtB9Qwp0RKckGSzyc5lOTRJO9t2s9Ocl+SJ5r7s/q2ubGp7fEkV/S1/50kX2ue+69pLvJPsjXJx5r2B5JM9W2zu3mNJ5LsPo26tyT5cpJPdb3eJK9Ick+Srzf/zm/ucr3aGEluT3IsySN9bdc0+9kLSTp/SXO/Zd7Prza/119N8skkr2ixxFVb5r38p+Z9PJzks0le2WaNy6qq1m70Tvz+MfBq4MXAV4CLBvh624CLm+UfAv6I3hQyvwLc0LTfAPxys3xRU9NW4MKm1i3Ncw8Cb6Y3VuX3gLc37f8a+O/N8i7gY83y2cA3mvuzmuWzVln3vwU+CnyqedzZeoG9wD9vll8MvKLL9XrbsH3rrcDFwCN9ba8DXgt8AZhuu8YNeD+XA2c0y78893vc9dsy7+Xlfcs/P7dPde3Wdg9qqFO5VNXRqvpSs/w94BC90fo76f1hpbm/ulneCdxdVcer6kngMHBJkm30/oP/oHr/w7+9YJu5n3UPcFnz6f8K4L6qeq6q/hS4D7hypZqTnA/8JPCRvuZO1pvk5fR2htsAqur7VfVnXa1XG6eq7geeW9B2qKpWmNWim5Z5P5+tqhPNwy/SG5fWecu8l+/2PTyTLsxrtIS2A2qpqVy2D+OFm0NDbwQeAM6rqqPQCzHg3BXq294sL2yft03zy/znwN88xc9aya8D7wde6Gvrar2vBmaB32oOSX4kyZkdrldaq3fT69mPrCQ3J3kG+GngP7Rdz1LaDqhVTeWy4S+avAz4OPC+BZ8kFq26RFudon2t2yxX5zuBY1X10KnW699kDa+9YfXSG1d3MfDhqnoj8Bf0Duktp+16pdOW5CbgBHBn27WsR1XdVFUX0Hsf72m7nqW0HVBDn8olyYvohdOdVfWJpnmmOaxEc39shfqOML9731/3D7ZJcgbwN+h1r9fyXt8CXJXkm/QOf/5Ekt/pcL1HgCNV9UDz+B56gdXVeqXT0lx8807gp5vDz5vBR4F/3HYRS2k7oIY6lUtzruI24FBVfbDvqf3A3FVfu4F7+9p3NVeOXQjsAB5sDlN9L8mbmp/5zxZsM/ez/gnwueYX+TPA5UnOaq5iu7xpW1ZV3VhV51fVFL1/m89V1bs6XO+3gWeSvLZpugx4rKv1SqcjyZXALwJXVdXiafZHSJIdfQ+vAr7eVi2n1PZVGsA76F1N98fATQN+rX9A77DPV4GHm9s76J3DOAA80dyf3bfNTU1tj9NcSda0TwOPNM/9Jidn5XgJ8D/pnfB/EHh13zbvbtoPAz97mrVfysmr+DpbL/AG4GDzb/y79K6o62y93jZs37oLOAr8Fb3e7HXATzXLx4EZ4DNt17nO93OY3nnOub8dnbzybZXv5ePN/vVV4H8B29uuc6mbUx1Jkjqp7UN8kiQtyYCSJHWSASVJ6iQDSpLUSQaUJKmTDChJUicZUJKkTvr/Zv3VXRDimvcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "var = 'LotArea'\n",
    "# 2 fitures\n",
    "ax = plt.subplot(1, 2, 1)\n",
    "# non-transformed variable    \n",
    "ax.hist(SalePrice, bins = int(180/5),\n",
    "         color = 'blue', edgecolor = 'black')\n",
    "\n",
    "ax = plt.subplot(1, 2, 2)\n",
    "# transformed_variable\n",
    "ax.hist(np.log1p(SalePrice), bins = int(180/5),\n",
    "         color = 'blue', edgecolor = 'black')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "least error is: 0.1382281067080659, best parameters are: [(0.3981071705534972, 0.0)]\n",
      "least error is: 0.13065758654150422, best parameters are: [(0.1, 0.1111111111111111)]\n",
      "least error is: 0.13065758650403755, best parameters are: [(0.1, 0.1111111111111111)]\n",
      "least error is: 0.12822409569904014, best parameters are: [(0.12181879120101156, 0.0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/martin/miniconda3/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning: overflow encountered in multiply\n",
      "  sqr = np.multiply(arr, arr, out=arr)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "least error is: 0.12375202050910084, best parameters are: [(0.4849693428528198, 0.0)]\n"
     ]
    }
   ],
   "source": [
    "error = []\n",
    "best_parameters = []\n",
    "# we iterate over list of data-sets\n",
    "for d in [base, with_box_cox, with_na, with_interactions, with_interactions2]:\n",
    "    # scale variables\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(d[:len(train_ID)]) #  fit  the scale        \n",
    "\n",
    "    X_train = scaler.transform(d[:len(train_ID)])\n",
    "    X_test = scaler.transform(d[len(train_ID):])\n",
    "    \n",
    "    # the function cross_val_score computes the model passed to it for cv=5-fold \n",
    "    # cross validation; we compute the mean over the 5 folds\n",
    "    get_results = [(l, r, np.mean(np.sqrt(-cross_val_score(ElasticNet(alpha = l,\n",
    "                                                            l1_ratio = r),\n",
    "            X_train, y , scoring = 'neg_mean_squared_error',\n",
    "            cv = 5, n_jobs = -1))))\n",
    "                for l in lamb for r in ratio]\n",
    "    \n",
    "    # the least error is extracted\n",
    "    least_error = np.min([i[2] for i in get_results])\n",
    "    error.append(least_error)\n",
    "    # the parameters belonging to the best result\n",
    "    parameters = [i[0:2] for i in get_results if i[2] == least_error]\n",
    "    best_parameters.append(parameters)\n",
    "    print(f'least error is: {least_error}, best parameters are: {parameters}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0.3981071705534972, 0.0)],\n",
       " [(0.1, 0.1111111111111111)],\n",
       " [(0.1, 0.1111111111111111)],\n",
       " [(0.12181879120101156, 0.0)],\n",
       " [(0.4849693428528198, 0.0)]]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2919, 310)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(2919, 310)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(2919, 346)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(2919, 451)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(2919, 1831)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(base.shape, with_box_cox.shape, with_na.shape, with_interactions.shape, with_interactions2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "variables": {
     "np.round(100 - (best_parameters[1][0][1] * 100))": "89.0",
     "np.round(best_parameters[0][0][0], 4)": "0.3981",
     "np.round(best_parameters[0][0][1], 4)": "0.0",
     "np.round(best_parameters[1][0][0], 4)": "0.1",
     "np.round(best_parameters[1][0][1] * 100)": "11.0",
     "np.round(best_parameters[2][0][0], 4)": "0.1",
     "np.round(error[0], 4)": "0.1382",
     "np.round(error[1], 4)": "0.1307",
     "np.round(error[2], 4)": "0.1307",
     "np.round(error[3], 4)": "0.1282"
    }
   },
   "source": [
    "We conclude:\n",
    "1. The error for the base data set (only missing values imputed) is: {{np.round(error[0], 4)}}  (mse); The corresponding lambda is {{np.round(best_parameters[0][0][0], 4)}}, i.e. the amount of regularization; the l1_ratio = {{np.round(best_parameters[0][0][1], 4)}}; the kind of regularization was pure ridge (l2-penalty)\n",
    "2. The error with some of the numeric variables box-cox transformed is {{np.round(error[1], 4)}} (mse); the amount of regularization is far less than before ({{np.round(best_parameters[1][0][0], 4)}}); we have {{np.round(best_parameters[1][0][1] * 100)}}% l1-penalty and {{np.round(100 - (best_parameters[1][0][1] * 100))}}% l2-penalty\n",
    "3. Indicator variables for formerly missing values are included in the data-set; The error ({{np.round(error[2], 4)}}) shrinks by an insignificant amount. The lambda parameter is {{np.round(best_parameters[2][0][0], 4)}}; no l1-penalty is used\n",
    "4. adding the interaction terms has the most pronounced effect. The error drops to {{np.round(error[3], 4)}}; The best parameters are as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1460"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One additional note: By including the interaction2 terms, we have __more variables (1831) than observations (1460)__ in the training set. This situation is not admissable in classical statistics. For machine learning algorithms with regularization and/or iterative optimization, it does not mean any problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have found the best parameters by cross-validation. Now, we try to solve a business problem with these results:<br>\n",
    "__The sales team needs all houses from the test set with estimated prices higher than 350'000\\$. Can you please deliver an estimate about how accurate your predictions are?__ (again we are allowed to be biased towards the test-set)<br>\n",
    "1. Compute the confidence intervals for the test-set.\n",
    "We proceed as follows:\n",
    "2. Obtain estimates for the train-set by splitting the train-set in k=5 folds and always train on 4 folds and make predictions on the 5th fold. We obtain CIs in this manner.\n",
    "3. We take the lower-bounds of the confidence intervals. This ensures, that we do not include cases (houses) with very unstable estimates.\n",
    "4. Since we trained the CIs for the training-set with cross-validation, we can treat them as an estimate for the accuracy of the CIs of the test-set: This gives us an estimate of the error we make."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from random import choices\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import KFold # import KFold\n",
    "warnings.filterwarnings('ignore')\n",
    "# we get a lot of warnings:\n",
    "# LinAlgWarning: Ill-conditioned matrix (rcond=1.80167e-08): result may not be accurate.\n",
    "#  overwrite_a=False)\n",
    "# this is because we use more variables than observations and we get the already discussed\n",
    "# problems with matrix inversion\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(with_interactions) #  fit  the scale        \n",
    "\n",
    "\n",
    "X = scaler.transform(with_interactions[:len(train_ID)])\n",
    "test = scaler.transform(with_interactions[len(train_ID):])\n",
    "\n",
    "## 1.\n",
    "indices = np.arange(0, X.shape[0])\n",
    "# draw 200 samples with replacement from training data set\n",
    "sampler = (choices(indices, k = len(indices)) for i in range(200))\n",
    "# fit 200 models to the samples drawn and predict on test-set\n",
    "# \n",
    "CIS_test = np.percentile(\n",
    "            np.array(\n",
    "                [\n",
    "                 Ridge(alpha=best_parameters[-2][0][0], fit_intercept=True)\\\n",
    "                 .fit(X[drew,:], y.values[drew]).predict(test).tolist()\n",
    "                 for drew in sampler]\n",
    "                 ), [2.5, 97.5], axis = 0)\n",
    "\n",
    "\n",
    "## 2.\n",
    "kf = KFold(n_splits = 5, shuffle=True)\n",
    "CIS = np.empty((2, X.shape[0]))\n",
    "y_hat = np.empty((y.shape[0],))\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train = X[train_index,:]\n",
    "    y_train = y[train_index]\n",
    "    X_test = X[test_index, :]\n",
    "    y_test = y[test_index]\n",
    "    indices = np.arange(0, X_train.shape[0])\n",
    "\n",
    "    sampler = (choices(indices, k = len(indices)) for i in range(200))\n",
    "    CIS[:, test_index] = np.percentile(\n",
    "        np.array(\n",
    "            [\n",
    "             Ridge(alpha=best_parameters[-1][0][0], fit_intercept=True)\\\n",
    "             .fit(X_train[drew,:], y_train.values[drew])\\\n",
    "                              .predict(X_test).tolist()\n",
    "             for drew in sampler]\n",
    "             ), [2.5, 97.5], axis = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3.\n",
    "bool_indizes = np.exp(CIS_test[0, :]) - 1 > 350000\n",
    "sum(bool_indizes)\n",
    "for_sales_departement = list(\n",
    "    zip(np.arange(0, CIS_test.shape[1])[bool_indizes], np.exp(CIS_test[0, bool_indizes])+1)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we estimate that 90.48% of our predictions are correct\n",
      "\n",
      "however, we only got 33.93% of all houses with prices higher than 350000\n"
     ]
    }
   ],
   "source": [
    "y_hat_lower = np.exp(CIS[0,:])-1\n",
    "estimates = y_hat_lower > 350000\n",
    "true = (np.exp(y) +1) > 350000\n",
    "y_hat_lower[estimates]\n",
    "print(f'we estimate that {np.round(np.mean(true[estimates]) * 100, 2)}% of our predictions are correct')\n",
    "print(f'\\nhowever, we only got {np.round(sum(true[estimates])/sum(true)*100, 2)}% of all houses with prices higher than 350000')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, suppose\n",
    "the sales team wants to use your algorith for new incoming houses. How good can we predict theses houses?\n",
    "\n",
    "__Question:__ What is the most accurate method to get a good estimate? In the example before, we fitted each statistic on the whole training-set. Is this a good idea to get an estimate about how the algorithm will perform on unseen data?\n",
    "\n",
    "__Exercise:__ get the estimates right by help of python Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/martin/python/fhnw_lecture/notebooks\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-hot encoding and adding variables for missing values is not critical: no statistics are fitted<br>\n",
    "\n",
    "we load the data (only train) once again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/train.csv', sep=\",\")\n",
    "train_ID = train['Id']\n",
    "train.drop('Id', axis = 1, inplace = True)\n",
    "SalePrice = train['SalePrice']\n",
    "train.drop('SalePrice', axis=1, inplace = True)\n",
    "categorical = [var for var in train.columns if train[var].dtype=='O']\n",
    "numerical = [var for var in train.columns if train[var].dtype!='O']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we add an indicator variable for every missing value: no statistics are fitted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[categorical] = train[categorical].fillna('None')\n",
    "for val in numerical:\n",
    "    train[val + '_na'] = pd.isnull(train[val])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the follwing statistics however, depend on the data:<br>\n",
    "- filling NAs with mean-values\n",
    "- box-cox transform of variable\n",
    "- computing the best features and forming interaction variables\n",
    "- fitting the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this task, please use the custom-function InteractionsTransformer provided in the file interactions_transformer.py; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "sys.path.append(os.path.abspath('../scripts'))\n",
    "from interactions_transformer import InteractionsTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "numeric_features = numerical\n",
    "categorical_features = categorical\n",
    "\n",
    "# please use for these steps SimpleImputer and PowerTransform -> look it up in the internet\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "                                     ])\n",
    "# one-hot encode (dummy encode) the categorical variables with OneHotEncoder\n",
    "categorical_transformer = \n",
    "\n",
    "# the ColumnTransformer combines the numeric_transformer and the categorical_transformer\n",
    "preprocessor = \n",
    "\n",
    "# use GridSearchCV, combine the preprocessor, InteractionsTransformer an ElasticNet within make_pipeline\n",
    "clf = GridSearchCV(\n",
    "            ,\n",
    "            param_grid={'elasticnet__alpha': 10**(np.linspace(-1, 0.2, 5)),\n",
    "                        'elasticnet__l1_ratio': np.linspace(0, 1, 6)},\n",
    "         cv=5, refit=False, scoring = 'neg_mean_squared_error'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting feature importance\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "sys.path.append(os.path.abspath('../scripts'))\n",
    "from interactions_transformer import InteractionsTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(missing_values=np.nan, strategy='mean')),\n",
    "    ('scaler', PowerTransformer(method='box-cox'))])\n",
    "\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numerical),\n",
    "        ('cat', categorical_transformer, categorical),\n",
    "        ])\n",
    "\n",
    "clf = GridSearchCV(\n",
    "        make_pipeline(\n",
    "            preprocessor,\n",
    "            InteractionsTransformer(),\n",
    "            ElasticNet()\n",
    "            ),\n",
    "            param_grid={'elasticnet__alpha': 10**(np.linspace(-1, 0.2, 5)),\n",
    "                        'elasticnet__l1_ratio': np.linspace(0, 1, 6)},\n",
    "         cv=5, refit=False, scoring = 'neg_mean_squared_error'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('columntransformer',\n",
       "                                        ColumnTransformer(transformers=[('num',\n",
       "                                                                         Pipeline(steps=[('imputer',\n",
       "                                                                                          SimpleImputer()),\n",
       "                                                                                         ('scaler',\n",
       "                                                                                          PowerTransformer(method='box-cox'))]),\n",
       "                                                                         ['MSSubClass',\n",
       "                                                                          'LotFrontage',\n",
       "                                                                          'LotArea',\n",
       "                                                                          'OverallQual',\n",
       "                                                                          'OverallCond',\n",
       "                                                                          'YearBuilt',\n",
       "                                                                          'YearRemodAdd',\n",
       "                                                                          'MasVnrArea',\n",
       "                                                                          'BsmtFinSF1',\n",
       "                                                                          'BsmtFinSF2',\n",
       "                                                                          'BsmtUnfSF',\n",
       "                                                                          'TotalBsmt...\n",
       "                                                                          'BsmtFinType1',\n",
       "                                                                          'BsmtFinType2',\n",
       "                                                                          'Heating',\n",
       "                                                                          'HeatingQC',\n",
       "                                                                          'CentralAir',\n",
       "                                                                          'Electrical', ...])])),\n",
       "                                       ('interactionstransformer',\n",
       "                                        InteractionsTransformer()),\n",
       "                                       ('elasticnet', ElasticNet())]),\n",
       "             param_grid={'elasticnet__alpha': array([0.1       , 0.19952623, 0.39810717, 0.79432823, 1.58489319]),\n",
       "                         'elasticnet__l1_ratio': array([0. , 0.2, 0.4, 0.6, 0.8, 1. ])},\n",
       "             refit=False, scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[numerical] += 1\n",
    "clf.fit(train, np.log1p(SalePrice))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'elasticnet__alpha': 0.1, 'elasticnet__l1_ratio': 0.0}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.12478130060340616"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(clf.best_params_, np.sqrt(-clf.best_score_))\n",
    "# clf.cv_results_.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time', 'param_elasticnet__alpha', 'param_elasticnet__l1_ratio', 'params', 'split0_test_score', 'split1_test_score', 'split2_test_score', 'split3_test_score', 'split4_test_score', 'mean_test_score', 'std_test_score', 'rank_test_score'])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.cv_results_.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.1247813 , 0.14769876, 0.16453242, 0.18267359, 0.19985306,\n",
       "       0.21528227, 0.12948769, 0.16705808, 0.20169271, 0.23435203,\n",
       "       0.26753428, 0.299449  , 0.13458011, 0.20678027, 0.27600369,\n",
       "       0.33904176, 0.39445307, 0.39954338, 0.14411109, 0.28669422,\n",
       "       0.39540082, 0.39954338, 0.39954338, 0.39954338, 0.15495452,\n",
       "       0.39657224, 0.39954338, 0.39954338, 0.39954338, 0.39954338])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(-clf.cv_results_['mean_test_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have to get the confidence intervalas CIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n",
      "starting feature importance\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold # import KFold\n",
    "from random import choices\n",
    "train[numerical] += 1\n",
    "\n",
    "kf = KFold(n_splits = 5, shuffle=True)\n",
    "CIS = np.empty((2, train.shape[0]))\n",
    "y_hat = np.empty((SalePrice.shape[0],))\n",
    "for train_index, test_index in kf.split(train):\n",
    "    X_train = train.iloc[train_index,:]\n",
    "    y_train = np.log1p(SalePrice)[train_index]\n",
    "    X_test = train.iloc[test_index, :]\n",
    "    y_test = np.log1p(SalePrice)[test_index]\n",
    "    indices = np.arange(0, X_train.shape[0])\n",
    "\n",
    "    custom_pipeline = make_pipeline(\n",
    "            preprocessor,\n",
    "            InteractionsTransformer(),\n",
    "            ElasticNet().set_params(alpha=clf.best_params_['elasticnet__alpha'],\n",
    "                                   l1_ratio=clf.best_params_['elasticnet__l1_ratio']))\n",
    "    sampler = (choices(indices, k = len(indices)) for i in range(200))\n",
    "    runs = []\n",
    "    for drew in sampler:\n",
    "        try:\n",
    "            runs.append(custom_pipeline.\\\n",
    "             fit(X_train.iloc[drew, :], y_train.iloc[drew]).predict(X_test).tolist()\n",
    "                       )\n",
    "        except:\n",
    "            pass\n",
    "            \n",
    "    CIS[:, test_index] = np.percentile(np.array(runs), [2.5, 97.5], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we estimate that 90.91% of our predictions are correct\n",
      "\n",
      "however, we only got 40.74% of all houses with prices higher than 350000\n"
     ]
    }
   ],
   "source": [
    "y_hat_lower = np.exp(CIS[0,:]) - 1\n",
    "estimates = y_hat_lower > 350000\n",
    "true = SalePrice > 350000\n",
    "y_hat_lower[estimates]\n",
    "print(f'we estimate that {np.round(np.mean(true[estimates]) * 100, 2)}% of our predictions are correct')\n",
    "print(f'\\nhowever, we only get {np.round(sum(estimates)/sum(true)*100, 2)}% of all houses with prices higher than 350000')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reminder\n",
    "We found the best parameters via extensive search over the whole data-set. As we have discussed, theoretically double-cross-validation would have been the better choice. However, it would also be computationally more expensive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
