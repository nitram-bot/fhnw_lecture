{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "patient-white",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "threaded-booth",
   "metadata": {},
   "source": [
    "## let's attack our house-prices example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "useful-rally",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "train = pd.read_csv('../data/train.csv', sep=\",\")\n",
    "test = pd.read_csv('../data/test.csv')\n",
    "\n",
    "import sklearn\n",
    "y = train['SalePrice']\n",
    "X = train.drop('SalePrice', axis=1)\n",
    "categorical = [var for var in X.columns if X[var].dtype=='O']\n",
    "numerical = [var for var in X.columns if X[var].dtype!='O']\n",
    "X[categorical] = X[categorical].fillna('None')\n",
    "\n",
    "# auto-sklearn can not deal with categorical variables\n",
    "X= pd.concat([pd.get_dummies(X[categorical], dummy_na=True), X[numerical]], axis=1)\n",
    "\n",
    "y = np.log1p(y)\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(X, y, random_state=42, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lovely-spokesman",
   "metadata": {},
   "source": [
    "# Auto-Sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eastern-friendship",
   "metadata": {},
   "source": [
    "[install auto-sklearn](https://automl.github.io/auto-sklearn/master/installation.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "spectacular-printer",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics\n",
    "import autosklearn.regression\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"default\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intensive-contributor",
   "metadata": {},
   "source": [
    "[Parameters](https://automl.github.io/auto-sklearn/master/api.html#regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09b2d5b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.15.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autosklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "stupid-solution",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11867/1984358511.py:2: DeprecationWarning: `ensemble_size` has been deprecated, please use `ensemble_kwargs = {'ensemble_size': 8}`. Inserting `ensemble_size` into `ensemble_kwargs` for now. `ensemble_size` will be removed in auto-sklearn 0.16.\n",
      "  automl = autosklearn.regression.AutoSklearnRegressor(\n"
     ]
    }
   ],
   "source": [
    "! rm -rf /tmp/autosklearn_*\n",
    "automl = autosklearn.regression.AutoSklearnRegressor(\n",
    "    #time_left_for_this_task=600,\n",
    "    time_left_for_this_task=120,\n",
    "    per_run_time_limit=10,\n",
    "    memory_limit = 4096,\n",
    "    ensemble_size = 8, \n",
    "    ensemble_nbest=4,\n",
    "    max_models_on_disc = 16,\n",
    "    n_jobs = 2,\n",
    "    include = {'regressor': ['gradient_boosting', 'ard_regression', 'sgd', 'random_forest'],\n",
    "    'feature_preprocessor': [\"no_preprocessing\"]\n",
    "              },\n",
    "    resampling_strategy = 'cv',\n",
    "    # include_preprocessors=[\"no_preprocessing\"],\n",
    "    tmp_folder='/tmp/autosklearn_regression_example_tmp',\n",
    "    # output_folder='/tmp/autosklearn_regression_example_out',\n",
    "    delete_tmp_folder_after_terminate = True,\n",
    "    # delete_output_folder_after_terminate = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "immune-release",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] [2023-04-20 21:24:15,755:Client-AutoMLSMBO(1)::house-prices] Configuration 228 not found\n",
      "[WARNING] [2023-04-20 21:24:15,755:Client-AutoMLSMBO(1)::house-prices] Configuration 58 not found\n",
      "[WARNING] [2023-04-20 21:24:15,755:Client-AutoMLSMBO(1)::house-prices] Configuration 138 not found\n",
      "[WARNING] [2023-04-20 21:24:15,755:Client-AutoMLSMBO(1)::house-prices] Configuration 23 not found\n",
      "[WARNING] [2023-04-20 21:24:15,755:Client-AutoMLSMBO(1)::house-prices] Configuration 282 not found\n",
      "[WARNING] [2023-04-20 21:24:15,755:Client-AutoMLSMBO(1)::house-prices] Configuration 257 not found\n",
      "[WARNING] [2023-04-20 21:24:15,755:Client-AutoMLSMBO(1)::house-prices] Configuration 240 not found\n",
      "[WARNING] [2023-04-20 21:24:15,755:Client-AutoMLSMBO(1)::house-prices] Configuration 214 not found\n",
      "[WARNING] [2023-04-20 21:24:15,755:Client-AutoMLSMBO(1)::house-prices] Configuration 247 not found\n",
      "[WARNING] [2023-04-20 21:24:15,755:Client-AutoMLSMBO(1)::house-prices] Configuration 66 not found\n",
      "[WARNING] [2023-04-20 21:24:15,755:Client-AutoMLSMBO(1)::house-prices] Configuration 224 not found\n",
      "[WARNING] [2023-04-20 21:24:15,755:Client-AutoMLSMBO(1)::house-prices] Configuration 197 not found\n",
      "[WARNING] [2023-04-20 21:24:15,755:Client-AutoMLSMBO(1)::house-prices] Configuration 245 not found\n",
      "[WARNING] [2023-04-20 21:24:15,755:Client-AutoMLSMBO(1)::house-prices] Configuration 7 not found\n",
      "[WARNING] [2023-04-20 21:24:15,755:Client-AutoMLSMBO(1)::house-prices] Configuration 176 not found\n",
      "[WARNING] [2023-04-20 21:24:15,755:Client-AutoMLSMBO(1)::house-prices] Configuration 124 not found\n",
      "[WARNING] [2023-04-20 21:24:15,755:Client-AutoMLSMBO(1)::house-prices] Configuration 140 not found\n",
      "[WARNING] [2023-04-20 21:24:15,755:Client-AutoMLSMBO(1)::house-prices] Configuration 266 not found\n",
      "[WARNING] [2023-04-20 21:24:15,755:Client-AutoMLSMBO(1)::house-prices] Configuration 163 not found\n",
      "[WARNING] [2023-04-20 21:24:15,755:Client-AutoMLSMBO(1)::house-prices] Configuration 270 not found\n",
      "[WARNING] [2023-04-20 21:24:15,755:Client-AutoMLSMBO(1)::house-prices] Configuration 235 not found\n",
      "[WARNING] [2023-04-20 21:24:15,755:Client-AutoMLSMBO(1)::house-prices] Configuration 86 not found\n",
      "[WARNING] [2023-04-20 21:24:15,755:Client-AutoMLSMBO(1)::house-prices] Configuration 171 not found\n",
      "[WARNING] [2023-04-20 21:24:15,755:Client-AutoMLSMBO(1)::house-prices] Configuration 237 not found\n",
      "[WARNING] [2023-04-20 21:24:15,755:Client-AutoMLSMBO(1)::house-prices] Configuration 262 not found\n",
      "[WARNING] [2023-04-20 21:24:15,755:Client-AutoMLSMBO(1)::house-prices] Configuration 98 not found\n",
      "[WARNING] [2023-04-20 21:24:15,755:Client-AutoMLSMBO(1)::house-prices] Configuration 17 not found\n",
      "[WARNING] [2023-04-20 21:24:15,755:Client-AutoMLSMBO(1)::house-prices] Configuration 67 not found\n",
      "[WARNING] [2023-04-20 21:24:15,755:Client-AutoMLSMBO(1)::house-prices] Configuration 119 not found\n",
      "[WARNING] [2023-04-20 21:24:15,755:Client-AutoMLSMBO(1)::house-prices] Configuration 57 not found\n",
      "[WARNING] [2023-04-20 21:24:15,755:Client-AutoMLSMBO(1)::house-prices] Configuration 252 not found\n",
      "[WARNING] [2023-04-20 21:24:15,755:Client-AutoMLSMBO(1)::house-prices] Configuration 10 not found\n",
      "[WARNING] [2023-04-20 21:24:15,755:Client-AutoMLSMBO(1)::house-prices] Configuration 26 not found\n",
      "[WARNING] [2023-04-20 21:24:15,755:Client-AutoMLSMBO(1)::house-prices] Configuration 115 not found\n",
      "[WARNING] [2023-04-20 21:24:15,755:Client-AutoMLSMBO(1)::house-prices] Configuration 40 not found\n",
      "[WARNING] [2023-04-20 21:24:15,755:Client-AutoMLSMBO(1)::house-prices] Configuration 276 not found\n",
      "[WARNING] [2023-04-20 21:24:15,755:Client-AutoMLSMBO(1)::house-prices] Configuration 191 not found\n",
      "[WARNING] [2023-04-20 21:24:15,755:Client-AutoMLSMBO(1)::house-prices] Configuration 92 not found\n",
      "[WARNING] [2023-04-20 21:24:15,755:Client-AutoMLSMBO(1)::house-prices] Configuration 2 not found\n",
      "[WARNING] [2023-04-20 21:24:15,755:Client-AutoMLSMBO(1)::house-prices] Configuration 43 not found\n",
      "[WARNING] [2023-04-20 21:24:15,755:Client-AutoMLSMBO(1)::house-prices] Configuration 258 not found\n",
      "[WARNING] [2023-04-20 21:24:15,755:Client-AutoMLSMBO(1)::house-prices] Configuration 158 not found\n",
      "[WARNING] [2023-04-20 21:24:15,755:Client-AutoMLSMBO(1)::house-prices] Configuration 186 not found\n",
      "[WARNING] [2023-04-20 21:24:15,755:Client-AutoMLSMBO(1)::house-prices] Configuration 70 not found\n",
      "[WARNING] [2023-04-20 21:24:15,755:Client-AutoMLSMBO(1)::house-prices] Configuration 225 not found\n",
      "[WARNING] [2023-04-20 21:24:15,755:Client-AutoMLSMBO(1)::house-prices] Configuration 232 not found\n",
      "[WARNING] [2023-04-20 21:24:15,755:Client-AutoMLSMBO(1)::house-prices] Configuration 132 not found\n",
      "[WARNING] [2023-04-20 21:24:15,755:Client-AutoMLSMBO(1)::house-prices] Configuration 268 not found\n",
      "[WARNING] [2023-04-20 21:24:15,755:Client-AutoMLSMBO(1)::house-prices] Configuration 117 not found\n",
      "[WARNING] [2023-04-20 21:24:15,755:Client-AutoMLSMBO(1)::house-prices] Configuration 199 not found\n",
      "[WARNING] [2023-04-20 21:24:15,755:Client-AutoMLSMBO(1)::house-prices] Configuration 285 not found\n",
      "[WARNING] [2023-04-20 21:24:15,755:Client-AutoMLSMBO(1)::house-prices] Configuration 77 not found\n",
      "[WARNING] [2023-04-20 21:24:15,755:Client-AutoMLSMBO(1)::house-prices] Configuration 79 not found\n",
      "[WARNING] [2023-04-20 21:24:15,755:Client-AutoMLSMBO(1)::house-prices] Configuration 28 not found\n",
      "[WARNING] [2023-04-20 21:24:15,756:Client-AutoMLSMBO(1)::house-prices] Configuration 19 not found\n",
      "[WARNING] [2023-04-20 21:24:15,756:Client-AutoMLSMBO(1)::house-prices] Configuration 150 not found\n",
      "[WARNING] [2023-04-20 21:24:15,756:Client-AutoMLSMBO(1)::house-prices] Configuration 184 not found\n",
      "[WARNING] [2023-04-20 21:24:15,756:Client-AutoMLSMBO(1)::house-prices] Configuration 31 not found\n",
      "[WARNING] [2023-04-20 21:24:15,756:Client-AutoMLSMBO(1)::house-prices] Configuration 174 not found\n",
      "[WARNING] [2023-04-20 21:24:15,756:Client-AutoMLSMBO(1)::house-prices] Configuration 13 not found\n",
      "[WARNING] [2023-04-20 21:24:15,756:Client-AutoMLSMBO(1)::house-prices] Configuration 73 not found\n",
      "[WARNING] [2023-04-20 21:24:15,756:Client-AutoMLSMBO(1)::house-prices] Configuration 54 not found\n",
      "[WARNING] [2023-04-20 21:24:15,756:Client-AutoMLSMBO(1)::house-prices] Configuration 211 not found\n",
      "[WARNING] [2023-04-20 21:24:15,756:Client-AutoMLSMBO(1)::house-prices] Configuration 217 not found\n",
      "[WARNING] [2023-04-20 21:24:15,756:Client-AutoMLSMBO(1)::house-prices] Configuration 48 not found\n",
      "[WARNING] [2023-04-20 21:24:15,756:Client-AutoMLSMBO(1)::house-prices] Configuration 6 not found\n",
      "[WARNING] [2023-04-20 21:24:15,756:Client-AutoMLSMBO(1)::house-prices] Configuration 279 not found\n",
      "[WARNING] [2023-04-20 21:24:15,756:Client-AutoMLSMBO(1)::house-prices] Configuration 207 not found\n",
      "[WARNING] [2023-04-20 21:24:15,756:Client-AutoMLSMBO(1)::house-prices] Configuration 201 not found\n",
      "[WARNING] [2023-04-20 21:24:15,756:Client-AutoMLSMBO(1)::house-prices] Configuration 126 not found\n",
      "[WARNING] [2023-04-20 21:24:15,756:Client-AutoMLSMBO(1)::house-prices] Configuration 160 not found\n",
      "[WARNING] [2023-04-20 21:24:15,756:Client-AutoMLSMBO(1)::house-prices] Configuration 274 not found\n",
      "[WARNING] [2023-04-20 21:24:15,756:Client-AutoMLSMBO(1)::house-prices] Configuration 107 not found\n",
      "[WARNING] [2023-04-20 21:24:15,756:Client-AutoMLSMBO(1)::house-prices] Configuration 39 not found\n",
      "[WARNING] [2023-04-20 21:24:15,756:Client-AutoMLSMBO(1)::house-prices] Configuration 182 not found\n",
      "[WARNING] [2023-04-20 21:24:15,756:Client-AutoMLSMBO(1)::house-prices] Configuration 156 not found\n",
      "[WARNING] [2023-04-20 21:24:15,756:Client-AutoMLSMBO(1)::house-prices] Configuration 153 not found\n",
      "[WARNING] [2023-04-20 21:24:15,756:Client-AutoMLSMBO(1)::house-prices] Configuration 102 not found\n",
      "[WARNING] [2023-04-20 21:24:15,757:Client-AutoMLSMBO(1)::house-prices] Configuration 82 not found\n",
      "[WARNING] [2023-04-20 21:24:15,757:Client-AutoMLSMBO(1)::house-prices] Configuration 63 not found\n",
      "[WARNING] [2023-04-20 21:24:15,757:Client-AutoMLSMBO(1)::house-prices] Configuration 144 not found\n",
      "[WARNING] [2023-04-20 21:24:15,757:Client-AutoMLSMBO(1)::house-prices] Configuration 105 not found\n",
      "[WARNING] [2023-04-20 21:24:15,757:Client-AutoMLSMBO(1)::house-prices] Configuration 251 not found\n",
      "[WARNING] [2023-04-20 21:24:15,757:Client-AutoMLSMBO(1)::house-prices] Configuration 193 not found\n",
      "[WARNING] [2023-04-20 21:24:15,757:Client-AutoMLSMBO(1)::house-prices] Configuration 50 not found\n",
      "[WARNING] [2023-04-20 21:24:15,757:Client-AutoMLSMBO(1)::house-prices] Configuration 148 not found\n",
      "[WARNING] [2023-04-20 21:24:15,757:Client-AutoMLSMBO(1)::house-prices] Configuration 136 not found\n",
      "[WARNING] [2023-04-20 21:24:15,757:Client-AutoMLSMBO(1)::house-prices] Configuration 204 not found\n",
      "[WARNING] [2023-04-20 21:24:15,757:Client-AutoMLSMBO(1)::house-prices] Configuration 168 not found\n",
      "[WARNING] [2023-04-20 21:24:15,757:Client-AutoMLSMBO(1)::house-prices] Configuration 221 not found\n",
      "[WARNING] [2023-04-20 21:24:15,757:Client-AutoMLSMBO(1)::house-prices] Configuration 179 not found\n",
      "[WARNING] [2023-04-20 21:24:15,757:Client-AutoMLSMBO(1)::house-prices] Configuration 110 not found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process pynisher function call:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/martin/miniconda3/envs/autosklearn/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/martin/miniconda3/envs/autosklearn/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/martin/miniconda3/envs/autosklearn/lib/python3.8/site-packages/pynisher/limit_function_call.py\", line 133, in subprocess_func\n",
      "    return_value = ((func(*args, **kwargs), 0))\n",
      "  File \"/home/martin/miniconda3/envs/autosklearn/lib/python3.8/site-packages/autosklearn/smbo.py\", line 160, in _calculate_metafeatures_encoded\n",
      "    result = calculate_all_metafeatures_encoded_labels(\n",
      "  File \"/home/martin/miniconda3/envs/autosklearn/lib/python3.8/site-packages/autosklearn/metalearning/metafeatures/metafeatures.py\", line 1115, in calculate_all_metafeatures_encoded_labels\n",
      "    return calculate_all_metafeatures(\n",
      "  File \"/home/martin/miniconda3/envs/autosklearn/lib/python3.8/site-packages/autosklearn/metalearning/metafeatures/metafeatures.py\", line 1194, in calculate_all_metafeatures\n",
      "    X_transformed = DPP.fit_transform(X)\n",
      "  File \"/home/martin/miniconda3/envs/autosklearn/lib/python3.8/site-packages/sklearn/base.py\", line 699, in fit_transform\n",
      "    return self.fit(X, **fit_params).transform(X)\n",
      "  File \"/home/martin/miniconda3/envs/autosklearn/lib/python3.8/site-packages/autosklearn/pipeline/components/data_preprocessing/feature_type.py\", line 216, in fit\n",
      "    self.column_transformer.fit(X, y)\n",
      "  File \"/home/martin/miniconda3/envs/autosklearn/lib/python3.8/site-packages/sklearn/compose/_column_transformer.py\", line 470, in fit\n",
      "    self.fit_transform(X, y=y)\n",
      "  File \"/home/martin/miniconda3/envs/autosklearn/lib/python3.8/site-packages/sklearn/compose/_column_transformer.py\", line 507, in fit_transform\n",
      "    result = self._fit_transform(X, y, _fit_transform_one)\n",
      "  File \"/home/martin/miniconda3/envs/autosklearn/lib/python3.8/site-packages/sklearn/compose/_column_transformer.py\", line 434, in _fit_transform\n",
      "    return Parallel(n_jobs=self.n_jobs)(\n",
      "  File \"/home/martin/miniconda3/envs/autosklearn/lib/python3.8/site-packages/joblib/parallel.py\", line 1085, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/home/martin/miniconda3/envs/autosklearn/lib/python3.8/site-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/martin/miniconda3/envs/autosklearn/lib/python3.8/site-packages/joblib/parallel.py\", line 819, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/home/martin/miniconda3/envs/autosklearn/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/home/martin/miniconda3/envs/autosklearn/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/home/martin/miniconda3/envs/autosklearn/lib/python3.8/site-packages/joblib/parallel.py\", line 288, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/home/martin/miniconda3/envs/autosklearn/lib/python3.8/site-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/home/martin/miniconda3/envs/autosklearn/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/home/martin/miniconda3/envs/autosklearn/lib/python3.8/site-packages/sklearn/pipeline.py\", line 754, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/home/martin/miniconda3/envs/autosklearn/lib/python3.8/site-packages/sklearn/pipeline.py\", line 378, in fit_transform\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"/home/martin/miniconda3/envs/autosklearn/lib/python3.8/site-packages/sklearn/pipeline.py\", line 303, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"/home/martin/miniconda3/envs/autosklearn/lib/python3.8/site-packages/joblib/memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/home/martin/miniconda3/envs/autosklearn/lib/python3.8/site-packages/sklearn/pipeline.py\", line 754, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/home/martin/miniconda3/envs/autosklearn/lib/python3.8/site-packages/sklearn/base.py\", line 699, in fit_transform\n",
      "    return self.fit(X, **fit_params).transform(X)\n",
      "  File \"/home/martin/miniconda3/envs/autosklearn/lib/python3.8/site-packages/autosklearn/pipeline/components/data_preprocessing/imputation/categorical_imputation.py\", line 58, in fit\n",
      "    self.preprocessor.fit(X)\n",
      "  File \"/home/martin/miniconda3/envs/autosklearn/lib/python3.8/site-packages/sklearn/impute/_base.py\", line 288, in fit\n",
      "    X = self._validate_input(X, in_fit=True)\n",
      "  File \"/home/martin/miniconda3/envs/autosklearn/lib/python3.8/site-packages/sklearn/impute/_base.py\", line 266, in _validate_input\n",
      "    raise ValueError(\"SimpleImputer does not support data with dtype \"\n",
      "ValueError: SimpleImputer does not support data with dtype bool. Please provide either a numeric array (with a floating point or integer dtype) or categorical data represented either as an array with integer dtype or an array of string values with an object dtype.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] [2023-04-20 21:24:16,124:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-20 21:24:16,482:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-20 21:24:17,172:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-20 21:24:17,939:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-20 21:24:19,225:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-20 21:24:19,520:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-20 21:24:20,206:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-20 21:24:20,566:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-20 21:24:21,294:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-20 21:24:22,177:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-20 21:24:23,685:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-20 21:24:24,563:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-20 21:24:25,466:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-20 21:24:25,789:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-20 21:24:26,552:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-20 21:24:27,384:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-20 21:24:28,340:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-20 21:24:29,177:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-20 21:24:30,026:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-20 21:24:30,958:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-20 21:24:31,908:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-20 21:24:33,042:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-20 21:24:33,936:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-20 21:24:34,909:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-20 21:24:35,826:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-20 21:24:36,833:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-20 21:24:37,118:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-20 21:24:38,002:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-20 21:24:38,998:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-20 21:24:40,114:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-20 21:24:41,139:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-20 21:24:42,005:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-20 21:24:42,286:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-20 21:24:42,448:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-20 21:24:43,410:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-20 21:24:44,405:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-20 21:24:45,307:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-20 21:24:46,203:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-20 21:24:47,106:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-20 21:24:48,031:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-20 21:24:48,951:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-20 21:24:49,890:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-20 21:24:50,912:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-20 21:24:52,754:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-20 21:24:53,770:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-20 21:24:55,725:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-20 21:24:57,541:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-20 21:24:58,638:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-20 21:24:59,761:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-20 21:25:00,632:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-20 21:25:01,613:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-20 21:25:02,652:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-20 21:25:03,748:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-20 21:25:04,077:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-20 21:25:05,069:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-20 21:25:06,085:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-20 21:25:07,922:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-20 21:25:08,923:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-20 21:25:09,842:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-20 21:25:10,791:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-20 21:25:11,854:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-20 21:25:12,836:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-20 21:25:13,858:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-20 21:25:14,178:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-20 21:25:14,232:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-20 21:25:14,536:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-20 21:25:15,533:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-20 21:25:15,775:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-20 21:25:16,033:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-20 21:25:16,101:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-20 21:25:17,081:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-20 21:25:18,045:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-20 21:25:19,038:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-20 21:25:20,093:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-20 21:25:20,418:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-20 21:25:20,477:Client-EnsembleBuilder] No runs were available to build an ensemble from\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] [2023-04-20 21:25:21,372:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-20 21:25:22,421:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-20 21:25:23,447:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-20 21:25:24,381:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-20 21:25:24,688:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-20 21:25:25,562:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-20 21:25:26,582:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-20 21:25:27,501:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-20 21:25:27,806:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-20 21:25:28,825:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-20 21:25:29,915:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-20 21:25:30,258:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-20 21:25:30,302:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-20 21:25:31,368:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-20 21:25:32,445:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-20 21:25:33,629:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-20 21:25:34,638:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-20 21:25:35,555:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-20 21:25:36,467:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-20 21:25:37,429:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-20 21:25:38,582:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-20 21:25:39,540:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-20 21:25:40,624:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-20 21:25:41,887:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-20 21:25:41,928:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-20 21:25:42,937:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-20 21:25:43,277:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-20 21:25:43,327:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-20 21:25:44,301:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-20 21:25:45,272:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-20 21:25:46,428:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-20 21:25:46,765:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-20 21:25:46,813:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-20 21:25:47,783:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-20 21:25:48,720:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-20 21:25:49,674:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-20 21:25:50,807:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-20 21:25:51,765:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-20 21:25:52,728:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-20 21:25:53,918:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-20 21:25:54,927:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-20 21:25:56,026:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-20 21:25:56,372:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-20 21:25:56,421:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-20 21:25:57,390:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-20 21:25:58,407:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-20 21:25:59,430:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-20 21:25:59,775:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-20 21:26:00,648:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-20 21:26:01,840:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-20 21:26:02,849:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-04-20 21:26:03,837:Client-EnsembleBuilder] No runs were available to build an ensemble from\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sys:1: ResourceWarning: unclosed socket <zmq.Socket(zmq.PUSH) at 0xffff75cfcd00>\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "sys:1: ResourceWarning: unclosed socket <zmq.Socket(zmq.PUSH) at 0xffff75d90520>\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AutoSklearnRegressor(ensemble_class=<class 'autosklearn.ensembles.ensemble_selection.EnsembleSelection'>,\n",
       "                     ensemble_kwargs={'ensemble_size': 8}, ensemble_nbest=4,\n",
       "                     ensemble_size=8,\n",
       "                     include={'feature_preprocessor': ['no_preprocessing'],\n",
       "                              'regressor': ['gradient_boosting',\n",
       "                                            'ard_regression', 'sgd',\n",
       "                                            'random_forest']},\n",
       "                     max_models_on_disc=16, memory_limit=4096, n_jobs=2,\n",
       "                     per_run_time_limit=10, resampling_strategy='cv',\n",
       "                     time_left_for_this_task=120,\n",
       "                     tmp_folder='/tmp/autosklearn_regression_example_tmp')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "automl.fit(X_train, y_train, dataset_name='house-prices')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "objective-destruction",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "No model found. Try increasing 'time_left_for_this_task'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mautoml\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      3\u001b[0m autosklearn\u001b[38;5;241m.\u001b[39m__version__\n",
      "File \u001b[0;32m~/miniconda3/envs/autosklearn/lib/python3.8/site-packages/autosklearn/estimators.py:888\u001b[0m, in \u001b[0;36mAutoSklearnEstimator.show_models\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    806\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mshow_models\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    807\u001b[0m     \u001b[38;5;124;03m\"\"\"Returns a dictionary containing dictionaries of ensemble models.\u001b[39;00m\n\u001b[1;32m    808\u001b[0m \n\u001b[1;32m    809\u001b[0m \u001b[38;5;124;03m    Each model in the ensemble can be accessed by giving its ``model_id`` as key.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    885\u001b[0m \n\u001b[1;32m    886\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: E501\u001b[39;00m\n\u001b[0;32m--> 888\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautoml_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/autosklearn/lib/python3.8/site-packages/autosklearn/automl.py:2168\u001b[0m, in \u001b[0;36mAutoML.show_models\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2166\u001b[0m \u001b[38;5;66;03m# Checking if the dictionary is empty\u001b[39;00m\n\u001b[1;32m   2167\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m table_dict:\n\u001b[0;32m-> 2168\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   2169\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo model found. Try increasing \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime_left_for_this_task\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2170\u001b[0m     )\n\u001b[1;32m   2172\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (_, model_id, _), weight \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mensemble_\u001b[38;5;241m.\u001b[39mget_identifiers_with_weights():\n\u001b[1;32m   2173\u001b[0m     table_dict[model_id][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensemble_weight\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m weight\n",
      "\u001b[0;31mRuntimeError\u001b[0m: No model found. Try increasing 'time_left_for_this_task'."
     ]
    }
   ],
   "source": [
    "print(automl.show_models())\n",
    "\n",
    "autosklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "forward-gender",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score: 0.9093487621575952\n",
      "mean-squared-error: 0.1300635118339904\n"
     ]
    }
   ],
   "source": [
    "predictions = automl.predict(X_test)\n",
    "print(\"R2 score:\", sklearn.metrics.r2_score(y_test, predictions))\n",
    "print(\"mean-squared-error:\", sklearn.metrics.mean_squared_error(y_test, predictions, squared=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "80b67e20",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/tmp/autosklearn_regression_example_tmp/.auto-sklearn/datamanager.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [22]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mautoml\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_ensemble\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/AutoMLSklearn/lib/python3.8/site-packages/autosklearn/estimators.py:491\u001b[0m, in \u001b[0;36mAutoSklearnEstimator.fit_ensemble\u001b[0;34m(self, y, task, precision, dataset_name, ensemble_nbest, ensemble_size)\u001b[0m\n\u001b[1;32m    486\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mautoml_ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    487\u001b[0m     \u001b[38;5;66;03m# Build a dummy automl object to call fit_ensemble\u001b[39;00m\n\u001b[1;32m    488\u001b[0m     \u001b[38;5;66;03m# The ensemble size is honored in the .automl_.fit_ensemble\u001b[39;00m\n\u001b[1;32m    489\u001b[0m     \u001b[38;5;66;03m# call\u001b[39;00m\n\u001b[1;32m    490\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mautoml_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild_automl()\n\u001b[0;32m--> 491\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautoml_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_ensemble\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprecision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprecision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensemble_nbest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensemble_nbest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensemble_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensemble_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/AutoMLSklearn/lib/python3.8/site-packages/autosklearn/automl.py:1503\u001b[0m, in \u001b[0;36mAutoML.fit_ensemble\u001b[0;34m(self, y, task, precision, dataset_name, ensemble_nbest, ensemble_size)\u001b[0m\n\u001b[1;32m   1501\u001b[0m manager\u001b[38;5;241m.\u001b[39mbuild_ensemble(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dask_client)\n\u001b[1;32m   1502\u001b[0m future \u001b[38;5;241m=\u001b[39m manager\u001b[38;5;241m.\u001b[39mfutures\u001b[38;5;241m.\u001b[39mpop()\n\u001b[0;32m-> 1503\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1504\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1505\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError building the ensemble - please check the log file and command \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1506\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mline output for error messages.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/AutoMLSklearn/lib/python3.8/site-packages/distributed/client.py:283\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    282\u001b[0m     typ, exc, tb \u001b[38;5;241m=\u001b[39m result\n\u001b[0;32m--> 283\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcancelled\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m result\n",
      "File \u001b[0;32m~/miniconda3/envs/AutoMLSklearn/lib/python3.8/site-packages/autosklearn/ensemble_builder.py:349\u001b[0m, in \u001b[0;36mfit_and_return_ensemble\u001b[0;34m()\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit_and_return_ensemble\u001b[39m(\n\u001b[1;32m    260\u001b[0m     backend: Backend,\n\u001b[1;32m    261\u001b[0m     dataset_name: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    283\u001b[0m         Optional[np\u001b[38;5;241m.\u001b[39mndarray],\n\u001b[1;32m    284\u001b[0m ]:\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    286\u001b[0m \n\u001b[1;32m    287\u001b[0m \u001b[38;5;124;03m    A short function to fit and create an ensemble. It is just a wrapper to easily send\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    347\u001b[0m \n\u001b[1;32m    348\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 349\u001b[0m     result \u001b[38;5;241m=\u001b[39m EnsembleBuilder(\n\u001b[1;32m    350\u001b[0m         backend\u001b[38;5;241m=\u001b[39mbackend,\n\u001b[1;32m    351\u001b[0m         dataset_name\u001b[38;5;241m=\u001b[39mdataset_name,\n\u001b[1;32m    352\u001b[0m         task_type\u001b[38;5;241m=\u001b[39mtask_type,\n\u001b[1;32m    353\u001b[0m         metric\u001b[38;5;241m=\u001b[39mmetric,\n\u001b[1;32m    354\u001b[0m         ensemble_size\u001b[38;5;241m=\u001b[39mensemble_size,\n\u001b[1;32m    355\u001b[0m         ensemble_nbest\u001b[38;5;241m=\u001b[39mensemble_nbest,\n\u001b[1;32m    356\u001b[0m         max_models_on_disc\u001b[38;5;241m=\u001b[39mmax_models_on_disc,\n\u001b[1;32m    357\u001b[0m         seed\u001b[38;5;241m=\u001b[39mseed,\n\u001b[1;32m    358\u001b[0m         precision\u001b[38;5;241m=\u001b[39mprecision,\n\u001b[1;32m    359\u001b[0m         memory_limit\u001b[38;5;241m=\u001b[39mmemory_limit,\n\u001b[1;32m    360\u001b[0m         read_at_most\u001b[38;5;241m=\u001b[39mread_at_most,\n\u001b[1;32m    361\u001b[0m         random_state\u001b[38;5;241m=\u001b[39mrandom_state,\n\u001b[1;32m    362\u001b[0m         logger_port\u001b[38;5;241m=\u001b[39mlogger_port,\n\u001b[1;32m    363\u001b[0m         unit_test\u001b[38;5;241m=\u001b[39munit_test,\n\u001b[1;32m    364\u001b[0m     )\u001b[38;5;241m.\u001b[39mrun(\n\u001b[1;32m    365\u001b[0m         end_at\u001b[38;5;241m=\u001b[39mend_at,\n\u001b[1;32m    366\u001b[0m         iteration\u001b[38;5;241m=\u001b[39miteration,\n\u001b[1;32m    367\u001b[0m         return_predictions\u001b[38;5;241m=\u001b[39mreturn_predictions,\n\u001b[1;32m    368\u001b[0m         pynisher_context\u001b[38;5;241m=\u001b[39mpynisher_context,\n\u001b[1;32m    369\u001b[0m     )\n\u001b[1;32m    370\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/miniconda3/envs/AutoMLSklearn/lib/python3.8/site-packages/autosklearn/ensemble_builder.py:571\u001b[0m, in \u001b[0;36m__init__\u001b[0;34m()\u001b[0m\n\u001b[1;32m    568\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidation_performance_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39minf\n\u001b[1;32m    570\u001b[0m \u001b[38;5;66;03m# Track the ensemble performance\u001b[39;00m\n\u001b[0;32m--> 571\u001b[0m datamanager \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackend\u001b[38;5;241m.\u001b[39mload_datamanager()\n\u001b[1;32m    572\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_valid \u001b[38;5;241m=\u001b[39m datamanager\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mY_valid\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    573\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_test \u001b[38;5;241m=\u001b[39m datamanager\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mY_test\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/AutoMLSklearn/lib/python3.8/site-packages/autosklearn/automl_common/common/utils/backend.py:325\u001b[0m, in \u001b[0;36mload_datamanager\u001b[0;34m()\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_datamanager\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DATAMANAGER_TYPE:\n\u001b[1;32m    324\u001b[0m     filepath \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_datamanager_pickle_filename()\n\u001b[0;32m--> 325\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filepath, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fh:\n\u001b[1;32m    326\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m cast(DATAMANAGER_TYPE, pickle\u001b[38;5;241m.\u001b[39mload(fh))\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/tmp/autosklearn_regression_example_tmp/.auto-sklearn/datamanager.pkl'"
     ]
    }
   ],
   "source": [
    "automl.fit_ensemble(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "filled-accessory",
   "metadata": {},
   "source": [
    "# Scikit-Optimize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "voluntary-flower",
   "metadata": {},
   "source": [
    "Probably you'll have to reload the notebook for the changes being in place. Scikit-Optimize works only with sklearn 0.23.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "otherwise-blend",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-optimize in /home/martin/miniconda3/envs/autoML/lib/python3.8/site-packages (0.9.0)\n",
      "Requirement already satisfied: numpy in /home/martin/miniconda3/envs/autoML/lib/python3.8/site-packages (1.22.3)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/martin/miniconda3/envs/autoML/lib/python3.8/site-packages (from scikit-optimize) (1.1.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /home/martin/miniconda3/envs/autoML/lib/python3.8/site-packages (from scikit-optimize) (1.8.0)\n",
      "Requirement already satisfied: pyaml>=16.9 in /home/martin/miniconda3/envs/autoML/lib/python3.8/site-packages (from scikit-optimize) (21.10.1)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in /home/martin/miniconda3/envs/autoML/lib/python3.8/site-packages (from scikit-optimize) (0.24.2)\n",
      "Requirement already satisfied: PyYAML in /home/martin/miniconda3/envs/autoML/lib/python3.8/site-packages (from pyaml>=16.9->scikit-optimize) (6.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/martin/miniconda3/envs/autoML/lib/python3.8/site-packages (from scikit-learn>=0.20.0->scikit-optimize) (3.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-optimize numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "powerful-glasgow",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.9.0'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'0.24.2'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import skopt\n",
    "import importlib\n",
    "import sklearn\n",
    "display(skopt.__version__)\n",
    "importlib.reload(sklearn)\n",
    "display(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "asian-onion",
   "metadata": {},
   "source": [
    "Since BayesSearchCV can not deal with missing values, we have to impute them before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "worldwide-disease",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_106/1116315872.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train.loc[:, numerical] = numeric_transformer.fit_transform(X_train.loc[:, numerical])\n",
      "/tmp/ipykernel_106/1116315872.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test.loc[:, numerical] = numeric_transformer.fit_transform(X_test.loc[:, numerical])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "numeric_transformer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "\n",
    "X_train.loc[:, numerical] = numeric_transformer.fit_transform(X_train.loc[:, numerical])\n",
    "X_test.loc[:, numerical] = numeric_transformer.fit_transform(X_test.loc[:, numerical])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "prompt-newman",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/martin/miniconda3/envs/autoML/lib/python3.8/site-packages/skopt/searchcv.py:300: UserWarning: The `iid` parameter has been deprecated and will be ignored.\n",
      "  warnings.warn(\"The `iid` parameter has been deprecated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/martin/miniconda3/envs/autoML/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BayesSearchCV(cv=5, estimator=GradientBoostingRegressor(), iid=True, n_iter=64,\n",
       "              n_jobs=-1, random_state=0,\n",
       "              search_spaces={'learning_rate': Real(low=0.1, high=0.3, prior='uniform', transform='normalize'),\n",
       "                             'loss': Categorical(categories=('ls',), prior=None),\n",
       "                             'max_depth': Integer(low=3, high=6, prior='uniform', transform='normalize'),\n",
       "                             'max_features': Real(low=0.6, high=1.0, prior='uniform', transform='normalize'),\n",
       "                             'n_estimators': Integer(low=100, high=600, prior='uniform', transform='normalize'),\n",
       "                             'subsample': Real(low=0.6, high=1.0, prior='uniform', transform='normalize')},\n",
       "              verbose=1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from skopt.space import Real, Categorical, Integer\n",
    "from skopt import BayesSearchCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "regressor = BayesSearchCV(\n",
    "    estimator = GradientBoostingRegressor(),\n",
    "      search_spaces ={\n",
    "         'learning_rate': Real(0.1,0.3),\n",
    "         'loss': Categorical(['ls']),\n",
    "         'max_depth': Integer(3,6),\n",
    "         'n_estimators': Integer(100, 600),\n",
    "         'subsample': Real(0.6, 1.0),\n",
    "         'max_features': Real(0.6, 1.0) \n",
    "      },\n",
    "    n_iter=64,\n",
    "    random_state=0,\n",
    "    verbose=1, iid=True,\n",
    "    cv=5, n_jobs=-1\n",
    "  )\n",
    "regressor.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "derived-tribute",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean-squared-error: 0.1345759695614586\n"
     ]
    }
   ],
   "source": [
    "predictions = regressor.predict(X_test)\n",
    "print(\"mean-squared-error:\", sklearn.metrics.mean_squared_error(y_test, predictions, squared=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abroad-property",
   "metadata": {},
   "source": [
    "# TPOT (Tree-based Pipeline Optimization Tool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "regulation-employer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tpot\n",
      "  Downloading TPOT-0.11.7-py3-none-any.whl (87 kB)\n",
      "\u001b[K     |████████████████████████████████| 87 kB 706 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy>=1.3.1 in /home/martin/miniconda3/envs/autoML/lib/python3.8/site-packages (from tpot) (1.8.0)\n",
      "Collecting tqdm>=4.36.1\n",
      "  Downloading tqdm-4.64.0-py2.py3-none-any.whl (78 kB)\n",
      "\u001b[K     |████████████████████████████████| 78 kB 1.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pandas>=0.24.2 in /home/martin/miniconda3/envs/autoML/lib/python3.8/site-packages (from tpot) (1.4.2)\n",
      "Collecting xgboost>=1.1.0\n",
      "  Downloading xgboost-1.6.0-py3-none-manylinux2014_x86_64.whl (193.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 193.7 MB 23 kB/s  eta 0:00:01   |█▍                              | 8.6 MB 1.7 MB/s eta 0:01:47     |█▊                              | 10.2 MB 2.5 MB/s eta 0:01:14     |██▏                             | 13.1 MB 2.7 MB/s eta 0:01:08     |██▏                             | 13.3 MB 2.7 MB/s eta 0:01:08     |███▎                            | 20.0 MB 1.9 MB/s eta 0:01:33     |████████▎                       | 49.8 MB 1.7 MB/s eta 0:01:24     |█████████████▎                  | 80.1 MB 2.4 MB/s eta 0:00:47     |███████████████                 | 91.5 MB 2.4 MB/s eta 0:00:44     |████████████████▉               | 102.2 MB 904 kB/s eta 0:01:42     |███████████████████▊            | 119.1 MB 1.9 MB/s eta 0:00:39     |███████████████████▊            | 119.5 MB 1.9 MB/s eta 0:00:39     |████████████████████            | 121.5 MB 1.8 MB/s eta 0:00:41     |█████████████████████▌          | 130.0 MB 1.3 MB/s eta 0:00:48     |██████████████████████▉         | 138.0 MB 1.9 MB/s eta 0:00:29     |██████████████████████▉         | 138.1 MB 1.6 MB/s eta 0:00:34     |██████████████████████████▍     | 159.5 MB 1.4 MB/s eta 0:00:24     |██████████████████████████▋     | 160.9 MB 1.4 MB/s eta 0:00:25     |███████████████████████████▊    | 167.6 MB 2.1 MB/s eta 0:00:13     |███████████████████████████▉    | 168.6 MB 2.1 MB/s eta 0:00:12\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.16.3 in /home/martin/miniconda3/envs/autoML/lib/python3.8/site-packages (from tpot) (1.22.3)\n",
      "Collecting deap>=1.2\n",
      "  Downloading deap-1.3.1-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (160 kB)\n",
      "\u001b[K     |████████████████████████████████| 160 kB 630 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting update-checker>=0.16\n",
      "  Downloading update_checker-0.18.0-py3-none-any.whl (7.0 kB)\n",
      "Requirement already satisfied: scikit-learn>=0.22.0 in /home/martin/miniconda3/envs/autoML/lib/python3.8/site-packages (from tpot) (0.24.2)\n",
      "Collecting stopit>=1.1.1\n",
      "  Downloading stopit-1.1.2.tar.gz (18 kB)\n",
      "Requirement already satisfied: joblib>=0.13.2 in /home/martin/miniconda3/envs/autoML/lib/python3.8/site-packages (from tpot) (1.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/martin/miniconda3/envs/autoML/lib/python3.8/site-packages (from pandas>=0.24.2->tpot) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/martin/miniconda3/envs/autoML/lib/python3.8/site-packages (from pandas>=0.24.2->tpot) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/martin/miniconda3/envs/autoML/lib/python3.8/site-packages (from python-dateutil>=2.8.1->pandas>=0.24.2->tpot) (1.16.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/martin/miniconda3/envs/autoML/lib/python3.8/site-packages (from scikit-learn>=0.22.0->tpot) (3.1.0)\n",
      "Collecting requests>=2.3.0\n",
      "  Downloading requests-2.27.1-py2.py3-none-any.whl (63 kB)\n",
      "\u001b[K     |████████████████████████████████| 63 kB 853 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /home/martin/miniconda3/envs/autoML/lib/python3.8/site-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (2021.10.8)\n",
      "Collecting idna<4,>=2.5\n",
      "  Downloading idna-3.3-py3-none-any.whl (61 kB)\n",
      "\u001b[K     |████████████████████████████████| 61 kB 1.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /home/martin/miniconda3/envs/autoML/lib/python3.8/site-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (1.26.9)\n",
      "Collecting charset-normalizer~=2.0.0\n",
      "  Downloading charset_normalizer-2.0.12-py3-none-any.whl (39 kB)\n",
      "Building wheels for collected packages: stopit\n",
      "  Building wheel for stopit (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for stopit: filename=stopit-1.1.2-py3-none-any.whl size=11956 sha256=a25b56fe011a2c8b346590198826898d2f3c39c536941c0af19b58d7a527bb6a\n",
      "  Stored in directory: /home/martin/.cache/pip/wheels/a8/bb/8f/6b9328d23c2dcedbfeb8498b9f650d55d463089e3b8fc0bfb2\n",
      "Successfully built stopit\n",
      "Installing collected packages: idna, charset-normalizer, requests, xgboost, update-checker, tqdm, stopit, deap, tpot\n",
      "Successfully installed charset-normalizer-2.0.12 deap-1.3.1 idna-3.3 requests-2.27.1 stopit-1.1.2 tpot-0.11.7 tqdm-4.64.0 update-checker-0.18.0 xgboost-1.6.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tpot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "homeless-shareware",
   "metadata": {},
   "source": [
    "the steps below require a new-start of the notebook - if not the changes are not in place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "polish-horse",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ipywidgets\n",
      "  Downloading ipywidgets-7.7.0-py2.py3-none-any.whl (123 kB)\n",
      "\u001b[K     |████████████████████████████████| 123 kB 736 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting jupyterlab-widgets>=1.0.0\n",
      "  Downloading jupyterlab_widgets-1.1.0-py3-none-any.whl (245 kB)\n",
      "\u001b[K     |████████████████████████████████| 245 kB 1.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: traitlets>=4.3.1 in /home/martin/miniconda3/envs/autoML/lib/python3.8/site-packages (from ipywidgets) (5.1.1)\n",
      "Collecting nbformat>=4.2.0\n",
      "  Downloading nbformat-5.3.0-py3-none-any.whl (73 kB)\n",
      "\u001b[K     |████████████████████████████████| 73 kB 1.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting ipython-genutils~=0.2.0\n",
      "  Downloading ipython_genutils-0.2.0-py2.py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in /home/martin/miniconda3/envs/autoML/lib/python3.8/site-packages (from ipywidgets) (6.9.1)\n",
      "Requirement already satisfied: ipython>=4.0.0 in /home/martin/miniconda3/envs/autoML/lib/python3.8/site-packages (from ipywidgets) (8.2.0)\n",
      "Collecting widgetsnbextension~=3.6.0\n",
      "  Downloading widgetsnbextension-3.6.0-py2.py3-none-any.whl (1.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.6 MB 1.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tornado<7.0,>=4.2 in /home/martin/miniconda3/envs/autoML/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (6.1)\n",
      "Requirement already satisfied: nest-asyncio in /home/martin/miniconda3/envs/autoML/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (1.5.5)\n",
      "Requirement already satisfied: debugpy<2.0,>=1.0.0 in /home/martin/miniconda3/envs/autoML/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (1.5.1)\n",
      "Requirement already satisfied: matplotlib-inline<0.2.0,>=0.1.0 in /home/martin/miniconda3/envs/autoML/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.2)\n",
      "Requirement already satisfied: jupyter-client<8.0 in /home/martin/miniconda3/envs/autoML/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (7.2.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/martin/miniconda3/envs/autoML/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/martin/miniconda3/envs/autoML/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (0.18.1)\n",
      "Requirement already satisfied: decorator in /home/martin/miniconda3/envs/autoML/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /home/martin/miniconda3/envs/autoML/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (3.0.20)\n",
      "Requirement already satisfied: stack-data in /home/martin/miniconda3/envs/autoML/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: backcall in /home/martin/miniconda3/envs/autoML/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: pickleshare in /home/martin/miniconda3/envs/autoML/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: setuptools>=18.5 in /home/martin/miniconda3/envs/autoML/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (61.2.0)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /home/martin/miniconda3/envs/autoML/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (2.11.2)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /home/martin/miniconda3/envs/autoML/lib/python3.8/site-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/martin/miniconda3/envs/autoML/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (2.8.2)\n",
      "Requirement already satisfied: pyzmq>=22.3 in /home/martin/miniconda3/envs/autoML/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (22.3.0)\n",
      "Requirement already satisfied: jupyter-core>=4.9.2 in /home/martin/miniconda3/envs/autoML/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (4.9.2)\n",
      "Requirement already satisfied: entrypoints in /home/martin/miniconda3/envs/autoML/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (0.4)\n",
      "Collecting jsonschema>=2.6\n",
      "  Downloading jsonschema-4.4.0-py3-none-any.whl (72 kB)\n",
      "\u001b[K     |████████████████████████████████| 72 kB 887 kB/s eta 0:00:011\n",
      "\u001b[?25hCollecting fastjsonschema\n",
      "  Downloading fastjsonschema-2.15.3-py3-none-any.whl (22 kB)\n",
      "Collecting attrs>=17.4.0\n",
      "  Downloading attrs-21.4.0-py2.py3-none-any.whl (60 kB)\n",
      "\u001b[K     |████████████████████████████████| 60 kB 1.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0\n",
      "  Downloading pyrsistent-0.18.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (119 kB)\n",
      "\u001b[K     |████████████████████████████████| 119 kB 617 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting importlib-resources>=1.4.0\n",
      "  Downloading importlib_resources-5.7.1-py3-none-any.whl (28 kB)\n",
      "Collecting zipp>=3.1.0\n",
      "  Downloading zipp-3.8.0-py3-none-any.whl (5.4 kB)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/martin/miniconda3/envs/autoML/lib/python3.8/site-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /home/martin/miniconda3/envs/autoML/lib/python3.8/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets) (0.2.5)\n",
      "Requirement already satisfied: six>=1.5 in /home/martin/miniconda3/envs/autoML/lib/python3.8/site-packages (from python-dateutil>=2.8.2->jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (1.16.0)\n",
      "Collecting notebook>=4.4.1\n",
      "  Downloading notebook-6.4.11-py3-none-any.whl (9.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 9.9 MB 178 kB/s eta 0:00:01    |▎                               | 102 kB 973 kB/s eta 0:00:11\n",
      "\u001b[?25hCollecting nbconvert>=5\n",
      "  Downloading nbconvert-6.5.0-py3-none-any.whl (561 kB)\n",
      "\u001b[K     |████████████████████████████████| 561 kB 1.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting prometheus-client\n",
      "  Downloading prometheus_client-0.14.1-py3-none-any.whl (59 kB)\n",
      "\u001b[K     |████████████████████████████████| 59 kB 2.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting argon2-cffi\n",
      "  Downloading argon2_cffi-21.3.0-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: jinja2 in /home/martin/miniconda3/envs/autoML/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.1.1)\n",
      "Collecting Send2Trash>=1.8.0\n",
      "  Downloading Send2Trash-1.8.0-py3-none-any.whl (18 kB)\n",
      "Collecting terminado>=0.8.3\n",
      "  Downloading terminado-0.13.3-py3-none-any.whl (14 kB)\n",
      "Collecting pandocfilters>=1.4.1\n",
      "  Downloading pandocfilters-1.5.0-py2.py3-none-any.whl (8.7 kB)\n",
      "Collecting jupyterlab-pygments\n",
      "  Downloading jupyterlab_pygments-0.2.2-py2.py3-none-any.whl (21 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/martin/miniconda3/envs/autoML/lib/python3.8/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.1.1)\n",
      "Collecting bleach\n",
      "  Downloading bleach-5.0.0-py3-none-any.whl (160 kB)\n",
      "\u001b[K     |████████████████████████████████| 160 kB 1.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: packaging in /home/martin/miniconda3/envs/autoML/lib/python3.8/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (21.3)\n",
      "Collecting beautifulsoup4\n",
      "  Downloading beautifulsoup4-4.11.1-py3-none-any.whl (128 kB)\n",
      "\u001b[K     |████████████████████████████████| 128 kB 1.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting mistune<2,>=0.8.1\n",
      "  Downloading mistune-0.8.4-py2.py3-none-any.whl (16 kB)\n",
      "Collecting nbclient>=0.5.0\n",
      "  Downloading nbclient-0.6.0-py3-none-any.whl (70 kB)\n",
      "\u001b[K     |████████████████████████████████| 70 kB 6.2 MB/s eta 0:00:011\n",
      "\u001b[?25hCollecting defusedxml\n",
      "  Downloading defusedxml-0.7.1-py2.py3-none-any.whl (25 kB)\n",
      "Collecting tinycss2\n",
      "  Downloading tinycss2-1.1.1-py3-none-any.whl (21 kB)\n",
      "Collecting argon2-cffi-bindings\n",
      "  Downloading argon2_cffi_bindings-21.2.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (86 kB)\n",
      "\u001b[K     |████████████████████████████████| 86 kB 2.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting cffi>=1.0.1\n",
      "  Downloading cffi-1.15.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (446 kB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████████| 446 kB 2.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pycparser\n",
      "  Downloading pycparser-2.21-py2.py3-none-any.whl (118 kB)\n",
      "\u001b[K     |████████████████████████████████| 118 kB 1.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting soupsieve>1.2\n",
      "  Downloading soupsieve-2.3.2.post1-py3-none-any.whl (37 kB)\n",
      "Collecting webencodings\n",
      "  Downloading webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/martin/miniconda3/envs/autoML/lib/python3.8/site-packages (from packaging->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.0.8)\n",
      "Requirement already satisfied: executing in /home/martin/miniconda3/envs/autoML/lib/python3.8/site-packages (from stack-data->ipython>=4.0.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: asttokens in /home/martin/miniconda3/envs/autoML/lib/python3.8/site-packages (from stack-data->ipython>=4.0.0->ipywidgets) (2.0.5)\n",
      "Requirement already satisfied: pure-eval in /home/martin/miniconda3/envs/autoML/lib/python3.8/site-packages (from stack-data->ipython>=4.0.0->ipywidgets) (0.2.2)\n",
      "Installing collected packages: zipp, pyrsistent, importlib-resources, attrs, pycparser, jsonschema, fastjsonschema, webencodings, soupsieve, nbformat, cffi, tinycss2, pandocfilters, nbclient, mistune, jupyterlab-pygments, defusedxml, bleach, beautifulsoup4, argon2-cffi-bindings, terminado, Send2Trash, prometheus-client, nbconvert, ipython-genutils, argon2-cffi, notebook, widgetsnbextension, jupyterlab-widgets, ipywidgets\n",
      "Successfully installed Send2Trash-1.8.0 argon2-cffi-21.3.0 argon2-cffi-bindings-21.2.0 attrs-21.4.0 beautifulsoup4-4.11.1 bleach-5.0.0 cffi-1.15.0 defusedxml-0.7.1 fastjsonschema-2.15.3 importlib-resources-5.7.1 ipython-genutils-0.2.0 ipywidgets-7.7.0 jsonschema-4.4.0 jupyterlab-pygments-0.2.2 jupyterlab-widgets-1.1.0 mistune-0.8.4 nbclient-0.6.0 nbconvert-6.5.0 nbformat-5.3.0 notebook-6.4.11 pandocfilters-1.5.0 prometheus-client-0.14.1 pycparser-2.21 pyrsistent-0.18.1 soupsieve-2.3.2.post1 terminado-0.13.3 tinycss2-1.1.1 webencodings-0.5.1 widgetsnbextension-3.6.0 zipp-3.8.0\n",
      "Enabling notebook extension jupyter-js-widgets/extension...\n",
      "      - Validating: \u001b[32mOK\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade ipywidgets\n",
    "!jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "hydraulic-content",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/martin/miniconda3/envs/autoML/lib/python3.8/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.\n",
      "  warnings.warn(\"Warning: optional dependency `torch` is not available. - skipping import of NN models.\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/300 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: -0.017092608323869624\n",
      "\n",
      "Generation 2 - Current best internal CV score: -0.017092608323869624\n",
      "\n",
      "Generation 3 - Current best internal CV score: -0.016553822449490378\n",
      "\n",
      "Generation 4 - Current best internal CV score: -0.016426542795711523\n",
      "\n",
      "Generation 5 - Current best internal CV score: -0.016247255156747534\n",
      "\n",
      "Best pipeline: GradientBoostingRegressor(ElasticNetCV(RidgeCV(input_matrix), l1_ratio=1.0, tol=1e-05), alpha=0.99, learning_rate=0.1, loss=lad, max_depth=9, max_features=0.1, min_samples_leaf=14, min_samples_split=10, n_estimators=100, subsample=1.0)\n",
      "0.13876233125835594\n"
     ]
    }
   ],
   "source": [
    "from tpot import TPOTRegressor\n",
    "from sklearn.datasets import load_digits \n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "tpot = TPOTRegressor(generations=5, population_size=50, verbosity=2, random_state=42, n_jobs=-1)\n",
    "tpot.fit(X_train, y_train)\n",
    "print(np.sqrt(-tpot.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4ce221",
   "metadata": {},
   "source": [
    "# FLAML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "37072651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting flaml\n",
      "  Downloading FLAML-1.0.1-py3-none-any.whl (157 kB)\n",
      "\u001b[K     |████████████████████████████████| 157 kB 1.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting lightgbm>=2.3.1\n",
      "  Downloading lightgbm-3.3.2-py3-none-manylinux1_x86_64.whl (2.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.0 MB 3.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scikit-learn>=0.24 in /home/martin/miniconda3/envs/autoML/lib/python3.8/site-packages (from flaml) (0.24.2)\n",
      "Collecting xgboost<=1.3.3,>=0.90\n",
      "  Downloading xgboost-1.3.3-py3-none-manylinux2010_x86_64.whl (157.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 157.5 MB 35 kB/s  eta 0:00:01    |████▌                           | 22.0 MB 3.4 MB/s eta 0:00:41     |██████▏                         | 30.2 MB 7.5 MB/s eta 0:00:18     |██████▉                         | 33.8 MB 4.3 MB/s eta 0:00:29     |███████████████▋                | 77.0 MB 4.2 MB/s eta 0:00:20     |█████████████████████████▎      | 124.3 MB 4.8 MB/s eta 0:00:07     |██████████████████████████▌     | 130.2 MB 5.1 MB/s eta 0:00:06\n",
      "\u001b[?25hRequirement already satisfied: NumPy>=1.16.2 in /home/martin/miniconda3/envs/autoML/lib/python3.8/site-packages (from flaml) (1.22.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /home/martin/miniconda3/envs/autoML/lib/python3.8/site-packages (from flaml) (1.8.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /home/martin/miniconda3/envs/autoML/lib/python3.8/site-packages (from flaml) (1.4.2)\n",
      "Requirement already satisfied: wheel in /home/martin/miniconda3/envs/autoML/lib/python3.8/site-packages (from lightgbm>=2.3.1->flaml) (0.37.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/martin/miniconda3/envs/autoML/lib/python3.8/site-packages (from pandas>=1.1.4->flaml) (2022.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/martin/miniconda3/envs/autoML/lib/python3.8/site-packages (from pandas>=1.1.4->flaml) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/martin/miniconda3/envs/autoML/lib/python3.8/site-packages (from python-dateutil>=2.8.1->pandas>=1.1.4->flaml) (1.16.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/martin/miniconda3/envs/autoML/lib/python3.8/site-packages (from scikit-learn>=0.24->flaml) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/martin/miniconda3/envs/autoML/lib/python3.8/site-packages (from scikit-learn>=0.24->flaml) (3.1.0)\n",
      "Installing collected packages: xgboost, lightgbm, flaml\n",
      "  Attempting uninstall: xgboost\n",
      "    Found existing installation: xgboost 1.6.0\n",
      "    Uninstalling xgboost-1.6.0:\n",
      "      Successfully uninstalled xgboost-1.6.0\n",
      "Successfully installed flaml-1.0.1 lightgbm-3.3.2 xgboost-1.3.3\n"
     ]
    }
   ],
   "source": [
    "!pip install flaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265e3da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train = pd.read_csv('../data/train.csv', sep=\",\")\n",
    "test = pd.read_csv('../data/test.csv')\n",
    "\n",
    "import sklearn\n",
    "y = train['SalePrice']\n",
    "X = train.drop('SalePrice', axis=1)\n",
    "y = np.log1p(y)\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(X, y, random_state=42, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a8e2d687",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.automl: 04-28 10:36:43] {2105} INFO - task = regression\n",
      "[flaml.automl: 04-28 10:36:43] {2107} INFO - Data split method: uniform\n",
      "[flaml.automl: 04-28 10:36:43] {2111} INFO - Evaluation method: cv\n",
      "[flaml.automl: 04-28 10:36:43] {2188} INFO - Minimizing error metric: 1-r2\n",
      "[flaml.automl: 04-28 10:36:43] {2281} INFO - List of ML learners in AutoML Run: ['lgbm', 'rf', 'extra_tree']\n",
      "[flaml.automl: 04-28 10:36:43] {2567} INFO - iteration 0, current learner lgbm\n",
      "[flaml.automl: 04-28 10:36:43] {2697} INFO - Estimated sufficient time budget=1264s. Estimated necessary time budget=1s.\n",
      "[flaml.automl: 04-28 10:36:43] {2744} INFO -  at 0.4s,\testimator lgbm's best error=0.6557,\tbest estimator lgbm's best error=0.6557\n",
      "[flaml.automl: 04-28 10:36:43] {2567} INFO - iteration 1, current learner lgbm\n",
      "/home/martin/miniconda3/envs/autoML/lib/python3.8/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.\n",
      "  warnings.warn(\"Warning: optional dependency `torch` is not available. - skipping import of NN models.\")\n",
      "[flaml.automl: 04-28 10:36:43] {2744} INFO -  at 0.8s,\testimator lgbm's best error=0.6557,\tbest estimator lgbm's best error=0.6557\n",
      "[flaml.automl: 04-28 10:36:43] {2567} INFO - iteration 2, current learner extra_tree\n",
      "[flaml.automl: 04-28 10:36:44] {2744} INFO -  at 1.1s,\testimator extra_tree's best error=0.4216,\tbest estimator extra_tree's best error=0.4216\n",
      "[flaml.automl: 04-28 10:36:44] {2567} INFO - iteration 3, current learner rf\n",
      "[flaml.automl: 04-28 10:36:44] {2744} INFO -  at 1.4s,\testimator rf's best error=0.3779,\tbest estimator rf's best error=0.3779\n",
      "[flaml.automl: 04-28 10:36:44] {2567} INFO - iteration 4, current learner extra_tree\n",
      "[flaml.automl: 04-28 10:36:44] {2744} INFO -  at 1.7s,\testimator extra_tree's best error=0.2920,\tbest estimator extra_tree's best error=0.2920\n",
      "[flaml.automl: 04-28 10:36:44] {2567} INFO - iteration 5, current learner lgbm\n",
      "[flaml.automl: 04-28 10:36:44] {2744} INFO -  at 1.8s,\testimator lgbm's best error=0.3686,\tbest estimator extra_tree's best error=0.2920\n",
      "[flaml.automl: 04-28 10:36:44] {2567} INFO - iteration 6, current learner rf\n",
      "[flaml.automl: 04-28 10:36:45] {2744} INFO -  at 2.0s,\testimator rf's best error=0.2667,\tbest estimator rf's best error=0.2667\n",
      "[flaml.automl: 04-28 10:36:45] {2567} INFO - iteration 7, current learner lgbm\n",
      "[flaml.automl: 04-28 10:36:45] {2744} INFO -  at 2.2s,\testimator lgbm's best error=0.1995,\tbest estimator lgbm's best error=0.1995\n",
      "[flaml.automl: 04-28 10:36:45] {2567} INFO - iteration 8, current learner lgbm\n",
      "[flaml.automl: 04-28 10:36:45] {2744} INFO -  at 2.3s,\testimator lgbm's best error=0.1995,\tbest estimator lgbm's best error=0.1995\n",
      "[flaml.automl: 04-28 10:36:45] {2567} INFO - iteration 9, current learner lgbm\n",
      "[flaml.automl: 04-28 10:36:45] {2744} INFO -  at 2.4s,\testimator lgbm's best error=0.1956,\tbest estimator lgbm's best error=0.1956\n",
      "[flaml.automl: 04-28 10:36:45] {2567} INFO - iteration 10, current learner lgbm\n",
      "[flaml.automl: 04-28 10:36:45] {2744} INFO -  at 2.6s,\testimator lgbm's best error=0.1956,\tbest estimator lgbm's best error=0.1956\n",
      "[flaml.automl: 04-28 10:36:45] {2567} INFO - iteration 11, current learner rf\n",
      "/home/martin/miniconda3/envs/autoML/lib/python3.8/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.\n",
      "  warnings.warn(\"Warning: optional dependency `torch` is not available. - skipping import of NN models.\")\n",
      "[flaml.automl: 04-28 10:36:45] {2744} INFO -  at 2.8s,\testimator rf's best error=0.2667,\tbest estimator lgbm's best error=0.1956\n",
      "[flaml.automl: 04-28 10:36:45] {2567} INFO - iteration 12, current learner rf\n",
      "[flaml.automl: 04-28 10:36:46] {2744} INFO -  at 3.1s,\testimator rf's best error=0.2137,\tbest estimator lgbm's best error=0.1956\n",
      "[flaml.automl: 04-28 10:36:46] {2567} INFO - iteration 13, current learner lgbm\n",
      "[flaml.automl: 04-28 10:36:46] {2744} INFO -  at 3.3s,\testimator lgbm's best error=0.1956,\tbest estimator lgbm's best error=0.1956\n",
      "[flaml.automl: 04-28 10:36:46] {2567} INFO - iteration 14, current learner extra_tree\n",
      "[flaml.automl: 04-28 10:36:46] {2744} INFO -  at 3.5s,\testimator extra_tree's best error=0.2920,\tbest estimator lgbm's best error=0.1956\n",
      "[flaml.automl: 04-28 10:36:46] {2567} INFO - iteration 15, current learner lgbm\n",
      "[flaml.automl: 04-28 10:36:46] {2744} INFO -  at 3.6s,\testimator lgbm's best error=0.1525,\tbest estimator lgbm's best error=0.1525\n",
      "[flaml.automl: 04-28 10:36:46] {2567} INFO - iteration 16, current learner extra_tree\n",
      "[flaml.automl: 04-28 10:36:46] {2744} INFO -  at 3.9s,\testimator extra_tree's best error=0.2337,\tbest estimator lgbm's best error=0.1525\n",
      "[flaml.automl: 04-28 10:36:46] {2567} INFO - iteration 17, current learner lgbm\n",
      "[flaml.automl: 04-28 10:36:47] {2744} INFO -  at 4.0s,\testimator lgbm's best error=0.1525,\tbest estimator lgbm's best error=0.1525\n",
      "[flaml.automl: 04-28 10:36:47] {2567} INFO - iteration 18, current learner rf\n",
      "[flaml.automl: 04-28 10:36:47] {2744} INFO -  at 4.3s,\testimator rf's best error=0.1805,\tbest estimator lgbm's best error=0.1525\n",
      "[flaml.automl: 04-28 10:36:47] {2567} INFO - iteration 19, current learner rf\n",
      "[flaml.automl: 04-28 10:36:47] {2744} INFO -  at 4.6s,\testimator rf's best error=0.1805,\tbest estimator lgbm's best error=0.1525\n",
      "[flaml.automl: 04-28 10:36:47] {2567} INFO - iteration 20, current learner rf\n",
      "[flaml.automl: 04-28 10:36:47] {2744} INFO -  at 4.8s,\testimator rf's best error=0.1723,\tbest estimator lgbm's best error=0.1525\n",
      "[flaml.automl: 04-28 10:36:47] {2567} INFO - iteration 21, current learner lgbm\n",
      "[flaml.automl: 04-28 10:36:48] {2744} INFO -  at 5.1s,\testimator lgbm's best error=0.1178,\tbest estimator lgbm's best error=0.1178\n",
      "[flaml.automl: 04-28 10:36:48] {2567} INFO - iteration 22, current learner lgbm\n",
      "[flaml.automl: 04-28 10:36:48] {2744} INFO -  at 5.5s,\testimator lgbm's best error=0.1178,\tbest estimator lgbm's best error=0.1178\n",
      "[flaml.automl: 04-28 10:36:48] {2567} INFO - iteration 23, current learner rf\n",
      "/home/martin/miniconda3/envs/autoML/lib/python3.8/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.\n",
      "  warnings.warn(\"Warning: optional dependency `torch` is not available. - skipping import of NN models.\")\n",
      "[flaml.automl: 04-28 10:36:48] {2744} INFO -  at 5.7s,\testimator rf's best error=0.1723,\tbest estimator lgbm's best error=0.1178\n",
      "[flaml.automl: 04-28 10:36:48] {2567} INFO - iteration 24, current learner extra_tree\n",
      "[flaml.automl: 04-28 10:36:49] {2744} INFO -  at 6.0s,\testimator extra_tree's best error=0.1895,\tbest estimator lgbm's best error=0.1178\n",
      "[flaml.automl: 04-28 10:36:49] {2567} INFO - iteration 25, current learner lgbm\n",
      "[flaml.automl: 04-28 10:36:49] {2744} INFO -  at 6.4s,\testimator lgbm's best error=0.1178,\tbest estimator lgbm's best error=0.1178\n",
      "[flaml.automl: 04-28 10:36:49] {2567} INFO - iteration 26, current learner extra_tree\n",
      "[flaml.automl: 04-28 10:36:49] {2744} INFO -  at 6.6s,\testimator extra_tree's best error=0.1895,\tbest estimator lgbm's best error=0.1178\n",
      "[flaml.automl: 04-28 10:36:49] {2567} INFO - iteration 27, current learner extra_tree\n",
      "[flaml.automl: 04-28 10:36:49] {2744} INFO -  at 6.9s,\testimator extra_tree's best error=0.1889,\tbest estimator lgbm's best error=0.1178\n",
      "[flaml.automl: 04-28 10:36:49] {2567} INFO - iteration 28, current learner lgbm\n",
      "[flaml.automl: 04-28 10:36:50] {2744} INFO -  at 7.2s,\testimator lgbm's best error=0.1178,\tbest estimator lgbm's best error=0.1178\n",
      "[flaml.automl: 04-28 10:36:50] {2567} INFO - iteration 29, current learner lgbm\n",
      "[flaml.automl: 04-28 10:36:50] {2744} INFO -  at 7.7s,\testimator lgbm's best error=0.1178,\tbest estimator lgbm's best error=0.1178\n",
      "[flaml.automl: 04-28 10:36:50] {2567} INFO - iteration 30, current learner lgbm\n",
      "[flaml.automl: 04-28 10:36:51] {2744} INFO -  at 8.2s,\testimator lgbm's best error=0.1178,\tbest estimator lgbm's best error=0.1178\n",
      "[flaml.automl: 04-28 10:36:51] {2567} INFO - iteration 31, current learner lgbm\n",
      "[flaml.automl: 04-28 10:36:51] {2744} INFO -  at 8.5s,\testimator lgbm's best error=0.1178,\tbest estimator lgbm's best error=0.1178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.automl: 04-28 10:36:51] {2567} INFO - iteration 32, current learner rf\n",
      "[flaml.automl: 04-28 10:36:52] {2744} INFO -  at 9.1s,\testimator rf's best error=0.1484,\tbest estimator lgbm's best error=0.1178\n",
      "[flaml.automl: 04-28 10:36:52] {2567} INFO - iteration 33, current learner lgbm\n",
      "[flaml.automl: 04-28 10:36:52] {2744} INFO -  at 9.6s,\testimator lgbm's best error=0.1178,\tbest estimator lgbm's best error=0.1178\n",
      "[flaml.automl: 04-28 10:36:52] {2567} INFO - iteration 34, current learner lgbm\n",
      "[flaml.automl: 04-28 10:36:52] {2744} INFO -  at 9.9s,\testimator lgbm's best error=0.1178,\tbest estimator lgbm's best error=0.1178\n",
      "[flaml.automl: 04-28 10:36:52] {2567} INFO - iteration 35, current learner rf\n",
      "[flaml.automl: 04-28 10:36:53] {2744} INFO -  at 10.4s,\testimator rf's best error=0.1484,\tbest estimator lgbm's best error=0.1178\n",
      "[flaml.automl: 04-28 10:36:53] {2567} INFO - iteration 36, current learner rf\n",
      "[flaml.automl: 04-28 10:36:53] {2744} INFO -  at 10.7s,\testimator rf's best error=0.1484,\tbest estimator lgbm's best error=0.1178\n",
      "[flaml.automl: 04-28 10:36:53] {2567} INFO - iteration 37, current learner rf\n",
      "[flaml.automl: 04-28 10:36:54] {2744} INFO -  at 11.5s,\testimator rf's best error=0.1444,\tbest estimator lgbm's best error=0.1178\n",
      "[flaml.automl: 04-28 10:36:54] {2567} INFO - iteration 38, current learner lgbm\n",
      "[flaml.automl: 04-28 10:36:54] {2744} INFO -  at 11.7s,\testimator lgbm's best error=0.1178,\tbest estimator lgbm's best error=0.1178\n",
      "[flaml.automl: 04-28 10:36:54] {2567} INFO - iteration 39, current learner lgbm\n",
      "[flaml.automl: 04-28 10:36:55] {2744} INFO -  at 12.2s,\testimator lgbm's best error=0.1178,\tbest estimator lgbm's best error=0.1178\n",
      "[flaml.automl: 04-28 10:36:55] {2567} INFO - iteration 40, current learner rf\n",
      "[flaml.automl: 04-28 10:36:55] {2744} INFO -  at 12.6s,\testimator rf's best error=0.1444,\tbest estimator lgbm's best error=0.1178\n",
      "[flaml.automl: 04-28 10:36:55] {2567} INFO - iteration 41, current learner lgbm\n",
      "[flaml.automl: 04-28 10:36:55] {2744} INFO -  at 12.9s,\testimator lgbm's best error=0.1114,\tbest estimator lgbm's best error=0.1114\n",
      "[flaml.automl: 04-28 10:36:55] {2567} INFO - iteration 42, current learner lgbm\n",
      "[flaml.automl: 04-28 10:36:56] {2744} INFO -  at 13.2s,\testimator lgbm's best error=0.1114,\tbest estimator lgbm's best error=0.1114\n",
      "[flaml.automl: 04-28 10:36:56] {2567} INFO - iteration 43, current learner extra_tree\n",
      "[flaml.automl: 04-28 10:36:56] {2744} INFO -  at 13.5s,\testimator extra_tree's best error=0.1889,\tbest estimator lgbm's best error=0.1114\n",
      "[flaml.automl: 04-28 10:36:56] {2567} INFO - iteration 44, current learner lgbm\n",
      "[flaml.automl: 04-28 10:36:56] {2744} INFO -  at 13.8s,\testimator lgbm's best error=0.1114,\tbest estimator lgbm's best error=0.1114\n",
      "[flaml.automl: 04-28 10:36:56] {2567} INFO - iteration 45, current learner lgbm\n",
      "[flaml.automl: 04-28 10:36:57] {2744} INFO -  at 14.2s,\testimator lgbm's best error=0.1114,\tbest estimator lgbm's best error=0.1114\n",
      "[flaml.automl: 04-28 10:36:57] {2567} INFO - iteration 46, current learner lgbm\n",
      "[flaml.automl: 04-28 10:36:57] {2744} INFO -  at 14.7s,\testimator lgbm's best error=0.1114,\tbest estimator lgbm's best error=0.1114\n",
      "[flaml.automl: 04-28 10:36:57] {2567} INFO - iteration 47, current learner lgbm\n",
      "[flaml.automl: 04-28 10:36:58] {2744} INFO -  at 15.0s,\testimator lgbm's best error=0.1114,\tbest estimator lgbm's best error=0.1114\n",
      "[flaml.automl: 04-28 10:36:58] {2567} INFO - iteration 48, current learner lgbm\n",
      "[flaml.automl: 04-28 10:36:58] {2744} INFO -  at 15.6s,\testimator lgbm's best error=0.1114,\tbest estimator lgbm's best error=0.1114\n",
      "[flaml.automl: 04-28 10:36:58] {2567} INFO - iteration 49, current learner rf\n",
      "/home/martin/miniconda3/envs/autoML/lib/python3.8/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.\n",
      "  warnings.warn(\"Warning: optional dependency `torch` is not available. - skipping import of NN models.\")\n",
      "[flaml.automl: 04-28 10:37:00] {2744} INFO -  at 17.6s,\testimator rf's best error=0.1383,\tbest estimator lgbm's best error=0.1114\n",
      "[flaml.automl: 04-28 10:37:00] {2567} INFO - iteration 50, current learner lgbm\n",
      "[flaml.automl: 04-28 10:37:00] {2744} INFO -  at 17.8s,\testimator lgbm's best error=0.1114,\tbest estimator lgbm's best error=0.1114\n",
      "[flaml.automl: 04-28 10:37:00] {2567} INFO - iteration 51, current learner lgbm\n",
      "[flaml.automl: 04-28 10:37:01] {2744} INFO -  at 18.1s,\testimator lgbm's best error=0.1114,\tbest estimator lgbm's best error=0.1114\n",
      "[flaml.automl: 04-28 10:37:01] {2567} INFO - iteration 52, current learner lgbm\n",
      "[flaml.automl: 04-28 10:37:01] {2744} INFO -  at 18.6s,\testimator lgbm's best error=0.1114,\tbest estimator lgbm's best error=0.1114\n",
      "[flaml.automl: 04-28 10:37:01] {2567} INFO - iteration 53, current learner lgbm\n",
      "[flaml.automl: 04-28 10:37:01] {2744} INFO -  at 18.9s,\testimator lgbm's best error=0.1114,\tbest estimator lgbm's best error=0.1114\n",
      "[flaml.automl: 04-28 10:37:01] {2567} INFO - iteration 54, current learner lgbm\n",
      "[flaml.automl: 04-28 10:37:02] {2744} INFO -  at 19.2s,\testimator lgbm's best error=0.1114,\tbest estimator lgbm's best error=0.1114\n",
      "[flaml.automl: 04-28 10:37:02] {2567} INFO - iteration 55, current learner lgbm\n",
      "[flaml.automl: 04-28 10:37:02] {2744} INFO -  at 19.5s,\testimator lgbm's best error=0.1114,\tbest estimator lgbm's best error=0.1114\n",
      "[flaml.automl: 04-28 10:37:02] {2567} INFO - iteration 56, current learner lgbm\n",
      "[flaml.automl: 04-28 10:37:02] {2744} INFO -  at 19.9s,\testimator lgbm's best error=0.1114,\tbest estimator lgbm's best error=0.1114\n",
      "[flaml.automl: 04-28 10:37:02] {2567} INFO - iteration 57, current learner lgbm\n",
      "[flaml.automl: 04-28 10:37:03] {2744} INFO -  at 20.6s,\testimator lgbm's best error=0.1114,\tbest estimator lgbm's best error=0.1114\n",
      "[flaml.automl: 04-28 10:37:03] {2567} INFO - iteration 58, current learner lgbm\n",
      "[flaml.automl: 04-28 10:37:03] {2744} INFO -  at 20.8s,\testimator lgbm's best error=0.1114,\tbest estimator lgbm's best error=0.1114\n",
      "[flaml.automl: 04-28 10:37:03] {2567} INFO - iteration 59, current learner lgbm\n",
      "[flaml.automl: 04-28 10:37:04] {2744} INFO -  at 21.2s,\testimator lgbm's best error=0.1114,\tbest estimator lgbm's best error=0.1114\n",
      "[flaml.automl: 04-28 10:37:04] {2567} INFO - iteration 60, current learner lgbm\n",
      "[flaml.automl: 04-28 10:37:04] {2744} INFO -  at 21.4s,\testimator lgbm's best error=0.1114,\tbest estimator lgbm's best error=0.1114\n",
      "[flaml.automl: 04-28 10:37:04] {2567} INFO - iteration 61, current learner lgbm\n",
      "[flaml.automl: 04-28 10:37:05] {2744} INFO -  at 22.2s,\testimator lgbm's best error=0.1114,\tbest estimator lgbm's best error=0.1114\n",
      "[flaml.automl: 04-28 10:37:05] {2567} INFO - iteration 62, current learner lgbm\n",
      "[flaml.automl: 04-28 10:37:05] {2744} INFO -  at 22.4s,\testimator lgbm's best error=0.1114,\tbest estimator lgbm's best error=0.1114\n",
      "[flaml.automl: 04-28 10:37:05] {2567} INFO - iteration 63, current learner lgbm\n",
      "[flaml.automl: 04-28 10:37:05] {2744} INFO -  at 22.6s,\testimator lgbm's best error=0.1114,\tbest estimator lgbm's best error=0.1114\n",
      "[flaml.automl: 04-28 10:37:05] {2567} INFO - iteration 64, current learner lgbm\n",
      "[flaml.automl: 04-28 10:37:06] {2744} INFO -  at 23.3s,\testimator lgbm's best error=0.1106,\tbest estimator lgbm's best error=0.1106\n",
      "[flaml.automl: 04-28 10:37:06] {2567} INFO - iteration 65, current learner lgbm\n",
      "[flaml.automl: 04-28 10:37:07] {2744} INFO -  at 24.4s,\testimator lgbm's best error=0.1071,\tbest estimator lgbm's best error=0.1071\n",
      "[flaml.automl: 04-28 10:37:07] {2567} INFO - iteration 66, current learner lgbm\n",
      "[flaml.automl: 04-28 10:37:08] {2744} INFO -  at 25.0s,\testimator lgbm's best error=0.1071,\tbest estimator lgbm's best error=0.1071\n",
      "[flaml.automl: 04-28 10:37:08] {2567} INFO - iteration 67, current learner lgbm\n",
      "[flaml.automl: 04-28 10:37:08] {2744} INFO -  at 25.5s,\testimator lgbm's best error=0.1071,\tbest estimator lgbm's best error=0.1071\n",
      "[flaml.automl: 04-28 10:37:08] {2567} INFO - iteration 68, current learner lgbm\n",
      "[flaml.automl: 04-28 10:37:11] {2744} INFO -  at 28.8s,\testimator lgbm's best error=0.1071,\tbest estimator lgbm's best error=0.1071\n",
      "[flaml.automl: 04-28 10:37:11] {2567} INFO - iteration 69, current learner lgbm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.automl: 04-28 10:37:12] {2744} INFO -  at 29.3s,\testimator lgbm's best error=0.1071,\tbest estimator lgbm's best error=0.1071\n",
      "[flaml.automl: 04-28 10:37:12] {2567} INFO - iteration 70, current learner lgbm\n",
      "[flaml.automl: 04-28 10:37:16] {2744} INFO -  at 33.2s,\testimator lgbm's best error=0.1071,\tbest estimator lgbm's best error=0.1071\n",
      "[flaml.automl: 04-28 10:37:16] {2567} INFO - iteration 71, current learner rf\n",
      "[flaml.automl: 04-28 10:37:17] {2744} INFO -  at 34.0s,\testimator rf's best error=0.1383,\tbest estimator lgbm's best error=0.1071\n",
      "[flaml.automl: 04-28 10:37:17] {2567} INFO - iteration 72, current learner lgbm\n",
      "[flaml.automl: 04-28 10:37:17] {2744} INFO -  at 34.3s,\testimator lgbm's best error=0.1071,\tbest estimator lgbm's best error=0.1071\n",
      "[flaml.automl: 04-28 10:37:17] {2567} INFO - iteration 73, current learner rf\n",
      "[flaml.automl: 04-28 10:37:19] {2744} INFO -  at 36.7s,\testimator rf's best error=0.1325,\tbest estimator lgbm's best error=0.1071\n",
      "[flaml.automl: 04-28 10:37:19] {2567} INFO - iteration 74, current learner lgbm\n",
      "[flaml.automl: 04-28 10:37:24] {2744} INFO -  at 41.8s,\testimator lgbm's best error=0.1071,\tbest estimator lgbm's best error=0.1071\n",
      "[flaml.automl: 04-28 10:37:24] {2567} INFO - iteration 75, current learner lgbm\n",
      "[flaml.automl: 04-28 10:37:27] {2744} INFO -  at 44.8s,\testimator lgbm's best error=0.1035,\tbest estimator lgbm's best error=0.1035\n",
      "[flaml.automl: 04-28 10:37:27] {2567} INFO - iteration 76, current learner rf\n",
      "[flaml.automl: 04-28 10:37:29] {2744} INFO -  at 46.0s,\testimator rf's best error=0.1325,\tbest estimator lgbm's best error=0.1035\n",
      "[flaml.automl: 04-28 10:37:29] {2567} INFO - iteration 77, current learner lgbm\n",
      "[flaml.automl: 04-28 10:37:30] {2744} INFO -  at 47.1s,\testimator lgbm's best error=0.1035,\tbest estimator lgbm's best error=0.1035\n",
      "[flaml.automl: 04-28 10:37:30] {2567} INFO - iteration 78, current learner lgbm\n",
      "[flaml.automl: 04-28 10:37:34] {2744} INFO -  at 51.1s,\testimator lgbm's best error=0.1035,\tbest estimator lgbm's best error=0.1035\n",
      "[flaml.automl: 04-28 10:37:34] {2567} INFO - iteration 79, current learner rf\n",
      "[flaml.automl: 04-28 10:37:39] {2744} INFO -  at 56.5s,\testimator rf's best error=0.1325,\tbest estimator lgbm's best error=0.1035\n",
      "[flaml.automl: 04-28 10:37:39] {2567} INFO - iteration 80, current learner lgbm\n",
      "[flaml.automl: 04-28 10:37:40] {2744} INFO -  at 57.6s,\testimator lgbm's best error=0.1034,\tbest estimator lgbm's best error=0.1034\n",
      "[flaml.automl: 04-28 10:37:40] {2567} INFO - iteration 81, current learner lgbm\n",
      "[flaml.automl: 04-28 10:37:42] {2744} INFO -  at 59.3s,\testimator lgbm's best error=0.1008,\tbest estimator lgbm's best error=0.1008\n",
      "[flaml.automl: 04-28 10:37:42] {2567} INFO - iteration 82, current learner lgbm\n",
      "[flaml.automl: 04-28 10:37:43] {2744} INFO -  at 60.8s,\testimator lgbm's best error=0.1008,\tbest estimator lgbm's best error=0.1008\n",
      "[flaml.automl: 04-28 10:37:43] {2567} INFO - iteration 83, current learner lgbm\n",
      "[flaml.automl: 04-28 10:37:45] {2744} INFO -  at 62.3s,\testimator lgbm's best error=0.1008,\tbest estimator lgbm's best error=0.1008\n",
      "[flaml.automl: 04-28 10:37:45] {2567} INFO - iteration 84, current learner lgbm\n",
      "[flaml.automl: 04-28 10:37:47] {2744} INFO -  at 64.0s,\testimator lgbm's best error=0.1008,\tbest estimator lgbm's best error=0.1008\n",
      "[flaml.automl: 04-28 10:37:47] {2567} INFO - iteration 85, current learner lgbm\n",
      "[flaml.automl: 04-28 10:37:48] {2744} INFO -  at 65.1s,\testimator lgbm's best error=0.1008,\tbest estimator lgbm's best error=0.1008\n",
      "[flaml.automl: 04-28 10:37:48] {2567} INFO - iteration 86, current learner lgbm\n",
      "[flaml.automl: 04-28 10:37:50] {2744} INFO -  at 67.9s,\testimator lgbm's best error=0.1008,\tbest estimator lgbm's best error=0.1008\n",
      "[flaml.automl: 04-28 10:37:50] {2567} INFO - iteration 87, current learner lgbm\n",
      "[flaml.automl: 04-28 10:37:54] {2744} INFO -  at 71.4s,\testimator lgbm's best error=0.1008,\tbest estimator lgbm's best error=0.1008\n",
      "[flaml.automl: 04-28 10:37:54] {2567} INFO - iteration 88, current learner rf\n",
      "[flaml.automl: 04-28 10:37:59] {2744} INFO -  at 76.5s,\testimator rf's best error=0.1325,\tbest estimator lgbm's best error=0.1008\n",
      "[flaml.automl: 04-28 10:37:59] {2567} INFO - iteration 89, current learner lgbm\n",
      "[flaml.automl: 04-28 10:38:00] {2744} INFO -  at 77.4s,\testimator lgbm's best error=0.1008,\tbest estimator lgbm's best error=0.1008\n",
      "[flaml.automl: 04-28 10:38:00] {2567} INFO - iteration 90, current learner extra_tree\n",
      "[flaml.automl: 04-28 10:38:00] {2744} INFO -  at 77.8s,\testimator extra_tree's best error=0.1691,\tbest estimator lgbm's best error=0.1008\n",
      "[flaml.automl: 04-28 10:38:00] {2567} INFO - iteration 91, current learner extra_tree\n",
      "[flaml.automl: 04-28 10:38:01] {2744} INFO -  at 78.1s,\testimator extra_tree's best error=0.1691,\tbest estimator lgbm's best error=0.1008\n",
      "[flaml.automl: 04-28 10:38:01] {2567} INFO - iteration 92, current learner extra_tree\n",
      "[flaml.automl: 04-28 10:38:01] {2744} INFO -  at 78.5s,\testimator extra_tree's best error=0.1691,\tbest estimator lgbm's best error=0.1008\n",
      "[flaml.automl: 04-28 10:38:01] {2567} INFO - iteration 93, current learner lgbm\n",
      "[flaml.automl: 04-28 10:38:03] {2744} INFO -  at 80.6s,\testimator lgbm's best error=0.1008,\tbest estimator lgbm's best error=0.1008\n",
      "[flaml.automl: 04-28 10:38:03] {2567} INFO - iteration 94, current learner extra_tree\n",
      "[flaml.automl: 04-28 10:38:04] {2744} INFO -  at 81.3s,\testimator extra_tree's best error=0.1613,\tbest estimator lgbm's best error=0.1008\n",
      "[flaml.automl: 04-28 10:38:04] {2567} INFO - iteration 95, current learner lgbm\n",
      "[flaml.automl: 04-28 10:38:05] {2744} INFO -  at 82.9s,\testimator lgbm's best error=0.1008,\tbest estimator lgbm's best error=0.1008\n",
      "[flaml.automl: 04-28 10:38:05] {2567} INFO - iteration 96, current learner extra_tree\n",
      "[flaml.automl: 04-28 10:38:06] {2744} INFO -  at 83.2s,\testimator extra_tree's best error=0.1613,\tbest estimator lgbm's best error=0.1008\n",
      "[flaml.automl: 04-28 10:38:06] {2567} INFO - iteration 97, current learner lgbm\n",
      "[flaml.automl: 04-28 10:38:08] {2744} INFO -  at 85.9s,\testimator lgbm's best error=0.1008,\tbest estimator lgbm's best error=0.1008\n",
      "[flaml.automl: 04-28 10:38:08] {2567} INFO - iteration 98, current learner lgbm\n",
      "[flaml.automl: 04-28 10:38:10] {2744} INFO -  at 87.5s,\testimator lgbm's best error=0.1008,\tbest estimator lgbm's best error=0.1008\n",
      "[flaml.automl: 04-28 10:38:10] {2567} INFO - iteration 99, current learner extra_tree\n",
      "[flaml.automl: 04-28 10:38:11] {2744} INFO -  at 88.8s,\testimator extra_tree's best error=0.1497,\tbest estimator lgbm's best error=0.1008\n",
      "[flaml.automl: 04-28 10:38:11] {2567} INFO - iteration 100, current learner extra_tree\n",
      "[flaml.automl: 04-28 10:38:12] {2744} INFO -  at 89.5s,\testimator extra_tree's best error=0.1497,\tbest estimator lgbm's best error=0.1008\n",
      "[flaml.automl: 04-28 10:38:12] {2567} INFO - iteration 101, current learner lgbm\n",
      "[flaml.automl: 04-28 10:38:14] {2744} INFO -  at 91.3s,\testimator lgbm's best error=0.1008,\tbest estimator lgbm's best error=0.1008\n",
      "[flaml.automl: 04-28 10:38:14] {2567} INFO - iteration 102, current learner extra_tree\n",
      "[flaml.automl: 04-28 10:38:16] {2744} INFO -  at 93.5s,\testimator extra_tree's best error=0.1433,\tbest estimator lgbm's best error=0.1008\n",
      "[flaml.automl: 04-28 10:38:16] {2567} INFO - iteration 103, current learner lgbm\n",
      "[flaml.automl: 04-28 10:38:18] {2744} INFO -  at 95.6s,\testimator lgbm's best error=0.1008,\tbest estimator lgbm's best error=0.1008\n",
      "[flaml.automl: 04-28 10:38:18] {2567} INFO - iteration 104, current learner lgbm\n",
      "[flaml.automl: 04-28 10:38:21] {2744} INFO -  at 98.0s,\testimator lgbm's best error=0.1008,\tbest estimator lgbm's best error=0.1008\n",
      "[flaml.automl: 04-28 10:38:21] {2567} INFO - iteration 105, current learner extra_tree\n",
      "[flaml.automl: 04-28 10:38:22] {2744} INFO -  at 99.2s,\testimator extra_tree's best error=0.1433,\tbest estimator lgbm's best error=0.1008\n",
      "[flaml.automl: 04-28 10:38:22] {2567} INFO - iteration 106, current learner lgbm\n",
      "[flaml.automl: 04-28 10:38:22] {2744} INFO -  at 99.7s,\testimator lgbm's best error=0.1008,\tbest estimator lgbm's best error=0.1008\n",
      "[flaml.automl: 04-28 10:38:22] {2567} INFO - iteration 107, current learner extra_tree\n",
      "[flaml.automl: 04-28 10:38:27] {2744} INFO -  at 104.2s,\testimator extra_tree's best error=0.1433,\tbest estimator lgbm's best error=0.1008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.automl: 04-28 10:38:27] {2567} INFO - iteration 108, current learner lgbm\n",
      "[flaml.automl: 04-28 10:38:29] {2744} INFO -  at 106.3s,\testimator lgbm's best error=0.1008,\tbest estimator lgbm's best error=0.1008\n",
      "[flaml.automl: 04-28 10:38:29] {2567} INFO - iteration 109, current learner lgbm\n",
      "[flaml.automl: 04-28 10:38:30] {2744} INFO -  at 107.7s,\testimator lgbm's best error=0.1008,\tbest estimator lgbm's best error=0.1008\n",
      "[flaml.automl: 04-28 10:38:30] {2567} INFO - iteration 110, current learner extra_tree\n",
      "[flaml.automl: 04-28 10:38:35] {2744} INFO -  at 111.9s,\testimator extra_tree's best error=0.1411,\tbest estimator lgbm's best error=0.1008\n",
      "[flaml.automl: 04-28 10:38:35] {2567} INFO - iteration 111, current learner lgbm\n",
      "[flaml.automl: 04-28 10:38:35] {2744} INFO -  at 112.7s,\testimator lgbm's best error=0.1008,\tbest estimator lgbm's best error=0.1008\n",
      "[flaml.automl: 04-28 10:38:35] {2567} INFO - iteration 112, current learner extra_tree\n",
      "[flaml.automl: 04-28 10:38:43] {2744} INFO -  at 120.7s,\testimator extra_tree's best error=0.1411,\tbest estimator lgbm's best error=0.1008\n",
      "[flaml.automl: 04-28 10:38:43] {2567} INFO - iteration 113, current learner lgbm\n",
      "[flaml.automl: 04-28 10:38:47] {2744} INFO -  at 124.0s,\testimator lgbm's best error=0.1008,\tbest estimator lgbm's best error=0.1008\n",
      "[flaml.automl: 04-28 10:38:47] {2567} INFO - iteration 114, current learner lgbm\n",
      "[flaml.automl: 04-28 10:38:49] {2744} INFO -  at 126.6s,\testimator lgbm's best error=0.1008,\tbest estimator lgbm's best error=0.1008\n",
      "[flaml.automl: 04-28 10:38:49] {2567} INFO - iteration 115, current learner rf\n",
      "[flaml.automl: 04-28 10:38:50] {2744} INFO -  at 127.9s,\testimator rf's best error=0.1325,\tbest estimator lgbm's best error=0.1008\n",
      "[flaml.automl: 04-28 10:38:50] {2567} INFO - iteration 116, current learner lgbm\n",
      "[flaml.automl: 04-28 10:38:51] {2744} INFO -  at 128.6s,\testimator lgbm's best error=0.1008,\tbest estimator lgbm's best error=0.1008\n",
      "[flaml.automl: 04-28 10:38:51] {2567} INFO - iteration 117, current learner lgbm\n",
      "[flaml.automl: 04-28 10:38:52] {2744} INFO -  at 129.4s,\testimator lgbm's best error=0.1008,\tbest estimator lgbm's best error=0.1008\n",
      "[flaml.automl: 04-28 10:38:52] {2567} INFO - iteration 118, current learner lgbm\n",
      "[flaml.automl: 04-28 10:38:55] {2744} INFO -  at 132.0s,\testimator lgbm's best error=0.1004,\tbest estimator lgbm's best error=0.1004\n",
      "[flaml.automl: 04-28 10:38:55] {2567} INFO - iteration 119, current learner lgbm\n",
      "[flaml.automl: 04-28 10:38:57] {2744} INFO -  at 134.5s,\testimator lgbm's best error=0.1004,\tbest estimator lgbm's best error=0.1004\n",
      "[flaml.automl: 04-28 10:38:57] {2567} INFO - iteration 120, current learner rf\n",
      "[flaml.automl: 04-28 10:39:02] {2744} INFO -  at 139.0s,\testimator rf's best error=0.1325,\tbest estimator lgbm's best error=0.1004\n",
      "[flaml.automl: 04-28 10:39:02] {2567} INFO - iteration 121, current learner lgbm\n",
      "[flaml.automl: 04-28 10:39:03] {2744} INFO -  at 140.7s,\testimator lgbm's best error=0.1004,\tbest estimator lgbm's best error=0.1004\n",
      "[flaml.automl: 04-28 10:39:03] {2567} INFO - iteration 122, current learner lgbm\n",
      "[flaml.automl: 04-28 10:39:06] {2744} INFO -  at 143.6s,\testimator lgbm's best error=0.1004,\tbest estimator lgbm's best error=0.1004\n",
      "[flaml.automl: 04-28 10:39:06] {2567} INFO - iteration 123, current learner lgbm\n",
      "[flaml.automl: 04-28 10:39:07] {2744} INFO -  at 144.6s,\testimator lgbm's best error=0.1004,\tbest estimator lgbm's best error=0.1004\n",
      "[flaml.automl: 04-28 10:39:07] {2567} INFO - iteration 124, current learner lgbm\n",
      "[flaml.automl: 04-28 10:39:10] {2744} INFO -  at 147.1s,\testimator lgbm's best error=0.1004,\tbest estimator lgbm's best error=0.1004\n",
      "[flaml.automl: 04-28 10:39:10] {2567} INFO - iteration 125, current learner lgbm\n",
      "[flaml.automl: 04-28 10:39:12] {2744} INFO -  at 149.6s,\testimator lgbm's best error=0.1004,\tbest estimator lgbm's best error=0.1004\n",
      "[flaml.automl: 04-28 10:39:12] {2567} INFO - iteration 126, current learner lgbm\n",
      "[flaml.automl: 04-28 10:39:14] {2744} INFO -  at 151.1s,\testimator lgbm's best error=0.1004,\tbest estimator lgbm's best error=0.1004\n",
      "[flaml.automl: 04-28 10:39:14] {2567} INFO - iteration 127, current learner rf\n",
      "[flaml.automl: 04-28 10:39:15] {2744} INFO -  at 152.3s,\testimator rf's best error=0.1325,\tbest estimator lgbm's best error=0.1004\n",
      "[flaml.automl: 04-28 10:39:15] {2567} INFO - iteration 128, current learner lgbm\n",
      "[flaml.automl: 04-28 10:39:18] {2744} INFO -  at 155.7s,\testimator lgbm's best error=0.1004,\tbest estimator lgbm's best error=0.1004\n",
      "[flaml.automl: 04-28 10:39:18] {2567} INFO - iteration 129, current learner lgbm\n",
      "[flaml.automl: 04-28 10:39:21] {2744} INFO -  at 158.6s,\testimator lgbm's best error=0.1004,\tbest estimator lgbm's best error=0.1004\n",
      "[flaml.automl: 04-28 10:39:21] {2567} INFO - iteration 130, current learner rf\n",
      "[flaml.automl: 04-28 10:39:22] {2744} INFO -  at 159.9s,\testimator rf's best error=0.1325,\tbest estimator lgbm's best error=0.1004\n",
      "[flaml.automl: 04-28 10:39:22] {2567} INFO - iteration 131, current learner lgbm\n",
      "[flaml.automl: 04-28 10:39:25] {2744} INFO -  at 162.5s,\testimator lgbm's best error=0.1004,\tbest estimator lgbm's best error=0.1004\n",
      "[flaml.automl: 04-28 10:39:25] {2567} INFO - iteration 132, current learner lgbm\n",
      "[flaml.automl: 04-28 10:39:28] {2744} INFO -  at 165.2s,\testimator lgbm's best error=0.0989,\tbest estimator lgbm's best error=0.0989\n",
      "[flaml.automl: 04-28 10:39:28] {2567} INFO - iteration 133, current learner lgbm\n",
      "[flaml.automl: 04-28 10:39:30] {2744} INFO -  at 167.8s,\testimator lgbm's best error=0.0989,\tbest estimator lgbm's best error=0.0989\n",
      "[flaml.automl: 04-28 10:39:30] {2567} INFO - iteration 134, current learner extra_tree\n",
      "[flaml.automl: 04-28 10:39:33] {2744} INFO -  at 169.9s,\testimator extra_tree's best error=0.1411,\tbest estimator lgbm's best error=0.0989\n",
      "[flaml.automl: 04-28 10:39:33] {2567} INFO - iteration 135, current learner lgbm\n",
      "[flaml.automl: 04-28 10:39:34] {2744} INFO -  at 171.6s,\testimator lgbm's best error=0.0989,\tbest estimator lgbm's best error=0.0989\n",
      "[flaml.automl: 04-28 10:39:34] {2567} INFO - iteration 136, current learner lgbm\n",
      "[flaml.automl: 04-28 10:39:37] {2744} INFO -  at 174.0s,\testimator lgbm's best error=0.0989,\tbest estimator lgbm's best error=0.0989\n",
      "[flaml.automl: 04-28 10:39:37] {2567} INFO - iteration 137, current learner lgbm\n",
      "[flaml.automl: 04-28 10:39:38] {2744} INFO -  at 175.0s,\testimator lgbm's best error=0.0989,\tbest estimator lgbm's best error=0.0989\n",
      "[flaml.automl: 04-28 10:39:38] {2567} INFO - iteration 138, current learner lgbm\n",
      "[flaml.automl: 04-28 10:39:40] {2744} INFO -  at 177.5s,\testimator lgbm's best error=0.0989,\tbest estimator lgbm's best error=0.0989\n",
      "[flaml.automl: 04-28 10:39:40] {2567} INFO - iteration 139, current learner lgbm\n",
      "[flaml.automl: 04-28 10:39:43] {2744} INFO -  at 180.5s,\testimator lgbm's best error=0.0989,\tbest estimator lgbm's best error=0.0989\n",
      "[flaml.automl: 04-28 10:39:43] {2567} INFO - iteration 140, current learner lgbm\n",
      "[flaml.automl: 04-28 10:39:45] {2744} INFO -  at 182.0s,\testimator lgbm's best error=0.0989,\tbest estimator lgbm's best error=0.0989\n",
      "[flaml.automl: 04-28 10:39:45] {2567} INFO - iteration 141, current learner lgbm\n",
      "[flaml.automl: 04-28 10:39:47] {2744} INFO -  at 184.0s,\testimator lgbm's best error=0.0989,\tbest estimator lgbm's best error=0.0989\n",
      "[flaml.automl: 04-28 10:39:47] {2567} INFO - iteration 142, current learner lgbm\n",
      "[flaml.automl: 04-28 10:39:50] {2744} INFO -  at 187.0s,\testimator lgbm's best error=0.0980,\tbest estimator lgbm's best error=0.0980\n",
      "[flaml.automl: 04-28 10:39:50] {2567} INFO - iteration 143, current learner lgbm\n",
      "[flaml.automl: 04-28 10:39:52] {2744} INFO -  at 189.5s,\testimator lgbm's best error=0.0980,\tbest estimator lgbm's best error=0.0980\n",
      "[flaml.automl: 04-28 10:39:52] {2567} INFO - iteration 144, current learner lgbm\n",
      "[flaml.automl: 04-28 10:39:55] {2744} INFO -  at 192.7s,\testimator lgbm's best error=0.0980,\tbest estimator lgbm's best error=0.0980\n",
      "[flaml.automl: 04-28 10:39:55] {2567} INFO - iteration 145, current learner lgbm\n",
      "[flaml.automl: 04-28 10:39:58] {2744} INFO -  at 195.8s,\testimator lgbm's best error=0.0980,\tbest estimator lgbm's best error=0.0980\n",
      "[flaml.automl: 04-28 10:39:58] {2567} INFO - iteration 146, current learner lgbm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.automl: 04-28 10:40:02] {2744} INFO -  at 199.1s,\testimator lgbm's best error=0.0980,\tbest estimator lgbm's best error=0.0980\n",
      "[flaml.automl: 04-28 10:40:02] {2567} INFO - iteration 147, current learner lgbm\n",
      "[flaml.automl: 04-28 10:40:05] {2744} INFO -  at 202.4s,\testimator lgbm's best error=0.0980,\tbest estimator lgbm's best error=0.0980\n",
      "[flaml.automl: 04-28 10:40:05] {2567} INFO - iteration 148, current learner lgbm\n",
      "[flaml.automl: 04-28 10:40:06] {2744} INFO -  at 203.9s,\testimator lgbm's best error=0.0980,\tbest estimator lgbm's best error=0.0980\n",
      "[flaml.automl: 04-28 10:40:06] {2567} INFO - iteration 149, current learner lgbm\n",
      "[flaml.automl: 04-28 10:40:12] {2744} INFO -  at 209.4s,\testimator lgbm's best error=0.0977,\tbest estimator lgbm's best error=0.0977\n",
      "[flaml.automl: 04-28 10:40:12] {2567} INFO - iteration 150, current learner lgbm\n",
      "[flaml.automl: 04-28 10:40:14] {2744} INFO -  at 211.6s,\testimator lgbm's best error=0.0977,\tbest estimator lgbm's best error=0.0977\n",
      "[flaml.automl: 04-28 10:40:14] {2567} INFO - iteration 151, current learner lgbm\n",
      "[flaml.automl: 04-28 10:40:16] {2744} INFO -  at 213.4s,\testimator lgbm's best error=0.0977,\tbest estimator lgbm's best error=0.0977\n",
      "[flaml.automl: 04-28 10:40:16] {2567} INFO - iteration 152, current learner lgbm\n",
      "[flaml.automl: 04-28 10:40:21] {2744} INFO -  at 218.6s,\testimator lgbm's best error=0.0977,\tbest estimator lgbm's best error=0.0977\n",
      "[flaml.automl: 04-28 10:40:21] {2567} INFO - iteration 153, current learner lgbm\n",
      "[flaml.automl: 04-28 10:40:24] {2744} INFO -  at 221.2s,\testimator lgbm's best error=0.0974,\tbest estimator lgbm's best error=0.0974\n",
      "[flaml.automl: 04-28 10:40:24] {2567} INFO - iteration 154, current learner rf\n",
      "[flaml.automl: 04-28 10:40:29] {2744} INFO -  at 225.9s,\testimator rf's best error=0.1325,\tbest estimator lgbm's best error=0.0974\n",
      "[flaml.automl: 04-28 10:40:29] {2567} INFO - iteration 155, current learner lgbm\n",
      "[flaml.automl: 04-28 10:40:33] {2744} INFO -  at 230.5s,\testimator lgbm's best error=0.0974,\tbest estimator lgbm's best error=0.0974\n",
      "[flaml.automl: 04-28 10:40:33] {2567} INFO - iteration 156, current learner lgbm\n",
      "[flaml.automl: 04-28 10:40:38] {2744} INFO -  at 235.0s,\testimator lgbm's best error=0.0974,\tbest estimator lgbm's best error=0.0974\n",
      "[flaml.automl: 04-28 10:40:38] {2567} INFO - iteration 157, current learner lgbm\n",
      "[flaml.automl: 04-28 10:40:38] {2744} INFO -  at 235.9s,\testimator lgbm's best error=0.0974,\tbest estimator lgbm's best error=0.0974\n",
      "[flaml.automl: 04-28 10:40:38] {2567} INFO - iteration 158, current learner lgbm\n",
      "[flaml.automl: 04-28 10:40:41] {2744} INFO -  at 238.2s,\testimator lgbm's best error=0.0974,\tbest estimator lgbm's best error=0.0974\n",
      "[flaml.automl: 04-28 10:40:41] {2567} INFO - iteration 159, current learner lgbm\n",
      "[flaml.automl: 04-28 10:40:44] {2744} INFO -  at 241.4s,\testimator lgbm's best error=0.0974,\tbest estimator lgbm's best error=0.0974\n",
      "[flaml.automl: 04-28 10:40:44] {2567} INFO - iteration 160, current learner lgbm\n",
      "[flaml.automl: 04-28 10:40:45] {2744} INFO -  at 242.8s,\testimator lgbm's best error=0.0974,\tbest estimator lgbm's best error=0.0974\n",
      "[flaml.automl: 04-28 10:40:45] {2567} INFO - iteration 161, current learner rf\n",
      "[flaml.automl: 04-28 10:40:48] {2744} INFO -  at 245.7s,\testimator rf's best error=0.1325,\tbest estimator lgbm's best error=0.0974\n",
      "[flaml.automl: 04-28 10:40:48] {2567} INFO - iteration 162, current learner lgbm\n",
      "[flaml.automl: 04-28 10:40:53] {2744} INFO -  at 250.1s,\testimator lgbm's best error=0.0974,\tbest estimator lgbm's best error=0.0974\n",
      "[flaml.automl: 04-28 10:40:53] {2567} INFO - iteration 163, current learner lgbm\n",
      "[flaml.automl: 04-28 10:40:57] {2744} INFO -  at 254.7s,\testimator lgbm's best error=0.0974,\tbest estimator lgbm's best error=0.0974\n",
      "[flaml.automl: 04-28 10:40:57] {2567} INFO - iteration 164, current learner lgbm\n",
      "[flaml.automl: 04-28 10:40:58] {2744} INFO -  at 255.6s,\testimator lgbm's best error=0.0974,\tbest estimator lgbm's best error=0.0974\n",
      "[flaml.automl: 04-28 10:40:58] {2567} INFO - iteration 165, current learner lgbm\n",
      "[flaml.automl: 04-28 10:41:01] {2744} INFO -  at 258.2s,\testimator lgbm's best error=0.0974,\tbest estimator lgbm's best error=0.0974\n",
      "[flaml.automl: 04-28 10:41:01] {2567} INFO - iteration 166, current learner lgbm\n",
      "[flaml.automl: 04-28 10:41:03] {2744} INFO -  at 260.9s,\testimator lgbm's best error=0.0974,\tbest estimator lgbm's best error=0.0974\n",
      "[flaml.automl: 04-28 10:41:03] {2567} INFO - iteration 167, current learner lgbm\n",
      "[flaml.automl: 04-28 10:41:06] {2744} INFO -  at 263.6s,\testimator lgbm's best error=0.0974,\tbest estimator lgbm's best error=0.0974\n",
      "[flaml.automl: 04-28 10:41:06] {2567} INFO - iteration 168, current learner lgbm\n",
      "[flaml.automl: 04-28 10:41:08] {2744} INFO -  at 265.7s,\testimator lgbm's best error=0.0974,\tbest estimator lgbm's best error=0.0974\n",
      "[flaml.automl: 04-28 10:41:08] {2567} INFO - iteration 169, current learner lgbm\n",
      "[flaml.automl: 04-28 10:41:10] {2744} INFO -  at 267.8s,\testimator lgbm's best error=0.0974,\tbest estimator lgbm's best error=0.0974\n",
      "[flaml.automl: 04-28 10:41:10] {2567} INFO - iteration 170, current learner lgbm\n",
      "[flaml.automl: 04-28 10:41:13] {2744} INFO -  at 270.3s,\testimator lgbm's best error=0.0974,\tbest estimator lgbm's best error=0.0974\n",
      "[flaml.automl: 04-28 10:41:13] {2567} INFO - iteration 171, current learner lgbm\n",
      "[flaml.automl: 04-28 10:41:15] {2744} INFO -  at 272.6s,\testimator lgbm's best error=0.0974,\tbest estimator lgbm's best error=0.0974\n",
      "[flaml.automl: 04-28 10:41:15] {2567} INFO - iteration 172, current learner lgbm\n",
      "[flaml.automl: 04-28 10:41:18] {2744} INFO -  at 275.9s,\testimator lgbm's best error=0.0974,\tbest estimator lgbm's best error=0.0974\n",
      "[flaml.automl: 04-28 10:41:18] {2567} INFO - iteration 173, current learner lgbm\n",
      "[flaml.automl: 04-28 10:41:21] {2744} INFO -  at 278.5s,\testimator lgbm's best error=0.0974,\tbest estimator lgbm's best error=0.0974\n",
      "[flaml.automl: 04-28 10:41:21] {2567} INFO - iteration 174, current learner rf\n",
      "[flaml.automl: 04-28 10:41:23] {2744} INFO -  at 280.6s,\testimator rf's best error=0.1325,\tbest estimator lgbm's best error=0.0974\n",
      "[flaml.automl: 04-28 10:41:23] {2567} INFO - iteration 175, current learner lgbm\n",
      "[flaml.automl: 04-28 10:41:24] {2744} INFO -  at 281.8s,\testimator lgbm's best error=0.0974,\tbest estimator lgbm's best error=0.0974\n",
      "[flaml.automl: 04-28 10:41:24] {2567} INFO - iteration 176, current learner lgbm\n",
      "[flaml.automl: 04-28 10:41:26] {2744} INFO -  at 283.7s,\testimator lgbm's best error=0.0974,\tbest estimator lgbm's best error=0.0974\n",
      "[flaml.automl: 04-28 10:41:26] {2567} INFO - iteration 177, current learner lgbm\n",
      "[flaml.automl: 04-28 10:41:29] {2744} INFO -  at 286.7s,\testimator lgbm's best error=0.0974,\tbest estimator lgbm's best error=0.0974\n",
      "[flaml.automl: 04-28 10:41:29] {2567} INFO - iteration 178, current learner lgbm\n",
      "[flaml.automl: 04-28 10:41:31] {2744} INFO -  at 288.1s,\testimator lgbm's best error=0.0974,\tbest estimator lgbm's best error=0.0974\n",
      "[flaml.automl: 04-28 10:41:31] {2567} INFO - iteration 179, current learner lgbm\n",
      "[flaml.automl: 04-28 10:41:34] {2744} INFO -  at 291.2s,\testimator lgbm's best error=0.0974,\tbest estimator lgbm's best error=0.0974\n",
      "[flaml.automl: 04-28 10:41:34] {2567} INFO - iteration 180, current learner lgbm\n",
      "[flaml.automl: 04-28 10:41:37] {2744} INFO -  at 294.4s,\testimator lgbm's best error=0.0974,\tbest estimator lgbm's best error=0.0974\n",
      "[flaml.automl: 04-28 10:41:37] {2567} INFO - iteration 181, current learner lgbm\n",
      "[flaml.automl: 04-28 10:41:38] {2744} INFO -  at 295.3s,\testimator lgbm's best error=0.0974,\tbest estimator lgbm's best error=0.0974\n",
      "[flaml.automl: 04-28 10:41:38] {2567} INFO - iteration 182, current learner lgbm\n",
      "[flaml.automl: 04-28 10:41:40] {2744} INFO -  at 297.4s,\testimator lgbm's best error=0.0974,\tbest estimator lgbm's best error=0.0974\n",
      "[flaml.automl: 04-28 10:41:40] {2567} INFO - iteration 183, current learner lgbm\n",
      "[flaml.automl: 04-28 10:41:43] {2744} INFO -  at 300.2s,\testimator lgbm's best error=0.0974,\tbest estimator lgbm's best error=0.0974\n",
      "[flaml.automl: 04-28 10:41:43] {2567} INFO - iteration 184, current learner lgbm\n",
      "[flaml.automl: 04-28 10:41:46] {2744} INFO -  at 303.9s,\testimator lgbm's best error=0.0974,\tbest estimator lgbm's best error=0.0974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.automl: 04-28 10:41:46] {2567} INFO - iteration 185, current learner lgbm\n",
      "[flaml.automl: 04-28 10:41:48] {2744} INFO -  at 305.5s,\testimator lgbm's best error=0.0974,\tbest estimator lgbm's best error=0.0974\n",
      "[flaml.automl: 04-28 10:41:48] {2567} INFO - iteration 186, current learner lgbm\n",
      "[flaml.automl: 04-28 10:41:49] {2744} INFO -  at 306.8s,\testimator lgbm's best error=0.0974,\tbest estimator lgbm's best error=0.0974\n",
      "[flaml.automl: 04-28 10:41:49] {2567} INFO - iteration 187, current learner lgbm\n",
      "[flaml.automl: 04-28 10:41:53] {2744} INFO -  at 310.9s,\testimator lgbm's best error=0.0974,\tbest estimator lgbm's best error=0.0974\n",
      "[flaml.automl: 04-28 10:41:53] {2567} INFO - iteration 188, current learner lgbm\n",
      "[flaml.automl: 04-28 10:41:55] {2744} INFO -  at 312.1s,\testimator lgbm's best error=0.0974,\tbest estimator lgbm's best error=0.0974\n",
      "[flaml.automl: 04-28 10:41:55] {2567} INFO - iteration 189, current learner lgbm\n",
      "[flaml.automl: 04-28 10:41:58] {2744} INFO -  at 315.3s,\testimator lgbm's best error=0.0974,\tbest estimator lgbm's best error=0.0974\n",
      "[flaml.automl: 04-28 10:41:58] {2567} INFO - iteration 190, current learner lgbm\n",
      "[flaml.automl: 04-28 10:41:59] {2744} INFO -  at 316.5s,\testimator lgbm's best error=0.0974,\tbest estimator lgbm's best error=0.0974\n",
      "[flaml.automl: 04-28 10:41:59] {2567} INFO - iteration 191, current learner lgbm\n",
      "[flaml.automl: 04-28 10:42:04] {2744} INFO -  at 321.1s,\testimator lgbm's best error=0.0974,\tbest estimator lgbm's best error=0.0974\n",
      "[flaml.automl: 04-28 10:42:04] {2567} INFO - iteration 192, current learner rf\n",
      "[flaml.automl: 04-28 10:42:08] {2744} INFO -  at 325.3s,\testimator rf's best error=0.1325,\tbest estimator lgbm's best error=0.0974\n",
      "[flaml.automl: 04-28 10:42:08] {2567} INFO - iteration 193, current learner lgbm\n",
      "[flaml.automl: 04-28 10:42:09] {2744} INFO -  at 326.3s,\testimator lgbm's best error=0.0974,\tbest estimator lgbm's best error=0.0974\n",
      "[flaml.automl: 04-28 10:42:09] {2567} INFO - iteration 194, current learner lgbm\n",
      "[flaml.automl: 04-28 10:42:12] {2744} INFO -  at 329.9s,\testimator lgbm's best error=0.0961,\tbest estimator lgbm's best error=0.0961\n",
      "[flaml.automl: 04-28 10:42:12] {2567} INFO - iteration 195, current learner lgbm\n",
      "[flaml.automl: 04-28 10:42:14] {2744} INFO -  at 331.6s,\testimator lgbm's best error=0.0961,\tbest estimator lgbm's best error=0.0961\n",
      "[flaml.automl: 04-28 10:42:14] {2567} INFO - iteration 196, current learner lgbm\n",
      "[flaml.automl: 04-28 10:42:18] {2744} INFO -  at 335.1s,\testimator lgbm's best error=0.0961,\tbest estimator lgbm's best error=0.0961\n",
      "[flaml.automl: 04-28 10:42:18] {2567} INFO - iteration 197, current learner rf\n",
      "[flaml.automl: 04-28 10:42:19] {2744} INFO -  at 336.5s,\testimator rf's best error=0.1325,\tbest estimator lgbm's best error=0.0961\n",
      "[flaml.automl: 04-28 10:42:19] {2567} INFO - iteration 198, current learner rf\n",
      "[flaml.automl: 04-28 10:42:22] {2744} INFO -  at 339.0s,\testimator rf's best error=0.1325,\tbest estimator lgbm's best error=0.0961\n",
      "[flaml.automl: 04-28 10:42:22] {2567} INFO - iteration 199, current learner lgbm\n",
      "[flaml.automl: 04-28 10:42:23] {2744} INFO -  at 340.3s,\testimator lgbm's best error=0.0961,\tbest estimator lgbm's best error=0.0961\n",
      "[flaml.automl: 04-28 10:42:23] {2567} INFO - iteration 200, current learner lgbm\n",
      "[flaml.automl: 04-28 10:42:28] {2744} INFO -  at 345.0s,\testimator lgbm's best error=0.0961,\tbest estimator lgbm's best error=0.0961\n",
      "[flaml.automl: 04-28 10:42:28] {2567} INFO - iteration 201, current learner lgbm\n",
      "[flaml.automl: 04-28 10:42:31] {2744} INFO -  at 348.1s,\testimator lgbm's best error=0.0961,\tbest estimator lgbm's best error=0.0961\n",
      "[flaml.automl: 04-28 10:42:31] {2567} INFO - iteration 202, current learner rf\n",
      "[flaml.automl: 04-28 10:42:33] {2744} INFO -  at 350.4s,\testimator rf's best error=0.1325,\tbest estimator lgbm's best error=0.0961\n",
      "[flaml.automl: 04-28 10:42:33] {2567} INFO - iteration 203, current learner rf\n",
      "[flaml.automl: 04-28 10:42:35] {2744} INFO -  at 352.0s,\testimator rf's best error=0.1325,\tbest estimator lgbm's best error=0.0961\n",
      "[flaml.automl: 04-28 10:42:35] {2567} INFO - iteration 204, current learner lgbm\n",
      "[flaml.automl: 04-28 10:42:37] {2744} INFO -  at 354.2s,\testimator lgbm's best error=0.0961,\tbest estimator lgbm's best error=0.0961\n",
      "[flaml.automl: 04-28 10:42:37] {2567} INFO - iteration 205, current learner rf\n",
      "[flaml.automl: 04-28 10:42:40] {2744} INFO -  at 357.8s,\testimator rf's best error=0.1325,\tbest estimator lgbm's best error=0.0961\n",
      "[flaml.automl: 04-28 10:42:40] {2567} INFO - iteration 206, current learner lgbm\n",
      "[flaml.automl: 04-28 10:42:41] {2744} INFO -  at 358.6s,\testimator lgbm's best error=0.0961,\tbest estimator lgbm's best error=0.0961\n",
      "[flaml.automl: 04-28 10:42:41] {2567} INFO - iteration 207, current learner lgbm\n",
      "[flaml.automl: 04-28 10:42:46] {2744} INFO -  at 362.9s,\testimator lgbm's best error=0.0961,\tbest estimator lgbm's best error=0.0961\n",
      "[flaml.automl: 04-28 10:42:46] {2567} INFO - iteration 208, current learner lgbm\n",
      "[flaml.automl: 04-28 10:42:49] {2744} INFO -  at 366.2s,\testimator lgbm's best error=0.0953,\tbest estimator lgbm's best error=0.0953\n",
      "[flaml.automl: 04-28 10:42:49] {2567} INFO - iteration 209, current learner lgbm\n",
      "[flaml.automl: 04-28 10:42:50] {2744} INFO -  at 367.4s,\testimator lgbm's best error=0.0953,\tbest estimator lgbm's best error=0.0953\n",
      "[flaml.automl: 04-28 10:42:50] {2567} INFO - iteration 210, current learner lgbm\n",
      "[flaml.automl: 04-28 10:42:51] {2744} INFO -  at 368.6s,\testimator lgbm's best error=0.0953,\tbest estimator lgbm's best error=0.0953\n",
      "[flaml.automl: 04-28 10:42:51] {2567} INFO - iteration 211, current learner lgbm\n",
      "[flaml.automl: 04-28 10:42:57] {2744} INFO -  at 374.2s,\testimator lgbm's best error=0.0953,\tbest estimator lgbm's best error=0.0953\n",
      "[flaml.automl: 04-28 10:42:57] {2567} INFO - iteration 212, current learner lgbm\n",
      "[flaml.automl: 04-28 10:42:59] {2744} INFO -  at 375.9s,\testimator lgbm's best error=0.0953,\tbest estimator lgbm's best error=0.0953\n",
      "[flaml.automl: 04-28 10:42:59] {2567} INFO - iteration 213, current learner lgbm\n",
      "[flaml.automl: 04-28 10:43:02] {2744} INFO -  at 379.7s,\testimator lgbm's best error=0.0953,\tbest estimator lgbm's best error=0.0953\n",
      "[flaml.automl: 04-28 10:43:02] {2567} INFO - iteration 214, current learner rf\n",
      "[flaml.automl: 04-28 10:43:05] {2744} INFO -  at 382.4s,\testimator rf's best error=0.1313,\tbest estimator lgbm's best error=0.0953\n",
      "[flaml.automl: 04-28 10:43:05] {2567} INFO - iteration 215, current learner lgbm\n",
      "[flaml.automl: 04-28 10:43:08] {2744} INFO -  at 385.4s,\testimator lgbm's best error=0.0953,\tbest estimator lgbm's best error=0.0953\n",
      "[flaml.automl: 04-28 10:43:08] {2567} INFO - iteration 216, current learner lgbm\n",
      "[flaml.automl: 04-28 10:43:10] {2744} INFO -  at 387.3s,\testimator lgbm's best error=0.0953,\tbest estimator lgbm's best error=0.0953\n",
      "[flaml.automl: 04-28 10:43:10] {2567} INFO - iteration 217, current learner lgbm\n",
      "[flaml.automl: 04-28 10:43:12] {2744} INFO -  at 389.0s,\testimator lgbm's best error=0.0953,\tbest estimator lgbm's best error=0.0953\n",
      "[flaml.automl: 04-28 10:43:12] {2567} INFO - iteration 218, current learner lgbm\n",
      "[flaml.automl: 04-28 10:43:15] {2744} INFO -  at 392.9s,\testimator lgbm's best error=0.0953,\tbest estimator lgbm's best error=0.0953\n",
      "[flaml.automl: 04-28 10:43:15] {2567} INFO - iteration 219, current learner lgbm\n",
      "[flaml.automl: 04-28 10:43:19] {2744} INFO -  at 396.3s,\testimator lgbm's best error=0.0953,\tbest estimator lgbm's best error=0.0953\n",
      "[flaml.automl: 04-28 10:43:19] {2567} INFO - iteration 220, current learner lgbm\n",
      "[flaml.automl: 04-28 10:43:22] {2744} INFO -  at 399.6s,\testimator lgbm's best error=0.0953,\tbest estimator lgbm's best error=0.0953\n",
      "[flaml.automl: 04-28 10:43:22] {2567} INFO - iteration 221, current learner lgbm\n",
      "[flaml.automl: 04-28 10:43:23] {2744} INFO -  at 400.7s,\testimator lgbm's best error=0.0953,\tbest estimator lgbm's best error=0.0953\n",
      "[flaml.automl: 04-28 10:43:23] {2567} INFO - iteration 222, current learner lgbm\n",
      "[flaml.automl: 04-28 10:43:28] {2744} INFO -  at 405.7s,\testimator lgbm's best error=0.0953,\tbest estimator lgbm's best error=0.0953\n",
      "[flaml.automl: 04-28 10:43:28] {2567} INFO - iteration 223, current learner lgbm\n",
      "[flaml.automl: 04-28 10:43:30] {2744} INFO -  at 407.2s,\testimator lgbm's best error=0.0953,\tbest estimator lgbm's best error=0.0953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.automl: 04-28 10:43:30] {2567} INFO - iteration 224, current learner lgbm\n",
      "[flaml.automl: 04-28 10:43:33] {2744} INFO -  at 410.0s,\testimator lgbm's best error=0.0953,\tbest estimator lgbm's best error=0.0953\n",
      "[flaml.automl: 04-28 10:43:33] {2567} INFO - iteration 225, current learner lgbm\n",
      "[flaml.automl: 04-28 10:43:36] {2744} INFO -  at 413.6s,\testimator lgbm's best error=0.0953,\tbest estimator lgbm's best error=0.0953\n",
      "[flaml.automl: 04-28 10:43:36] {2567} INFO - iteration 226, current learner lgbm\n",
      "[flaml.automl: 04-28 10:43:38] {2744} INFO -  at 415.6s,\testimator lgbm's best error=0.0953,\tbest estimator lgbm's best error=0.0953\n",
      "[flaml.automl: 04-28 10:43:38] {2567} INFO - iteration 227, current learner lgbm\n",
      "[flaml.automl: 04-28 10:43:43] {2744} INFO -  at 420.3s,\testimator lgbm's best error=0.0953,\tbest estimator lgbm's best error=0.0953\n",
      "[flaml.automl: 04-28 10:43:43] {2567} INFO - iteration 228, current learner lgbm\n",
      "[flaml.automl: 04-28 10:43:45] {2744} INFO -  at 422.7s,\testimator lgbm's best error=0.0953,\tbest estimator lgbm's best error=0.0953\n",
      "[flaml.automl: 04-28 10:43:45] {2567} INFO - iteration 229, current learner lgbm\n",
      "[flaml.automl: 04-28 10:43:51] {2744} INFO -  at 428.1s,\testimator lgbm's best error=0.0953,\tbest estimator lgbm's best error=0.0953\n",
      "[flaml.automl: 04-28 10:43:51] {2567} INFO - iteration 230, current learner lgbm\n",
      "[flaml.automl: 04-28 10:43:54] {2744} INFO -  at 431.0s,\testimator lgbm's best error=0.0953,\tbest estimator lgbm's best error=0.0953\n",
      "[flaml.automl: 04-28 10:43:54] {2567} INFO - iteration 231, current learner lgbm\n",
      "[flaml.automl: 04-28 10:43:57] {2744} INFO -  at 434.3s,\testimator lgbm's best error=0.0953,\tbest estimator lgbm's best error=0.0953\n",
      "[flaml.automl: 04-28 10:43:57] {2567} INFO - iteration 232, current learner lgbm\n",
      "[flaml.automl: 04-28 10:43:58] {2744} INFO -  at 435.8s,\testimator lgbm's best error=0.0953,\tbest estimator lgbm's best error=0.0953\n",
      "[flaml.automl: 04-28 10:43:58] {2567} INFO - iteration 233, current learner lgbm\n",
      "[flaml.automl: 04-28 10:44:01] {2744} INFO -  at 438.3s,\testimator lgbm's best error=0.0953,\tbest estimator lgbm's best error=0.0953\n",
      "[flaml.automl: 04-28 10:44:01] {2567} INFO - iteration 234, current learner lgbm\n",
      "[flaml.automl: 04-28 10:44:03] {2744} INFO -  at 440.7s,\testimator lgbm's best error=0.0953,\tbest estimator lgbm's best error=0.0953\n",
      "[flaml.automl: 04-28 10:44:03] {2567} INFO - iteration 235, current learner lgbm\n",
      "[flaml.automl: 04-28 10:44:07] {2744} INFO -  at 444.5s,\testimator lgbm's best error=0.0953,\tbest estimator lgbm's best error=0.0953\n",
      "[flaml.automl: 04-28 10:44:07] {2567} INFO - iteration 236, current learner lgbm\n",
      "[flaml.automl: 04-28 10:44:09] {2744} INFO -  at 446.2s,\testimator lgbm's best error=0.0953,\tbest estimator lgbm's best error=0.0953\n",
      "[flaml.automl: 04-28 10:44:09] {2567} INFO - iteration 237, current learner lgbm\n",
      "[flaml.automl: 04-28 10:44:13] {2744} INFO -  at 450.3s,\testimator lgbm's best error=0.0953,\tbest estimator lgbm's best error=0.0953\n",
      "[flaml.automl: 04-28 10:44:13] {2567} INFO - iteration 238, current learner lgbm\n",
      "[flaml.automl: 04-28 10:44:15] {2744} INFO -  at 452.3s,\testimator lgbm's best error=0.0953,\tbest estimator lgbm's best error=0.0953\n",
      "[flaml.automl: 04-28 10:44:15] {2567} INFO - iteration 239, current learner lgbm\n",
      "[flaml.automl: 04-28 10:44:20] {2744} INFO -  at 457.3s,\testimator lgbm's best error=0.0953,\tbest estimator lgbm's best error=0.0953\n",
      "[flaml.automl: 04-28 10:44:20] {2567} INFO - iteration 240, current learner lgbm\n",
      "[flaml.automl: 04-28 10:44:22] {2744} INFO -  at 459.8s,\testimator lgbm's best error=0.0953,\tbest estimator lgbm's best error=0.0953\n",
      "[flaml.automl: 04-28 10:44:22] {2567} INFO - iteration 241, current learner lgbm\n",
      "[flaml.automl: 04-28 10:44:27] {2744} INFO -  at 464.8s,\testimator lgbm's best error=0.0953,\tbest estimator lgbm's best error=0.0953\n",
      "[flaml.automl: 04-28 10:44:27] {2567} INFO - iteration 242, current learner lgbm\n",
      "[flaml.automl: 04-28 10:44:29] {2744} INFO -  at 466.1s,\testimator lgbm's best error=0.0953,\tbest estimator lgbm's best error=0.0953\n",
      "[flaml.automl: 04-28 10:44:29] {2567} INFO - iteration 243, current learner lgbm\n",
      "[flaml.automl: 04-28 10:44:30] {2744} INFO -  at 467.1s,\testimator lgbm's best error=0.0953,\tbest estimator lgbm's best error=0.0953\n",
      "[flaml.automl: 04-28 10:44:30] {2567} INFO - iteration 244, current learner lgbm\n",
      "[flaml.automl: 04-28 10:44:33] {2744} INFO -  at 470.1s,\testimator lgbm's best error=0.0953,\tbest estimator lgbm's best error=0.0953\n",
      "[flaml.automl: 04-28 10:44:33] {2567} INFO - iteration 245, current learner lgbm\n",
      "[flaml.automl: 04-28 10:44:36] {2744} INFO -  at 472.9s,\testimator lgbm's best error=0.0953,\tbest estimator lgbm's best error=0.0953\n",
      "[flaml.automl: 04-28 10:44:36] {2567} INFO - iteration 246, current learner lgbm\n",
      "[flaml.automl: 04-28 10:44:37] {2744} INFO -  at 474.3s,\testimator lgbm's best error=0.0953,\tbest estimator lgbm's best error=0.0953\n",
      "[flaml.automl: 04-28 10:44:37] {2567} INFO - iteration 247, current learner lgbm\n",
      "[flaml.automl: 04-28 10:44:40] {2744} INFO -  at 477.3s,\testimator lgbm's best error=0.0953,\tbest estimator lgbm's best error=0.0953\n",
      "[flaml.automl: 04-28 10:44:40] {2567} INFO - iteration 248, current learner lgbm\n",
      "[flaml.automl: 04-28 10:44:41] {2744} INFO -  at 478.5s,\testimator lgbm's best error=0.0953,\tbest estimator lgbm's best error=0.0953\n",
      "[flaml.automl: 04-28 10:44:41] {2567} INFO - iteration 249, current learner lgbm\n",
      "[flaml.automl: 04-28 10:44:44] {2744} INFO -  at 481.1s,\testimator lgbm's best error=0.0953,\tbest estimator lgbm's best error=0.0953\n",
      "[flaml.automl: 04-28 10:44:44] {2567} INFO - iteration 250, current learner lgbm\n",
      "[flaml.automl: 04-28 10:44:47] {2744} INFO -  at 484.2s,\testimator lgbm's best error=0.0953,\tbest estimator lgbm's best error=0.0953\n",
      "[flaml.automl: 04-28 10:44:47] {2567} INFO - iteration 251, current learner lgbm\n",
      "[flaml.automl: 04-28 10:44:50] {2744} INFO -  at 487.9s,\testimator lgbm's best error=0.0944,\tbest estimator lgbm's best error=0.0944\n",
      "[flaml.automl: 04-28 10:44:50] {2567} INFO - iteration 252, current learner lgbm\n",
      "[flaml.automl: 04-28 10:44:52] {2744} INFO -  at 489.7s,\testimator lgbm's best error=0.0944,\tbest estimator lgbm's best error=0.0944\n",
      "[flaml.automl: 04-28 10:44:52] {2567} INFO - iteration 253, current learner lgbm\n",
      "[flaml.automl: 04-28 10:44:54] {2744} INFO -  at 491.8s,\testimator lgbm's best error=0.0944,\tbest estimator lgbm's best error=0.0944\n",
      "[flaml.automl: 04-28 10:44:54] {2567} INFO - iteration 254, current learner rf\n",
      "[flaml.automl: 04-28 10:44:57] {2744} INFO -  at 494.2s,\testimator rf's best error=0.1313,\tbest estimator lgbm's best error=0.0944\n",
      "[flaml.automl: 04-28 10:44:57] {2567} INFO - iteration 255, current learner lgbm\n",
      "[flaml.automl: 04-28 10:45:00] {2744} INFO -  at 497.2s,\testimator lgbm's best error=0.0944,\tbest estimator lgbm's best error=0.0944\n",
      "[flaml.automl: 04-28 10:45:00] {2567} INFO - iteration 256, current learner rf\n",
      "[flaml.automl: 04-28 10:45:04] {2744} INFO -  at 501.6s,\testimator rf's best error=0.1313,\tbest estimator lgbm's best error=0.0944\n",
      "[flaml.automl: 04-28 10:45:04] {2567} INFO - iteration 257, current learner lgbm\n",
      "[flaml.automl: 04-28 10:45:06] {2744} INFO -  at 503.1s,\testimator lgbm's best error=0.0944,\tbest estimator lgbm's best error=0.0944\n",
      "[flaml.automl: 04-28 10:45:06] {2567} INFO - iteration 258, current learner lgbm\n",
      "[flaml.automl: 04-28 10:45:10] {2744} INFO -  at 507.7s,\testimator lgbm's best error=0.0944,\tbest estimator lgbm's best error=0.0944\n",
      "[flaml.automl: 04-28 10:45:10] {2567} INFO - iteration 259, current learner lgbm\n",
      "[flaml.automl: 04-28 10:45:14] {2744} INFO -  at 511.1s,\testimator lgbm's best error=0.0944,\tbest estimator lgbm's best error=0.0944\n",
      "[flaml.automl: 04-28 10:45:14] {2567} INFO - iteration 260, current learner lgbm\n",
      "[flaml.automl: 04-28 10:45:18] {2744} INFO -  at 514.9s,\testimator lgbm's best error=0.0944,\tbest estimator lgbm's best error=0.0944\n",
      "[flaml.automl: 04-28 10:45:18] {2567} INFO - iteration 261, current learner lgbm\n",
      "[flaml.automl: 04-28 10:45:19] {2744} INFO -  at 516.8s,\testimator lgbm's best error=0.0944,\tbest estimator lgbm's best error=0.0944\n",
      "[flaml.automl: 04-28 10:45:19] {2567} INFO - iteration 262, current learner lgbm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.automl: 04-28 10:45:25] {2744} INFO -  at 522.6s,\testimator lgbm's best error=0.0944,\tbest estimator lgbm's best error=0.0944\n",
      "[flaml.automl: 04-28 10:45:25] {2567} INFO - iteration 263, current learner lgbm\n",
      "[flaml.automl: 04-28 10:45:28] {2744} INFO -  at 525.2s,\testimator lgbm's best error=0.0944,\tbest estimator lgbm's best error=0.0944\n",
      "[flaml.automl: 04-28 10:45:28] {2567} INFO - iteration 264, current learner lgbm\n",
      "[flaml.automl: 04-28 10:45:31] {2744} INFO -  at 528.9s,\testimator lgbm's best error=0.0944,\tbest estimator lgbm's best error=0.0944\n",
      "[flaml.automl: 04-28 10:45:31] {2567} INFO - iteration 265, current learner lgbm\n",
      "[flaml.automl: 04-28 10:45:35] {2744} INFO -  at 532.0s,\testimator lgbm's best error=0.0944,\tbest estimator lgbm's best error=0.0944\n",
      "[flaml.automl: 04-28 10:45:35] {2567} INFO - iteration 266, current learner lgbm\n",
      "[flaml.automl: 04-28 10:45:39] {2744} INFO -  at 536.4s,\testimator lgbm's best error=0.0944,\tbest estimator lgbm's best error=0.0944\n",
      "[flaml.automl: 04-28 10:45:39] {2567} INFO - iteration 267, current learner lgbm\n",
      "[flaml.automl: 04-28 10:45:43] {2744} INFO -  at 540.1s,\testimator lgbm's best error=0.0944,\tbest estimator lgbm's best error=0.0944\n",
      "[flaml.automl: 04-28 10:45:43] {2567} INFO - iteration 268, current learner lgbm\n",
      "[flaml.automl: 04-28 10:45:45] {2744} INFO -  at 542.0s,\testimator lgbm's best error=0.0944,\tbest estimator lgbm's best error=0.0944\n",
      "[flaml.automl: 04-28 10:45:45] {2567} INFO - iteration 269, current learner lgbm\n",
      "[flaml.automl: 04-28 10:45:47] {2744} INFO -  at 544.0s,\testimator lgbm's best error=0.0944,\tbest estimator lgbm's best error=0.0944\n",
      "[flaml.automl: 04-28 10:45:47] {2567} INFO - iteration 270, current learner lgbm\n",
      "[flaml.automl: 04-28 10:45:51] {2744} INFO -  at 548.7s,\testimator lgbm's best error=0.0944,\tbest estimator lgbm's best error=0.0944\n",
      "[flaml.automl: 04-28 10:45:51] {2567} INFO - iteration 271, current learner lgbm\n",
      "[flaml.automl: 04-28 10:45:58] {2744} INFO -  at 555.1s,\testimator lgbm's best error=0.0944,\tbest estimator lgbm's best error=0.0944\n",
      "[flaml.automl: 04-28 10:45:58] {2567} INFO - iteration 272, current learner lgbm\n",
      "[flaml.automl: 04-28 10:45:59] {2744} INFO -  at 556.7s,\testimator lgbm's best error=0.0944,\tbest estimator lgbm's best error=0.0944\n",
      "[flaml.automl: 04-28 10:45:59] {2567} INFO - iteration 273, current learner lgbm\n",
      "[flaml.automl: 04-28 10:46:02] {2744} INFO -  at 559.1s,\testimator lgbm's best error=0.0944,\tbest estimator lgbm's best error=0.0944\n",
      "[flaml.automl: 04-28 10:46:02] {2567} INFO - iteration 274, current learner lgbm\n",
      "[flaml.automl: 04-28 10:46:05] {2744} INFO -  at 562.8s,\testimator lgbm's best error=0.0944,\tbest estimator lgbm's best error=0.0944\n",
      "[flaml.automl: 04-28 10:46:05] {2567} INFO - iteration 275, current learner lgbm\n",
      "[flaml.automl: 04-28 10:46:10] {2744} INFO -  at 567.0s,\testimator lgbm's best error=0.0944,\tbest estimator lgbm's best error=0.0944\n",
      "[flaml.automl: 04-28 10:46:10] {2567} INFO - iteration 276, current learner lgbm\n",
      "[flaml.automl: 04-28 10:46:13] {2744} INFO -  at 570.1s,\testimator lgbm's best error=0.0944,\tbest estimator lgbm's best error=0.0944\n",
      "[flaml.automl: 04-28 10:46:13] {2567} INFO - iteration 277, current learner rf\n",
      "[flaml.automl: 04-28 10:46:14] {2744} INFO -  at 571.5s,\testimator rf's best error=0.1313,\tbest estimator lgbm's best error=0.0944\n",
      "[flaml.automl: 04-28 10:46:14] {2567} INFO - iteration 278, current learner lgbm\n",
      "[flaml.automl: 04-28 10:46:16] {2744} INFO -  at 573.4s,\testimator lgbm's best error=0.0944,\tbest estimator lgbm's best error=0.0944\n",
      "[flaml.automl: 04-28 10:46:16] {2567} INFO - iteration 279, current learner lgbm\n",
      "[flaml.automl: 04-28 10:46:19] {2744} INFO -  at 576.5s,\testimator lgbm's best error=0.0944,\tbest estimator lgbm's best error=0.0944\n",
      "[flaml.automl: 04-28 10:46:19] {2567} INFO - iteration 280, current learner lgbm\n",
      "[flaml.automl: 04-28 10:46:23] {2744} INFO -  at 580.0s,\testimator lgbm's best error=0.0944,\tbest estimator lgbm's best error=0.0944\n",
      "[flaml.automl: 04-28 10:46:23] {2567} INFO - iteration 281, current learner lgbm\n",
      "[flaml.automl: 04-28 10:46:24] {2744} INFO -  at 581.3s,\testimator lgbm's best error=0.0944,\tbest estimator lgbm's best error=0.0944\n",
      "[flaml.automl: 04-28 10:46:24] {2567} INFO - iteration 282, current learner lgbm\n",
      "[flaml.automl: 04-28 10:46:29] {2744} INFO -  at 586.7s,\testimator lgbm's best error=0.0944,\tbest estimator lgbm's best error=0.0944\n",
      "[flaml.automl: 04-28 10:46:29] {2567} INFO - iteration 283, current learner lgbm\n",
      "[flaml.automl: 04-28 10:46:32] {2744} INFO -  at 589.1s,\testimator lgbm's best error=0.0944,\tbest estimator lgbm's best error=0.0944\n",
      "[flaml.automl: 04-28 10:46:32] {2567} INFO - iteration 284, current learner lgbm\n",
      "[flaml.automl: 04-28 10:46:35] {2744} INFO -  at 592.4s,\testimator lgbm's best error=0.0944,\tbest estimator lgbm's best error=0.0944\n",
      "[flaml.automl: 04-28 10:46:35] {2567} INFO - iteration 285, current learner lgbm\n",
      "[flaml.automl: 04-28 10:46:37] {2744} INFO -  at 594.7s,\testimator lgbm's best error=0.0944,\tbest estimator lgbm's best error=0.0944\n",
      "[flaml.automl: 04-28 10:46:37] {2567} INFO - iteration 286, current learner lgbm\n",
      "[flaml.automl: 04-28 10:46:42] {2744} INFO -  at 599.8s,\testimator lgbm's best error=0.0944,\tbest estimator lgbm's best error=0.0944\n",
      "[flaml.automl: 04-28 10:46:43] {2974} INFO - retrain lgbm for 0.8s\n",
      "[flaml.automl: 04-28 10:46:43] {2981} INFO - retrained model: LGBMRegressor(colsample_bytree=0.14422556101887926,\n",
      "              learning_rate=0.016236018784183955, max_bin=511,\n",
      "              min_child_samples=2, n_estimators=1167, num_leaves=13,\n",
      "              reg_alpha=0.0021878989799153843, reg_lambda=0.29013631651471156,\n",
      "              verbose=-1)\n",
      "[flaml.automl: 04-28 10:46:43] {2310} INFO - fit succeeded\n",
      "[flaml.automl: 04-28 10:46:43] {2311} INFO - Time taken to find the best model: 487.8945827484131\n",
      "[flaml.automl: 04-28 10:46:43] {2322} WARNING - Time taken to find the best model is 81% of the provided time budget and not all estimators' hyperparameter search converged. Consider increasing the time budget.\n"
     ]
    }
   ],
   "source": [
    "from flaml import AutoML\n",
    "from flaml.default import LGBMRegressor\n",
    "automl = AutoML()\n",
    "# X_train, X_test, y_train, y_test\n",
    "automl.fit(X_train, y_train, task=\"regression\", estimator_list=[\"lgbm\", \"rf\", \"extra_tree\"],\n",
    "           train_time_limit=60,\n",
    "           time_budget=600,\n",
    "           n_jobs=-1,\n",
    "          ## ensemble=dict(final_estimator= LGBMRegressor(),\n",
    "          ## passthrough = True), \n",
    "           log_file_name='flaml_.log', log_type='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "275cb218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lgbm\n"
     ]
    }
   ],
   "source": [
    "print(automl.best_estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "70027704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 1167, 'num_leaves': 13, 'min_child_samples': 2, 'learning_rate': 0.016236018784183955, 'log_max_bin': 9, 'colsample_bytree': 0.14422556101887926, 'reg_alpha': 0.0021878989799153843, 'reg_lambda': 0.29013631651471156}\n"
     ]
    }
   ],
   "source": [
    "print(automl.best_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "88fceb7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lgbm': {'n_estimators': 1167, 'num_leaves': 13, 'min_child_samples': 2, 'learning_rate': 0.016236018784183955, 'log_max_bin': 9, 'colsample_bytree': 0.14422556101887926, 'reg_alpha': 0.0021878989799153843, 'reg_lambda': 0.29013631651471156}, 'rf': {'n_estimators': 129, 'max_features': 0.41559931863460825, 'max_leaves': 252}, 'extra_tree': {'n_estimators': 110, 'max_features': 0.3799322964180203, 'max_leaves': 583}}\n"
     ]
    }
   ],
   "source": [
    "print(automl.best_config_per_estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f7a21b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flaml.data import get_output_from_log\n",
    "\n",
    "time_history, best_valid_loss_history, valid_loss_history, config_history, metric_history = \\\n",
    "    get_output_from_log(filename='flaml_logfile', time_budget=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "57c3e4c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.5.1-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 11.3 MB 4.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting fonttools>=4.22.0\n",
      "  Downloading fonttools-4.33.3-py3-none-any.whl (930 kB)\n",
      "\u001b[K     |████████████████████████████████| 930 kB 2.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pillow>=6.2.0\n",
      "  Downloading Pillow-9.1.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.3 MB 5.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting cycler>=0.10\n",
      "  Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/martin/miniconda3/envs/autoML/lib/python3.8/site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/martin/miniconda3/envs/autoML/lib/python3.8/site-packages (from matplotlib) (3.0.8)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/martin/miniconda3/envs/autoML/lib/python3.8/site-packages (from matplotlib) (1.22.3)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Downloading kiwisolver-1.4.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2 MB 3.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7 in /home/martin/miniconda3/envs/autoML/lib/python3.8/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/martin/miniconda3/envs/autoML/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Installing collected packages: pillow, kiwisolver, fonttools, cycler, matplotlib\n",
      "Successfully installed cycler-0.11.0 fonttools-4.33.3 kiwisolver-1.4.2 matplotlib-3.5.1 pillow-9.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "80240fef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.title(\"Learning Curve\")\n",
    "plt.xlabel(\"Wall Clock Time (s)\")\n",
    "plt.ylabel(\"Validation Accuracy\")\n",
    "plt.step(time_history, 1 - np.array(best_valid_loss_history), where=\"post\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "63473500",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = automl.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8659db39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13330922469250328"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(np.mean((prediction - y_test)**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13dd8dbc",
   "metadata": {},
   "source": [
    "# OPTUNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ada925b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting optuna\n",
      "  Downloading optuna-2.10.0-py3-none-any.whl (308 kB)\n",
      "\u001b[K     |████████████████████████████████| 308 kB 1.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: PyYAML in /home/martin/miniconda3/envs/autoML/lib/python3.8/site-packages (from optuna) (6.0)\n",
      "Collecting colorlog\n",
      "  Downloading colorlog-6.6.0-py2.py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/martin/miniconda3/envs/autoML/lib/python3.8/site-packages (from optuna) (21.3)\n",
      "Requirement already satisfied: scipy!=1.4.0 in /home/martin/miniconda3/envs/autoML/lib/python3.8/site-packages (from optuna) (1.8.0)\n",
      "Collecting sqlalchemy>=1.1.0\n",
      "  Downloading SQLAlchemy-1.4.36-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.6 MB 1.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting alembic\n",
      "  Downloading alembic-1.7.7-py3-none-any.whl (210 kB)\n",
      "\u001b[K     |████████████████████████████████| 210 kB 2.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting cmaes>=0.8.2\n",
      "  Downloading cmaes-0.8.2-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: tqdm in /home/martin/miniconda3/envs/autoML/lib/python3.8/site-packages (from optuna) (4.64.0)\n",
      "Requirement already satisfied: numpy in /home/martin/miniconda3/envs/autoML/lib/python3.8/site-packages (from optuna) (1.22.3)\n",
      "Collecting cliff\n",
      "  Downloading cliff-3.10.1-py3-none-any.whl (81 kB)\n",
      "\u001b[K     |████████████████████████████████| 81 kB 2.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/martin/miniconda3/envs/autoML/lib/python3.8/site-packages (from packaging>=20.0->optuna) (3.0.8)\n",
      "Collecting greenlet!=0.4.17\n",
      "  Downloading greenlet-1.1.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (156 kB)\n",
      "\u001b[K     |████████████████████████████████| 156 kB 2.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting Mako\n",
      "  Downloading Mako-1.2.0-py3-none-any.whl (78 kB)\n",
      "\u001b[K     |████████████████████████████████| 78 kB 2.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: importlib-resources in /home/martin/miniconda3/envs/autoML/lib/python3.8/site-packages (from alembic->optuna) (5.7.1)\n",
      "Collecting importlib-metadata\n",
      "  Downloading importlib_metadata-4.11.3-py3-none-any.whl (18 kB)\n",
      "Collecting stevedore>=2.0.1\n",
      "  Downloading stevedore-3.5.0-py3-none-any.whl (49 kB)\n",
      "\u001b[K     |████████████████████████████████| 49 kB 2.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting PrettyTable>=0.7.2\n",
      "  Downloading prettytable-3.2.0-py3-none-any.whl (26 kB)\n",
      "Collecting autopage>=0.4.0\n",
      "  Downloading autopage-0.5.0-py3-none-any.whl (29 kB)\n",
      "Collecting pbr!=2.1.0,>=2.0.0\n",
      "  Downloading pbr-5.8.1-py2.py3-none-any.whl (113 kB)\n",
      "\u001b[K     |████████████████████████████████| 113 kB 2.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting cmd2>=1.0.0\n",
      "  Downloading cmd2-2.4.1-py3-none-any.whl (146 kB)\n",
      "\u001b[K     |████████████████████████████████| 146 kB 2.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: wcwidth>=0.1.7 in /home/martin/miniconda3/envs/autoML/lib/python3.8/site-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n",
      "Requirement already satisfied: attrs>=16.3.0 in /home/martin/miniconda3/envs/autoML/lib/python3.8/site-packages (from cmd2>=1.0.0->cliff->optuna) (21.4.0)\n",
      "Collecting pyperclip>=1.6\n",
      "  Downloading pyperclip-1.8.2.tar.gz (20 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/martin/miniconda3/envs/autoML/lib/python3.8/site-packages (from importlib-metadata->alembic->optuna) (3.8.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /home/martin/miniconda3/envs/autoML/lib/python3.8/site-packages (from Mako->alembic->optuna) (2.1.1)\n",
      "Building wheels for collected packages: pyperclip\n",
      "  Building wheel for pyperclip (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pyperclip: filename=pyperclip-1.8.2-py3-none-any.whl size=11137 sha256=66a18405d8179da3a22c991b50e30bd1b68190294d15057ad863e47120861bc0\n",
      "  Stored in directory: /home/martin/.cache/pip/wheels/7f/1a/65/84ff8c386bec21fca6d220ea1f5498a0367883a78dd5ba6122\n",
      "Successfully built pyperclip\n",
      "Installing collected packages: pyperclip, pbr, greenlet, stevedore, sqlalchemy, PrettyTable, Mako, importlib-metadata, cmd2, autopage, colorlog, cmaes, cliff, alembic, optuna\n",
      "Successfully installed Mako-1.2.0 PrettyTable-3.2.0 alembic-1.7.7 autopage-0.5.0 cliff-3.10.1 cmaes-0.8.2 cmd2-2.4.1 colorlog-6.6.0 greenlet-1.1.2 importlib-metadata-4.11.3 optuna-2.10.0 pbr-5.8.1 pyperclip-1.8.2 sqlalchemy-1.4.36 stevedore-3.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c3910601",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-28 10:50:07,972]\u001b[0m A new study created in memory with name: no-name-89cfb7d5-46e0-4e72-8798-d4371d3c5829\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=7 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=7 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=7 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=7 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=7 will be ignored. Current value: bagging_freq=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-28 10:50:08,494]\u001b[0m Trial 0 finished with value: 0.13461050785458054 and parameters: {'learning_rate': 0.0626445333008197, 'reg_lambda': 0.0005167418439852972, 'n_estimators': 174, 'num_leaves': 29, 'bagging_freq': 4, 'min_child_samples': 57, 'subsample_freq': 7, 'colsample_bytree': 0.533802541173267, 'subsample': 0.7322648458464427}. Best is trial 0 with value: 0.13461050785458054.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=8 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=8 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=8 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=8 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=8 will be ignored. Current value: bagging_freq=6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-28 10:50:09,534]\u001b[0m Trial 1 finished with value: 0.1339262357233636 and parameters: {'learning_rate': 0.03025335997452125, 'reg_lambda': 0.0020301951966907768, 'n_estimators': 199, 'num_leaves': 30, 'bagging_freq': 6, 'min_child_samples': 11, 'subsample_freq': 8, 'colsample_bytree': 0.826270282885486, 'subsample': 0.6446368960542288}. Best is trial 1 with value: 0.1339262357233636.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=7 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=7 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=7 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=7 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=7 will be ignored. Current value: bagging_freq=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-28 10:50:10,498]\u001b[0m Trial 2 finished with value: 0.13271433247721925 and parameters: {'learning_rate': 0.0969104340158595, 'reg_lambda': 0.0008386543993149321, 'n_estimators': 330, 'num_leaves': 25, 'bagging_freq': 3, 'min_child_samples': 46, 'subsample_freq': 7, 'colsample_bytree': 0.5519081755085138, 'subsample': 0.9474830093512736}. Best is trial 2 with value: 0.13271433247721925.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=6 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=6 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=6 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-28 10:50:10,996]\u001b[0m Trial 3 finished with value: 0.14766783418950502 and parameters: {'learning_rate': 0.0204342984415749, 'reg_lambda': 2.3123588683494552e-05, 'n_estimators': 225, 'num_leaves': 18, 'bagging_freq': 1, 'min_child_samples': 94, 'subsample_freq': 6, 'colsample_bytree': 0.6929707948190607, 'subsample': 0.9766705613985708}. Best is trial 2 with value: 0.13271433247721925.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=6 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=6 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=1 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=1 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=1 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=1 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-28 10:50:11,453]\u001b[0m Trial 4 finished with value: 0.252321939347829 and parameters: {'learning_rate': 0.003917872234977782, 'reg_lambda': 1.910692176951235e-06, 'n_estimators': 281, 'num_leaves': 12, 'bagging_freq': 1, 'min_child_samples': 80, 'subsample_freq': 1, 'colsample_bytree': 0.9760172813005643, 'subsample': 0.5052135963354876}. Best is trial 2 with value: 0.13271433247721925.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=1 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=2 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=2 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=2 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=2 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=2 will be ignored. Current value: bagging_freq=7"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-28 10:50:11,968]\u001b[0m Trial 5 finished with value: 0.23302434741665853 and parameters: {'learning_rate': 0.0047464298356568475, 'reg_lambda': 0.02283684275967303, 'n_estimators': 214, 'num_leaves': 28, 'bagging_freq': 7, 'min_child_samples': 63, 'subsample_freq': 2, 'colsample_bytree': 0.7551619703517376, 'subsample': 0.7315024742797556}. Best is trial 2 with value: 0.13271433247721925.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=3 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=3 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=3 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=3 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=3 will be ignored. Current value: bagging_freq=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-28 10:50:12,960]\u001b[0m Trial 6 finished with value: 0.33745141167289444 and parameters: {'learning_rate': 0.0009728671364942086, 'reg_lambda': 1.8935691213759531e-06, 'n_estimators': 200, 'num_leaves': 16, 'bagging_freq': 4, 'min_child_samples': 11, 'subsample_freq': 3, 'colsample_bytree': 0.9483325436040101, 'subsample': 0.9595231388098239}. Best is trial 2 with value: 0.13271433247721925.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=2 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=2 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=2 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=2 will be ignored. Current value: bagging_freq=7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-28 10:50:13,755]\u001b[0m Trial 7 finished with value: 0.3320493289353533 and parameters: {'learning_rate': 0.0008954828624269622, 'reg_lambda': 0.07637961525901081, 'n_estimators': 261, 'num_leaves': 10, 'bagging_freq': 7, 'min_child_samples': 13, 'subsample_freq': 2, 'colsample_bytree': 0.7145312292967583, 'subsample': 0.6067024515056727}. Best is trial 2 with value: 0.13271433247721925.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=2 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=8 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=8 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=8 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=8 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=8 will be ignored. Current value: bagging_freq=7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-28 10:50:15,492]\u001b[0m Trial 8 finished with value: 0.1525268829127271 and parameters: {'learning_rate': 0.006267250781796676, 'reg_lambda': 0.002650522694140983, 'n_estimators': 348, 'num_leaves': 27, 'bagging_freq': 7, 'min_child_samples': 6, 'subsample_freq': 8, 'colsample_bytree': 0.6854603946204186, 'subsample': 0.9530727316988872}. Best is trial 2 with value: 0.13271433247721925.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-28 10:50:15,829]\u001b[0m Trial 9 finished with value: 0.2509402789380366 and parameters: {'learning_rate': 0.008495500060912882, 'reg_lambda': 0.005234902188554965, 'n_estimators': 110, 'num_leaves': 30, 'bagging_freq': 2, 'min_child_samples': 100, 'subsample_freq': 0, 'colsample_bytree': 0.6150535606737002, 'subsample': 0.8472460557560444}. Best is trial 2 with value: 0.13271433247721925.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=5 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=5 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=5 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=5 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=5 will be ignored. Current value: bagging_freq=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-28 10:50:16,600]\u001b[0m Trial 10 finished with value: 0.3764874932343056 and parameters: {'learning_rate': 0.00012195485709320138, 'reg_lambda': 0.7604762740736989, 'n_estimators': 400, 'num_leaves': 4, 'bagging_freq': 5, 'min_child_samples': 36, 'subsample_freq': 5, 'colsample_bytree': 0.5120692884552408, 'subsample': 0.8512129156666413}. Best is trial 2 with value: 0.13271433247721925.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=8 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=8 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=8 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=8 will be ignored. Current value: bagging_freq=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-28 10:50:17,473]\u001b[0m Trial 11 finished with value: 0.13652187610640754 and parameters: {'learning_rate': 0.0782662291172844, 'reg_lambda': 2.0362772377747758e-08, 'n_estimators': 309, 'num_leaves': 22, 'bagging_freq': 5, 'min_child_samples': 35, 'subsample_freq': 8, 'colsample_bytree': 0.8407909293177894, 'subsample': 0.6359015172527513}. Best is trial 2 with value: 0.13271433247721925.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=8 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=5 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=5 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=5 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=5 will be ignored. Current value: bagging_freq=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-28 10:50:18,055]\u001b[0m Trial 12 finished with value: 0.13803732119161635 and parameters: {'learning_rate': 0.0330191373765353, 'reg_lambda': 7.646416227314871e-05, 'n_estimators': 146, 'num_leaves': 23, 'bagging_freq': 3, 'min_child_samples': 34, 'subsample_freq': 5, 'colsample_bytree': 0.8848391751078709, 'subsample': 0.635203605424622}. Best is trial 2 with value: 0.13271433247721925.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=5 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=7 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=7 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=7 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=7 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=7 will be ignored. Current value: bagging_freq=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-28 10:50:19,399]\u001b[0m Trial 13 finished with value: 0.13018254490965397 and parameters: {'learning_rate': 0.02035623039241466, 'reg_lambda': 0.0004975322700869825, 'n_estimators': 333, 'num_leaves': 24, 'bagging_freq': 5, 'min_child_samples': 23, 'subsample_freq': 7, 'colsample_bytree': 0.7948052391570827, 'subsample': 0.8206818403464098}. Best is trial 13 with value: 0.13018254490965397.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=6 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=6 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=6 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=6 will be ignored. Current value: bagging_freq=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-28 10:50:20,363]\u001b[0m Trial 14 finished with value: 0.13520325440896955 and parameters: {'learning_rate': 0.01469362487021236, 'reg_lambda': 1.0373936914570905e-05, 'n_estimators': 344, 'num_leaves': 23, 'bagging_freq': 3, 'min_child_samples': 45, 'subsample_freq': 6, 'colsample_bytree': 0.6140570251768419, 'subsample': 0.8518685564873979}. Best is trial 13 with value: 0.13018254490965397.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=6 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=4 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=4 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=4 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=4 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=4 will be ignored. Current value: bagging_freq=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-28 10:50:21,828]\u001b[0m Trial 15 finished with value: 0.13429017746487332 and parameters: {'learning_rate': 0.08391830974592686, 'reg_lambda': 0.00027459974397538075, 'n_estimators': 397, 'num_leaves': 19, 'bagging_freq': 3, 'min_child_samples': 26, 'subsample_freq': 4, 'colsample_bytree': 0.8054767809861506, 'subsample': 0.8096417595063896}. Best is trial 13 with value: 0.13018254490965397.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=6 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=6 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=6 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=6 will be ignored. Current value: bagging_freq=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-28 10:50:22,581]\u001b[0m Trial 16 finished with value: 0.28351545831771074 and parameters: {'learning_rate': 0.0016510668668564274, 'reg_lambda': 1.250550128096383e-08, 'n_estimators': 328, 'num_leaves': 25, 'bagging_freq': 5, 'min_child_samples': 66, 'subsample_freq': 6, 'colsample_bytree': 0.6094196056354062, 'subsample': 0.9037891509163969}. Best is trial 13 with value: 0.13018254490965397.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=6 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=7 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=7 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=7 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=7 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=7 will be ignored. Current value: bagging_freq=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-28 10:50:23,854]\u001b[0m Trial 17 finished with value: 0.1306708056406348 and parameters: {'learning_rate': 0.04751020549489045, 'reg_lambda': 0.10539186349238844, 'n_estimators': 290, 'num_leaves': 20, 'bagging_freq': 2, 'min_child_samples': 22, 'subsample_freq': 7, 'colsample_bytree': 0.775328275851668, 'subsample': 0.9062541098996595}. Best is trial 13 with value: 0.13018254490965397.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=4 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=4 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=4 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=4 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=4 will be ignored. Current value: bagging_freq=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-28 10:50:24,949]\u001b[0m Trial 18 finished with value: 0.13617413076371315 and parameters: {'learning_rate': 0.012426823034133866, 'reg_lambda': 0.511300491308945, 'n_estimators': 288, 'num_leaves': 14, 'bagging_freq': 2, 'min_child_samples': 22, 'subsample_freq': 4, 'colsample_bytree': 0.9035973553111036, 'subsample': 0.7808314953351884}. Best is trial 13 with value: 0.13018254490965397.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=7 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=7 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=7 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=7 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=7 will be ignored. Current value: bagging_freq=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-28 10:50:26,369]\u001b[0m Trial 19 finished with value: 0.3675096100417765 and parameters: {'learning_rate': 0.00018838728996601437, 'reg_lambda': 0.05214089529715269, 'n_estimators': 372, 'num_leaves': 21, 'bagging_freq': 4, 'min_child_samples': 22, 'subsample_freq': 7, 'colsample_bytree': 0.763377099330968, 'subsample': 0.8804856366062855}. Best is trial 13 with value: 0.13018254490965397.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=5 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=5 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=5 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=5 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=5 will be ignored. Current value: bagging_freq=6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-28 10:50:27,264]\u001b[0m Trial 20 finished with value: 0.1311222572140287 and parameters: {'learning_rate': 0.04444397054154442, 'reg_lambda': 2.2883198118259204e-07, 'n_estimators': 251, 'num_leaves': 8, 'bagging_freq': 6, 'min_child_samples': 28, 'subsample_freq': 5, 'colsample_bytree': 0.8809316833487199, 'subsample': 0.7756156183429876}. Best is trial 13 with value: 0.13018254490965397.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=5 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=5 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=5 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=5 will be ignored. Current value: bagging_freq=6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-28 10:50:27,962]\u001b[0m Trial 21 finished with value: 0.12927329694863 and parameters: {'learning_rate': 0.038234946883278324, 'reg_lambda': 1.5376313679381812e-07, 'n_estimators': 254, 'num_leaves': 7, 'bagging_freq': 6, 'min_child_samples': 23, 'subsample_freq': 5, 'colsample_bytree': 0.8570600131396184, 'subsample': 0.7864175917711234}. Best is trial 21 with value: 0.12927329694863.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=5 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=7 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=7 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=7 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=7 will be ignored. Current value: bagging_freq=6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-28 10:50:28,525]\u001b[0m Trial 22 finished with value: 0.13300844569509693 and parameters: {'learning_rate': 0.025294559393077242, 'reg_lambda': 2.0081954489528075e-07, 'n_estimators': 280, 'num_leaves': 4, 'bagging_freq': 6, 'min_child_samples': 18, 'subsample_freq': 7, 'colsample_bytree': 0.7858276353367357, 'subsample': 0.7105229769782749}. Best is trial 21 with value: 0.12927329694863.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=7 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=6 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=6 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=6 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=6 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=6 will be ignored. Current value: bagging_freq=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-28 10:50:29,509]\u001b[0m Trial 23 finished with value: 0.13986765220678285 and parameters: {'learning_rate': 0.01267088898916747, 'reg_lambda': 0.01812627241138135, 'n_estimators': 306, 'num_leaves': 16, 'bagging_freq': 5, 'min_child_samples': 43, 'subsample_freq': 6, 'colsample_bytree': 0.8472013292494861, 'subsample': 0.9028011357020702}. Best is trial 21 with value: 0.12927329694863.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=5 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=5 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=5 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=5 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=5 will be ignored. Current value: bagging_freq=6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-28 10:50:30,779]\u001b[0m Trial 24 finished with value: 0.1348251062492379 and parameters: {'learning_rate': 0.039815732103913495, 'reg_lambda': 6.175507343598935e-05, 'n_estimators': 241, 'num_leaves': 20, 'bagging_freq': 6, 'min_child_samples': 5, 'subsample_freq': 5, 'colsample_bytree': 0.921776351761496, 'subsample': 0.8138193895844769}. Best is trial 21 with value: 0.12927329694863.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=3 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=3 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=3 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=3 will be ignored. Current value: bagging_freq=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-28 10:50:31,636]\u001b[0m Trial 25 finished with value: 0.12803654639380244 and parameters: {'learning_rate': 0.05105335384749994, 'reg_lambda': 0.2366688920711734, 'n_estimators': 363, 'num_leaves': 7, 'bagging_freq': 2, 'min_child_samples': 29, 'subsample_freq': 3, 'colsample_bytree': 0.7245583523060263, 'subsample': 0.697251655360092}. Best is trial 25 with value: 0.12803654639380244.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=3 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=3 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=3 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=3 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=3 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=3 will be ignored. Current value: bagging_freq=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-28 10:50:32,467]\u001b[0m Trial 26 finished with value: 0.130217696537926 and parameters: {'learning_rate': 0.020582880513233415, 'reg_lambda': 4.290878730758029e-06, 'n_estimators': 375, 'num_leaves': 7, 'bagging_freq': 4, 'min_child_samples': 32, 'subsample_freq': 3, 'colsample_bytree': 0.7205913527867214, 'subsample': 0.6804583342598886}. Best is trial 25 with value: 0.12803654639380244.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=3 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=3 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=3 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=3 will be ignored. Current value: bagging_freq=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-28 10:50:33,170]\u001b[0m Trial 27 finished with value: 0.26638428238327755 and parameters: {'learning_rate': 0.0019209049266737705, 'reg_lambda': 2.756496378412226e-07, 'n_estimators': 363, 'num_leaves': 7, 'bagging_freq': 5, 'min_child_samples': 50, 'subsample_freq': 3, 'colsample_bytree': 0.6553124734199719, 'subsample': 0.5806372719713966}. Best is trial 25 with value: 0.12803654639380244.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=3 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=4 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=4 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=4 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=4 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=4 will be ignored. Current value: bagging_freq=6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-28 10:50:33,985]\u001b[0m Trial 28 finished with value: 0.14879632304065932 and parameters: {'learning_rate': 0.009469811453315538, 'reg_lambda': 4.9829803742996784e-08, 'n_estimators': 319, 'num_leaves': 11, 'bagging_freq': 6, 'min_child_samples': 40, 'subsample_freq': 4, 'colsample_bytree': 0.7343459759554514, 'subsample': 0.6920049990235538}. Best is trial 25 with value: 0.12803654639380244.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=2 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=2 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=2 will be ignored. Current value: bagging_freq=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-28 10:50:34,529]\u001b[0m Trial 29 finished with value: 0.13744136087486267 and parameters: {'learning_rate': 0.055303639472057395, 'reg_lambda': 0.00021069929768621957, 'n_estimators': 159, 'num_leaves': 13, 'bagging_freq': 4, 'min_child_samples': 55, 'subsample_freq': 2, 'colsample_bytree': 0.8065471493292253, 'subsample': 0.7605529745226043}. Best is trial 25 with value: 0.12803654639380244.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=2 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=2 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=3 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=3 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=3 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=3 will be ignored. Current value: bagging_freq=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-28 10:50:35,312]\u001b[0m Trial 30 finished with value: 0.13110816304753717 and parameters: {'learning_rate': 0.018566668479067235, 'reg_lambda': 0.00852418120761555, 'n_estimators': 347, 'num_leaves': 6, 'bagging_freq': 5, 'min_child_samples': 15, 'subsample_freq': 3, 'colsample_bytree': 0.6557560065142184, 'subsample': 0.7379652593138921}. Best is trial 25 with value: 0.12803654639380244.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=3 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=3 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=3 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=3 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=3 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=3 will be ignored. Current value: bagging_freq=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-28 10:50:36,253]\u001b[0m Trial 31 finished with value: 0.13026035186229284 and parameters: {'learning_rate': 0.02603525069595285, 'reg_lambda': 2.6738806500774292e-06, 'n_estimators': 378, 'num_leaves': 9, 'bagging_freq': 4, 'min_child_samples': 31, 'subsample_freq': 3, 'colsample_bytree': 0.7376829823187182, 'subsample': 0.681570919143527}. Best is trial 25 with value: 0.12803654639380244.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=1 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=1 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=1 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=1 will be ignored. Current value: bagging_freq=6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-28 10:50:37,106]\u001b[0m Trial 32 finished with value: 0.12988629133274376 and parameters: {'learning_rate': 0.05410075576115179, 'reg_lambda': 9.79678036397382e-06, 'n_estimators': 385, 'num_leaves': 6, 'bagging_freq': 6, 'min_child_samples': 27, 'subsample_freq': 1, 'colsample_bytree': 0.8441721492119204, 'subsample': 0.8105434629866073}. Best is trial 25 with value: 0.12803654639380244.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=1 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=1 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=1 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=1 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=1 will be ignored. Current value: bagging_freq=6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-28 10:50:37,906]\u001b[0m Trial 33 finished with value: 0.1290959541024816 and parameters: {'learning_rate': 0.06228341498845603, 'reg_lambda': 0.0009879829638964734, 'n_estimators': 390, 'num_leaves': 5, 'bagging_freq': 6, 'min_child_samples': 25, 'subsample_freq': 1, 'colsample_bytree': 0.8629799784961831, 'subsample': 0.8065408437510568}. Best is trial 25 with value: 0.12803654639380244.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=1 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-28 10:50:38,664]\u001b[0m Trial 34 finished with value: 0.12885394129937014 and parameters: {'learning_rate': 0.0676661453553806, 'reg_lambda': 6.689725352014924e-07, 'n_estimators': 384, 'num_leaves': 5, 'bagging_freq': 7, 'min_child_samples': 17, 'subsample_freq': 0, 'colsample_bytree': 0.8575459396835027, 'subsample': 0.7956030924386176}. Best is trial 25 with value: 0.12803654639380244.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-28 10:50:39,383]\u001b[0m Trial 35 finished with value: 0.12944791913584588 and parameters: {'learning_rate': 0.06957452202299753, 'reg_lambda': 6.374458438580713e-07, 'n_estimators': 357, 'num_leaves': 5, 'bagging_freq': 7, 'min_child_samples': 18, 'subsample_freq': 0, 'colsample_bytree': 0.8754379530687169, 'subsample': 0.787201110361871}. Best is trial 25 with value: 0.12803654639380244.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=1 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=1 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=1 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=1 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=1 will be ignored. Current value: bagging_freq=7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-28 10:50:40,399]\u001b[0m Trial 36 finished with value: 0.13692560025761624 and parameters: {'learning_rate': 0.09490659708536335, 'reg_lambda': 6.305812375478503e-08, 'n_estimators': 387, 'num_leaves': 9, 'bagging_freq': 7, 'min_child_samples': 39, 'subsample_freq': 1, 'colsample_bytree': 0.968073977835329, 'subsample': 0.7238393215301576}. Best is trial 25 with value: 0.12803654639380244.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-28 10:50:40,823]\u001b[0m Trial 37 finished with value: 0.139510822575434 and parameters: {'learning_rate': 0.03713534904411378, 'reg_lambda': 0.001069320954939506, 'n_estimators': 183, 'num_leaves': 4, 'bagging_freq': 1, 'min_child_samples': 62, 'subsample_freq': 0, 'colsample_bytree': 0.8250885677333716, 'subsample': 0.7644327367557957}. Best is trial 25 with value: 0.12803654639380244.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=1 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=1 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=1 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=1 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=1 will be ignored. Current value: bagging_freq=6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-28 10:50:41,996]\u001b[0m Trial 38 finished with value: 0.13357166488556638 and parameters: {'learning_rate': 0.09954375502565119, 'reg_lambda': 0.20869372737061553, 'n_estimators': 364, 'num_leaves': 11, 'bagging_freq': 6, 'min_child_samples': 9, 'subsample_freq': 1, 'colsample_bytree': 0.9276784091069605, 'subsample': 0.5593514381131861}. Best is trial 25 with value: 0.12803654639380244.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=2 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=2 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=2 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=2 will be ignored. Current value: bagging_freq=7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-28 10:50:42,741]\u001b[0m Trial 39 finished with value: 0.13166235343587326 and parameters: {'learning_rate': 0.058934624200155765, 'reg_lambda': 4.092614776642928e-05, 'n_estimators': 268, 'num_leaves': 8, 'bagging_freq': 7, 'min_child_samples': 14, 'subsample_freq': 2, 'colsample_bytree': 0.8692456936887888, 'subsample': 0.6593419034301986}. Best is trial 25 with value: 0.12803654639380244.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=2 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=1 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=1 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=1 will be ignored. Current value: bagging_freq=7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-28 10:50:43,330]\u001b[0m Trial 40 finished with value: 0.3584661125483583 and parameters: {'learning_rate': 0.0005471892334988537, 'reg_lambda': 7.60612281336593e-08, 'n_estimators': 222, 'num_leaves': 6, 'bagging_freq': 7, 'min_child_samples': 49, 'subsample_freq': 1, 'colsample_bytree': 0.9966424974725732, 'subsample': 0.743526164953341}. Best is trial 25 with value: 0.12803654639380244.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=1 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=1 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-28 10:50:44,062]\u001b[0m Trial 41 finished with value: 0.12984545099289238 and parameters: {'learning_rate': 0.0693263246442204, 'reg_lambda': 6.147885929188964e-07, 'n_estimators': 362, 'num_leaves': 5, 'bagging_freq': 7, 'min_child_samples': 18, 'subsample_freq': 0, 'colsample_bytree': 0.8638651198265898, 'subsample': 0.7822766397130615}. Best is trial 25 with value: 0.12803654639380244.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-28 10:50:44,789]\u001b[0m Trial 42 finished with value: 0.12873475134769274 and parameters: {'learning_rate': 0.03497109289695319, 'reg_lambda': 8.576103726792883e-07, 'n_estimators': 348, 'num_leaves': 5, 'bagging_freq': 7, 'min_child_samples': 18, 'subsample_freq': 0, 'colsample_bytree': 0.8966092587638878, 'subsample': 0.7957301426219371}. Best is trial 25 with value: 0.12803654639380244.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-28 10:50:45,873]\u001b[0m Trial 43 finished with value: 0.13017615511135774 and parameters: {'learning_rate': 0.030878849526700683, 'reg_lambda': 5.041875199990072e-07, 'n_estimators': 399, 'num_leaves': 8, 'bagging_freq': 6, 'min_child_samples': 10, 'subsample_freq': 0, 'colsample_bytree': 0.9430382189714875, 'subsample': 0.8366653737702645}. Best is trial 25 with value: 0.12803654639380244.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-28 10:50:46,911]\u001b[0m Trial 44 finished with value: 0.12913893811045601 and parameters: {'learning_rate': 0.038254772631148626, 'reg_lambda': 1.3635592835127698e-06, 'n_estimators': 339, 'num_leaves': 10, 'bagging_freq': 7, 'min_child_samples': 29, 'subsample_freq': 0, 'colsample_bytree': 0.9111500060715376, 'subsample': 0.8696608996375539}. Best is trial 25 with value: 0.12803654639380244.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-28 10:50:47,580]\u001b[0m Trial 45 finished with value: 0.1821315789803203 and parameters: {'learning_rate': 0.005710256603640508, 'reg_lambda': 1.2628728420816323e-06, 'n_estimators': 344, 'num_leaves': 10, 'bagging_freq': 7, 'min_child_samples': 81, 'subsample_freq': 0, 'colsample_bytree': 0.9119822564389275, 'subsample': 0.8761796195915835}. Best is trial 25 with value: 0.12803654639380244.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=1 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=1 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=1 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=1 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=1 will be ignored. Current value: bagging_freq=7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-28 10:50:48,298]\u001b[0m Trial 46 finished with value: 0.1296335604039825 and parameters: {'learning_rate': 0.027196390257353632, 'reg_lambda': 1.44775749135153e-05, 'n_estimators': 331, 'num_leaves': 5, 'bagging_freq': 7, 'min_child_samples': 30, 'subsample_freq': 1, 'colsample_bytree': 0.9002375182968161, 'subsample': 0.9321377668671409}. Best is trial 25 with value: 0.12803654639380244.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=1 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=1 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=1 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=1 will be ignored. Current value: bagging_freq=7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-28 10:50:49,513]\u001b[0m Trial 47 finished with value: 0.13461813313471976 and parameters: {'learning_rate': 0.016306593579020697, 'reg_lambda': 3.831107360702659e-06, 'n_estimators': 311, 'num_leaves': 13, 'bagging_freq': 7, 'min_child_samples': 39, 'subsample_freq': 1, 'colsample_bytree': 0.946425278107141, 'subsample': 0.8713815469422492}. Best is trial 25 with value: 0.12803654639380244.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=1 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-28 10:50:50,753]\u001b[0m Trial 48 finished with value: 0.21098309110811297 and parameters: {'learning_rate': 0.002995562073070344, 'reg_lambda': 1.28581225033313e-06, 'n_estimators': 386, 'num_leaves': 9, 'bagging_freq': 7, 'min_child_samples': 17, 'subsample_freq': 0, 'colsample_bytree': 0.97021030172237, 'subsample': 0.8329868622969597}. Best is trial 25 with value: 0.12803654639380244.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=2 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=2 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=2 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=2 will be ignored. Current value: bagging_freq=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-28 10:50:51,389]\u001b[0m Trial 49 finished with value: 0.12714589615503563 and parameters: {'learning_rate': 0.06968781875044947, 'reg_lambda': 3.059701474194842e-05, 'n_estimators': 352, 'num_leaves': 4, 'bagging_freq': 2, 'min_child_samples': 11, 'subsample_freq': 2, 'colsample_bytree': 0.8261119844531706, 'subsample': 0.9997983004687256}. Best is trial 49 with value: 0.12714589615503563.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=2 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=2 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=2 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=2 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=2 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=2 will be ignored. Current value: bagging_freq=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-28 10:50:52,146]\u001b[0m Trial 50 finished with value: 0.12952978733145115 and parameters: {'learning_rate': 0.06907034863164298, 'reg_lambda': 0.0015385680591039979, 'n_estimators': 355, 'num_leaves': 5, 'bagging_freq': 2, 'min_child_samples': 10, 'subsample_freq': 2, 'colsample_bytree': 0.8078098083270701, 'subsample': 0.9907525899455557}. Best is trial 49 with value: 0.12714589615503563.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=1 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=1 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=1 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=1 will be ignored. Current value: bagging_freq=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-28 10:50:52,792]\u001b[0m Trial 51 finished with value: 0.12867448676728138 and parameters: {'learning_rate': 0.0504621507393891, 'reg_lambda': 2.759949211506593e-05, 'n_estimators': 335, 'num_leaves': 4, 'bagging_freq': 2, 'min_child_samples': 25, 'subsample_freq': 1, 'colsample_bytree': 0.8266739859853524, 'subsample': 0.7069438807041056}. Best is trial 49 with value: 0.12714589615503563.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=1 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=2 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=2 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=2 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=2 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=2 will be ignored. Current value: bagging_freq=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-28 10:50:53,483]\u001b[0m Trial 52 finished with value: 0.130169222435396 and parameters: {'learning_rate': 0.047493151246566, 'reg_lambda': 0.00018518307398070734, 'n_estimators': 373, 'num_leaves': 4, 'bagging_freq': 2, 'min_child_samples': 7, 'subsample_freq': 2, 'colsample_bytree': 0.8291381736074221, 'subsample': 0.6996018719186162}. Best is trial 49 with value: 0.12714589615503563.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=2 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=2 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=2 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=2 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-28 10:50:54,167]\u001b[0m Trial 53 finished with value: 0.1282122355409955 and parameters: {'learning_rate': 0.07623473089321019, 'reg_lambda': 1.8294174043783964e-05, 'n_estimators': 317, 'num_leaves': 6, 'bagging_freq': 1, 'min_child_samples': 13, 'subsample_freq': 2, 'colsample_bytree': 0.8260071374480745, 'subsample': 0.7188120923350609}. Best is trial 49 with value: 0.12714589615503563.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=2 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=2 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=2 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=2 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=2 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=2 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-28 10:50:54,841]\u001b[0m Trial 54 finished with value: 0.1275127577690041 and parameters: {'learning_rate': 0.08111522551285662, 'reg_lambda': 2.9806169641057758e-05, 'n_estimators': 300, 'num_leaves': 6, 'bagging_freq': 1, 'min_child_samples': 12, 'subsample_freq': 2, 'colsample_bytree': 0.7628740462029133, 'subsample': 0.6581640062256955}. Best is trial 49 with value: 0.12714589615503563.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=2 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=2 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=2 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=2 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-28 10:50:55,606]\u001b[0m Trial 55 finished with value: 0.12891732968704503 and parameters: {'learning_rate': 0.048623723446338335, 'reg_lambda': 3.179738138333745e-05, 'n_estimators': 297, 'num_leaves': 7, 'bagging_freq': 1, 'min_child_samples': 14, 'subsample_freq': 2, 'colsample_bytree': 0.7005946898202658, 'subsample': 0.6139036402440907}. Best is trial 49 with value: 0.12714589615503563.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=2 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=3 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=3 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=3 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=3 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=3 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-28 10:50:56,386]\u001b[0m Trial 56 finished with value: 0.12872991636374093 and parameters: {'learning_rate': 0.08278174139933792, 'reg_lambda': 0.00012051542256817191, 'n_estimators': 324, 'num_leaves': 6, 'bagging_freq': 1, 'min_child_samples': 12, 'subsample_freq': 3, 'colsample_bytree': 0.7804921696625587, 'subsample': 0.6585210829929992}. Best is trial 49 with value: 0.12714589615503563.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=3 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=3 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=3 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=3 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-28 10:50:57,121]\u001b[0m Trial 57 finished with value: 0.12879935949702823 and parameters: {'learning_rate': 0.08484757740055268, 'reg_lambda': 9.571840916413849e-05, 'n_estimators': 320, 'num_leaves': 6, 'bagging_freq': 1, 'min_child_samples': 12, 'subsample_freq': 3, 'colsample_bytree': 0.7555274136024329, 'subsample': 0.6447664606470067}. Best is trial 49 with value: 0.12714589615503563.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=3 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=2 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=2 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=2 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-28 10:50:57,737]\u001b[0m Trial 58 finished with value: 0.13046977204654583 and parameters: {'learning_rate': 0.09896878227133091, 'reg_lambda': 0.00040363825980158265, 'n_estimators': 325, 'num_leaves': 4, 'bagging_freq': 1, 'min_child_samples': 7, 'subsample_freq': 2, 'colsample_bytree': 0.7847446867389453, 'subsample': 0.663126413063887}. Best is trial 49 with value: 0.12714589615503563.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=2 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=2 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=3 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=3 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=3 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=3 will be ignored. Current value: bagging_freq=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-28 10:50:58,619]\u001b[0m Trial 59 finished with value: 0.13038236599137315 and parameters: {'learning_rate': 0.02389556664259304, 'reg_lambda': 1.6166792066440618e-05, 'n_estimators': 301, 'num_leaves': 8, 'bagging_freq': 2, 'min_child_samples': 5, 'subsample_freq': 3, 'colsample_bytree': 0.7689751800908148, 'subsample': 0.7176353118436246}. Best is trial 49 with value: 0.12714589615503563.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=3 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=2 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=2 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=2 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=2 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-28 10:50:59,758]\u001b[0m Trial 60 finished with value: 0.13270455435227205 and parameters: {'learning_rate': 0.07809157753350215, 'reg_lambda': 6.148925353721036e-06, 'n_estimators': 335, 'num_leaves': 16, 'bagging_freq': 1, 'min_child_samples': 20, 'subsample_freq': 2, 'colsample_bytree': 0.6784673611602494, 'subsample': 0.6000476389821583}. Best is trial 49 with value: 0.12714589615503563.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=2 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=4 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=4 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=4 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=4 will be ignored. Current value: bagging_freq=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-28 10:51:00,538]\u001b[0m Trial 61 finished with value: 0.1299146183208349 and parameters: {'learning_rate': 0.032517604687180596, 'reg_lambda': 2.5829087907977965e-05, 'n_estimators': 315, 'num_leaves': 6, 'bagging_freq': 3, 'min_child_samples': 12, 'subsample_freq': 4, 'colsample_bytree': 0.8185819511874587, 'subsample': 0.6713573692695781}. Best is trial 49 with value: 0.12714589615503563.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=4 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=3 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=3 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=3 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=3 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=3 will be ignored. Current value: bagging_freq=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-28 10:51:01,339]\u001b[0m Trial 62 finished with value: 0.12774667062348505 and parameters: {'learning_rate': 0.052249264081261224, 'reg_lambda': 0.0001315383741263806, 'n_estimators': 280, 'num_leaves': 7, 'bagging_freq': 2, 'min_child_samples': 25, 'subsample_freq': 3, 'colsample_bytree': 0.7384738261433655, 'subsample': 0.7028880988943429}. Best is trial 49 with value: 0.12714589615503563.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=3 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=3 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=3 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=3 will be ignored. Current value: bagging_freq=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-28 10:51:02,133]\u001b[0m Trial 63 finished with value: 0.1282775361799025 and parameters: {'learning_rate': 0.04958812912661401, 'reg_lambda': 0.00017192106790929083, 'n_estimators': 277, 'num_leaves': 7, 'bagging_freq': 2, 'min_child_samples': 24, 'subsample_freq': 3, 'colsample_bytree': 0.74376028508044, 'subsample': 0.7089539727153585}. Best is trial 49 with value: 0.12714589615503563.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=3 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=3 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=3 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=3 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=3 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=3 will be ignored. Current value: bagging_freq=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-28 10:51:02,896]\u001b[0m Trial 64 finished with value: 0.12915734839661328 and parameters: {'learning_rate': 0.04678413784249598, 'reg_lambda': 5.4000367549550364e-05, 'n_estimators': 274, 'num_leaves': 7, 'bagging_freq': 2, 'min_child_samples': 24, 'subsample_freq': 3, 'colsample_bytree': 0.7402825645915421, 'subsample': 0.7079121042812418}. Best is trial 49 with value: 0.12714589615503563.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=4 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=4 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=4 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=4 will be ignored. Current value: bagging_freq=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-28 10:51:03,610]\u001b[0m Trial 65 finished with value: 0.13093284760823282 and parameters: {'learning_rate': 0.05991252287897286, 'reg_lambda': 0.003522573073998633, 'n_estimators': 237, 'num_leaves': 8, 'bagging_freq': 2, 'min_child_samples': 35, 'subsample_freq': 4, 'colsample_bytree': 0.7203450096942166, 'subsample': 0.7304259970419928}. Best is trial 49 with value: 0.12714589615503563.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=4 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=2 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=2 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=2 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=2 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=2 will be ignored. Current value: bagging_freq=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-28 10:51:04,227]\u001b[0m Trial 66 finished with value: 0.16596744807695352 and parameters: {'learning_rate': 0.009621509967361963, 'reg_lambda': 0.00013593920506461033, 'n_estimators': 287, 'num_leaves': 4, 'bagging_freq': 3, 'min_child_samples': 21, 'subsample_freq': 2, 'colsample_bytree': 0.6699111084035073, 'subsample': 0.7522361873200258}. Best is trial 49 with value: 0.12714589615503563.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=3 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=3 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=3 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=3 will be ignored. Current value: bagging_freq=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-28 10:51:05,138]\u001b[0m Trial 67 finished with value: 0.36505673060915644 and parameters: {'learning_rate': 0.0003169750891312366, 'reg_lambda': 6.454380895563993e-06, 'n_estimators': 260, 'num_leaves': 27, 'bagging_freq': 2, 'min_child_samples': 26, 'subsample_freq': 3, 'colsample_bytree': 0.7028793550407528, 'subsample': 0.6883676634075273}. Best is trial 49 with value: 0.12714589615503563.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=3 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=2 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=2 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=2 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=2 will be ignored. Current value: bagging_freq=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-28 10:51:06,027]\u001b[0m Trial 68 finished with value: 0.1315492527702964 and parameters: {'learning_rate': 0.0509735466476325, 'reg_lambda': 0.0003357320739963269, 'n_estimators': 296, 'num_leaves': 11, 'bagging_freq': 3, 'min_child_samples': 34, 'subsample_freq': 2, 'colsample_bytree': 0.7500168367153767, 'subsample': 0.6279334351925797}. Best is trial 49 with value: 0.12714589615503563.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=2 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=4 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=4 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=4 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=4 will be ignored. Current value: bagging_freq=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-28 10:51:06,778]\u001b[0m Trial 69 finished with value: 0.13156965654286645 and parameters: {'learning_rate': 0.021749984126173332, 'reg_lambda': 1.624048105967676e-05, 'n_estimators': 268, 'num_leaves': 7, 'bagging_freq': 2, 'min_child_samples': 20, 'subsample_freq': 4, 'colsample_bytree': 0.7943679638086144, 'subsample': 0.7024634979390891}. Best is trial 49 with value: 0.12714589615503563.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=4 will be ignored. Current value: bagging_freq=2\n",
      "learning_rate: 0.06968781875044947\n",
      "reg_lambda: 3.059701474194842e-05\n",
      "n_estimators: 352\n",
      "num_leaves: 4\n",
      "bagging_freq: 2\n",
      "min_child_samples: 11\n",
      "subsample_freq: 2\n",
      "colsample_bytree: 0.8261119844531706\n",
      "subsample: 0.9997983004687256\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=2 will be ignored. Current value: bagging_freq=2\n",
      "result on hold-out set after HPO: 0.12846352820280627\n"
     ]
    }
   ],
   "source": [
    "import lightgbm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "import optuna\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "train = pd.read_csv('../data/train.csv', sep=\",\")\n",
    "categorical = [var for var in train.columns if train[var].dtype=='O']\n",
    "\n",
    "for cat_feat in categorical:\n",
    "    train[cat_feat] = train[cat_feat].astype('category')\n",
    "    \n",
    "y = train['SalePrice']\n",
    "X = train.drop('SalePrice', axis=1)\n",
    "y = np.log1p(y)\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "        train_test_split(X, y, random_state=42, test_size=0.2)\n",
    "\n",
    "def objective(trial):\n",
    "\n",
    "    x_tr, x_te, y_tr, y_te = \\\n",
    "        train_test_split(X_train, y_train, random_state=42, test_size=0.2)\n",
    "    \n",
    "    model = lightgbm.LGBMRegressor()\n",
    "\n",
    "    param = {\n",
    "        \"objective\": \"regression\",\n",
    "        \"metric\": \"'neg_mean_squared_error'\",\n",
    "        \"verbosity\": -1,\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-4, 0.1, log=True),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 1e-8, 1.0, log=True),\n",
    "        \"n_estimators\" : trial.suggest_int(\"n_estimators\", 100, 400),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 4, 30),\n",
    "        \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 1, 7),\n",
    "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 100),\n",
    "        \"subsample_freq\": trial.suggest_int(\"subsample_freq\",0, 8),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\",0.5,1.0),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0)\n",
    "    }\n",
    "    model.set_params(**param)\n",
    "    clf = cross_val_score(\n",
    "    model,\n",
    "         x_tr, y_tr, scoring = 'neg_mean_squared_error'\n",
    "    )\n",
    "\n",
    "    return np.mean(np.sqrt(-clf))\n",
    "\n",
    "study = optuna.create_study()\n",
    "study.optimize(objective , n_trials =70)\n",
    "trial = study.best_trial\n",
    "model = lightgbm.LGBMRegressor()\n",
    "model.set_params(**trial.params)\n",
    "for k,v in trial.params.items():\n",
    "    print(f'{k}: {v}')\n",
    "model.fit(X_train, y_train)\n",
    "print(f'result on hold-out set after HPO: {np.sqrt(mean_squared_error(y_test, model.predict(X_test)))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9260b9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:autosklearn]",
   "language": "python",
   "name": "conda-env-autosklearn-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
